{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ef3116e",
   "metadata": {
    "id": "6ef3116e"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from IPython.utils import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2a82fc2",
   "metadata": {
    "id": "b2a82fc2"
   },
   "outputs": [],
   "source": [
    "features = pd.read_csv('Dataset/gastrointestinal_colonoscopy_lesions_dataset.csv')\n",
    "features = features.T\n",
    "class_label = pd.Series(features.index)\n",
    "features.index = range(features.shape[0])\n",
    "classes = np.zeros((features.shape[0], 3))\n",
    "for i in range(classes.shape[0]):\n",
    "    if 'adenoma' in class_label[i]:\n",
    "        classes[i,0] = 1.0\n",
    "        class_label[i] = 0\n",
    "    elif 'serrated' in class_label[i]:\n",
    "        classes[i,2] = 1.0\n",
    "        class_label[i] = 2\n",
    "    else:\n",
    "        classes[i,1] = 1.0\n",
    "        class_label[i] = 1\n",
    "classes = {'adenoma': classes[:,0], 'hyperplasic': classes[:,1], 'serrated': classes[:,2]}\n",
    "classes = pd.DataFrame(classes)\n",
    "class_label = class_label.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d3a520d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "9d3a520d",
    "outputId": "5b510f79-c4ad-403d-fbdf-9c8112630a41"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>690</th>\n",
       "      <th>691</th>\n",
       "      <th>692</th>\n",
       "      <th>693</th>\n",
       "      <th>694</th>\n",
       "      <th>695</th>\n",
       "      <th>696</th>\n",
       "      <th>697</th>\n",
       "      <th>698</th>\n",
       "      <th>699</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.048325</td>\n",
       "      <td>-0.005553</td>\n",
       "      <td>-0.056058</td>\n",
       "      <td>-0.084224</td>\n",
       "      <td>-0.037834</td>\n",
       "      <td>-0.031987</td>\n",
       "      <td>-0.101462</td>\n",
       "      <td>-0.050684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397177</td>\n",
       "      <td>0.392793</td>\n",
       "      <td>0.388256</td>\n",
       "      <td>0.383761</td>\n",
       "      <td>0.384351</td>\n",
       "      <td>0.383117</td>\n",
       "      <td>0.379185</td>\n",
       "      <td>0.365162</td>\n",
       "      <td>0.365579</td>\n",
       "      <td>0.375950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.001203</td>\n",
       "      <td>0.367137</td>\n",
       "      <td>-0.084265</td>\n",
       "      <td>-0.100569</td>\n",
       "      <td>0.018451</td>\n",
       "      <td>0.046227</td>\n",
       "      <td>-0.101911</td>\n",
       "      <td>-0.038210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397177</td>\n",
       "      <td>0.392793</td>\n",
       "      <td>0.388256</td>\n",
       "      <td>0.383761</td>\n",
       "      <td>0.384351</td>\n",
       "      <td>0.383117</td>\n",
       "      <td>0.379185</td>\n",
       "      <td>0.365162</td>\n",
       "      <td>0.365579</td>\n",
       "      <td>0.375950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.233810</td>\n",
       "      <td>0.046065</td>\n",
       "      <td>0.024136</td>\n",
       "      <td>0.032700</td>\n",
       "      <td>-0.031101</td>\n",
       "      <td>-0.036372</td>\n",
       "      <td>-0.169688</td>\n",
       "      <td>-0.154002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060715</td>\n",
       "      <td>0.057743</td>\n",
       "      <td>0.055493</td>\n",
       "      <td>0.056890</td>\n",
       "      <td>0.052044</td>\n",
       "      <td>0.053244</td>\n",
       "      <td>0.052057</td>\n",
       "      <td>0.045743</td>\n",
       "      <td>0.046962</td>\n",
       "      <td>0.047065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.182565</td>\n",
       "      <td>0.057049</td>\n",
       "      <td>-0.031463</td>\n",
       "      <td>-0.025114</td>\n",
       "      <td>-0.050518</td>\n",
       "      <td>-0.035422</td>\n",
       "      <td>-0.067798</td>\n",
       "      <td>-0.052955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060715</td>\n",
       "      <td>0.057743</td>\n",
       "      <td>0.055493</td>\n",
       "      <td>0.056890</td>\n",
       "      <td>0.052044</td>\n",
       "      <td>0.053244</td>\n",
       "      <td>0.052057</td>\n",
       "      <td>0.045743</td>\n",
       "      <td>0.046962</td>\n",
       "      <td>0.047065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.107936</td>\n",
       "      <td>-0.094438</td>\n",
       "      <td>0.092679</td>\n",
       "      <td>0.038768</td>\n",
       "      <td>0.186656</td>\n",
       "      <td>0.125008</td>\n",
       "      <td>0.095410</td>\n",
       "      <td>0.078630</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054256</td>\n",
       "      <td>-0.053808</td>\n",
       "      <td>-0.052869</td>\n",
       "      <td>-0.052718</td>\n",
       "      <td>-0.051934</td>\n",
       "      <td>-0.051097</td>\n",
       "      <td>-0.050394</td>\n",
       "      <td>-0.050345</td>\n",
       "      <td>-0.049870</td>\n",
       "      <td>-0.049726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.040649</td>\n",
       "      <td>-0.066683</td>\n",
       "      <td>-0.185786</td>\n",
       "      <td>-0.250955</td>\n",
       "      <td>-0.163660</td>\n",
       "      <td>-0.173238</td>\n",
       "      <td>-0.232896</td>\n",
       "      <td>-0.223542</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054095</td>\n",
       "      <td>-0.053643</td>\n",
       "      <td>-0.052701</td>\n",
       "      <td>-0.052581</td>\n",
       "      <td>-0.051796</td>\n",
       "      <td>-0.050957</td>\n",
       "      <td>-0.050288</td>\n",
       "      <td>-0.050236</td>\n",
       "      <td>-0.049758</td>\n",
       "      <td>-0.049611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.153445</td>\n",
       "      <td>0.092191</td>\n",
       "      <td>-0.010435</td>\n",
       "      <td>-0.057762</td>\n",
       "      <td>-0.097339</td>\n",
       "      <td>-0.111005</td>\n",
       "      <td>-0.120050</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043740</td>\n",
       "      <td>-0.044039</td>\n",
       "      <td>-0.043146</td>\n",
       "      <td>-0.043641</td>\n",
       "      <td>-0.042803</td>\n",
       "      <td>-0.042638</td>\n",
       "      <td>-0.042785</td>\n",
       "      <td>-0.042676</td>\n",
       "      <td>-0.042227</td>\n",
       "      <td>-0.042307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.144594</td>\n",
       "      <td>0.231284</td>\n",
       "      <td>-0.043448</td>\n",
       "      <td>-0.041229</td>\n",
       "      <td>-0.173962</td>\n",
       "      <td>-0.202734</td>\n",
       "      <td>-0.153664</td>\n",
       "      <td>-0.000519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043740</td>\n",
       "      <td>-0.044039</td>\n",
       "      <td>-0.043146</td>\n",
       "      <td>-0.043641</td>\n",
       "      <td>-0.042803</td>\n",
       "      <td>-0.042638</td>\n",
       "      <td>-0.042785</td>\n",
       "      <td>-0.042676</td>\n",
       "      <td>-0.042227</td>\n",
       "      <td>-0.042307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.169496</td>\n",
       "      <td>-0.098815</td>\n",
       "      <td>-0.207792</td>\n",
       "      <td>-0.250433</td>\n",
       "      <td>-0.221289</td>\n",
       "      <td>-0.226000</td>\n",
       "      <td>0.073333</td>\n",
       "      <td>0.138157</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053643</td>\n",
       "      <td>-0.053247</td>\n",
       "      <td>-0.052332</td>\n",
       "      <td>-0.052204</td>\n",
       "      <td>-0.051450</td>\n",
       "      <td>-0.050608</td>\n",
       "      <td>-0.049938</td>\n",
       "      <td>-0.049907</td>\n",
       "      <td>-0.049461</td>\n",
       "      <td>-0.049344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.159845</td>\n",
       "      <td>0.127796</td>\n",
       "      <td>0.027929</td>\n",
       "      <td>0.123740</td>\n",
       "      <td>-0.062721</td>\n",
       "      <td>-0.072166</td>\n",
       "      <td>0.041411</td>\n",
       "      <td>0.038973</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053643</td>\n",
       "      <td>-0.053247</td>\n",
       "      <td>-0.052332</td>\n",
       "      <td>-0.052204</td>\n",
       "      <td>-0.051450</td>\n",
       "      <td>-0.050608</td>\n",
       "      <td>-0.049938</td>\n",
       "      <td>-0.049907</td>\n",
       "      <td>-0.049461</td>\n",
       "      <td>-0.049344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows Ã— 700 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1         2         3         4         5         6    \\\n",
       "0    0.250000 -0.25  0.048325 -0.005553 -0.056058 -0.084224 -0.037834   \n",
       "1    0.250000  0.25 -0.001203  0.367137 -0.084265 -0.100569  0.018451   \n",
       "2    0.250000  0.25 -0.233810  0.046065  0.024136  0.032700 -0.031101   \n",
       "3    0.250000 -0.25 -0.182565  0.057049 -0.031463 -0.025114 -0.050518   \n",
       "4    0.250000  0.25 -0.107936 -0.094438  0.092679  0.038768  0.186656   \n",
       "..        ...   ...       ...       ...       ...       ...       ...   \n",
       "147 -0.083333  0.25  0.040649 -0.066683 -0.185786 -0.250955 -0.163660   \n",
       "148 -0.083333  0.25 -0.153445  0.092191 -0.010435 -0.057762 -0.097339   \n",
       "149 -0.083333 -0.25  0.144594  0.231284 -0.043448 -0.041229 -0.173962   \n",
       "150 -0.083333 -0.25 -0.169496 -0.098815 -0.207792 -0.250433 -0.221289   \n",
       "151 -0.083333  0.25 -0.159845  0.127796  0.027929  0.123740 -0.062721   \n",
       "\n",
       "          7         8         9    ...       690       691       692  \\\n",
       "0   -0.031987 -0.101462 -0.050684  ...  0.397177  0.392793  0.388256   \n",
       "1    0.046227 -0.101911 -0.038210  ...  0.397177  0.392793  0.388256   \n",
       "2   -0.036372 -0.169688 -0.154002  ...  0.060715  0.057743  0.055493   \n",
       "3   -0.035422 -0.067798 -0.052955  ...  0.060715  0.057743  0.055493   \n",
       "4    0.125008  0.095410  0.078630  ... -0.054256 -0.053808 -0.052869   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "147 -0.173238 -0.232896 -0.223542  ... -0.054095 -0.053643 -0.052701   \n",
       "148 -0.111005 -0.120050  0.000883  ... -0.043740 -0.044039 -0.043146   \n",
       "149 -0.202734 -0.153664 -0.000519  ... -0.043740 -0.044039 -0.043146   \n",
       "150 -0.226000  0.073333  0.138157  ... -0.053643 -0.053247 -0.052332   \n",
       "151 -0.072166  0.041411  0.038973  ... -0.053643 -0.053247 -0.052332   \n",
       "\n",
       "          693       694       695       696       697       698       699  \n",
       "0    0.383761  0.384351  0.383117  0.379185  0.365162  0.365579  0.375950  \n",
       "1    0.383761  0.384351  0.383117  0.379185  0.365162  0.365579  0.375950  \n",
       "2    0.056890  0.052044  0.053244  0.052057  0.045743  0.046962  0.047065  \n",
       "3    0.056890  0.052044  0.053244  0.052057  0.045743  0.046962  0.047065  \n",
       "4   -0.052718 -0.051934 -0.051097 -0.050394 -0.050345 -0.049870 -0.049726  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "147 -0.052581 -0.051796 -0.050957 -0.050288 -0.050236 -0.049758 -0.049611  \n",
       "148 -0.043641 -0.042803 -0.042638 -0.042785 -0.042676 -0.042227 -0.042307  \n",
       "149 -0.043641 -0.042803 -0.042638 -0.042785 -0.042676 -0.042227 -0.042307  \n",
       "150 -0.052204 -0.051450 -0.050608 -0.049938 -0.049907 -0.049461 -0.049344  \n",
       "151 -0.052204 -0.051450 -0.050608 -0.049938 -0.049907 -0.049461 -0.049344  \n",
       "\n",
       "[152 rows x 700 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in features.columns:\n",
    "    if features[col].abs().max()==0:\n",
    "        continue\n",
    "    features[col] = (features[col] - features[col].mean())/features[col].abs().max()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb3de32e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bb3de32e",
    "outputId": "1034eb4a-f027-49b8-a2aa-15c5c5261b95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 7)                 4907      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,965\n",
      "Trainable params: 4,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    \n",
    "    InputLayer(input_shape=(features.shape[1])),\n",
    "    \n",
    "    Dense(7, activation='sigmoid'),\n",
    "    \n",
    "    Dense(5, activation='sigmoid'),\n",
    "    \n",
    "    Dense(3, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "model.summary()\n",
    "model.save_weights('model_weights/initial_weights_colonoscopy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "406c8d25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "406c8d25",
    "outputId": "7be88874-578e-4554-a5fa-1acde877ca4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0413 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0609 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1134 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2184 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0974 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6769 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2306 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0970 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0811 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0427 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3725 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0512 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0537 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0548 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0528 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0436 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0826 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0413 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0414 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0498 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1353 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6309 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0447 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0553 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0502 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1373 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0726 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0721 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0470 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2487 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0458 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0448 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3266 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1201 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0431 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0419 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0527 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1074 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0419 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0434 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2308 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0686 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0455 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0620 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0416 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0439 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0938 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0572 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0460 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0418 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0528 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0430 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8539 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1444 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3097 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1746 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0420 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0553 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0853 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0440 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0423 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0446 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1282 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1081 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0494 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4158 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0531 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0552 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4951 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0728 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0442 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7717 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5365 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0942 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3696 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0630 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0443 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0829 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0434 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9493 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0378 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1360 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0455 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0437 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0560 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0527 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0560 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1375 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0848 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0526 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.6486 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1925 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1130 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1652 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6910 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0812 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0403 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0467 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0439 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0371 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0370 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0459 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0457 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0363 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0457 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0374 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0369 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0450 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1743 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0427 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0393 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0489 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0495 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1627 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0374 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0486 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5983 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0412 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0534 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0577 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0475 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0562 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.0677 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1768 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4292 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2281 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4108 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8251 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2594 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5378 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2656 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1722 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.8098 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.9799 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.0701 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1889 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2084 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2290 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1694 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1713 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2906 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3551 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9322 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2509 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0721 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3955 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3516 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1755 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.6873 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1781 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2675 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6006 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "j = 0\n",
    "for train_index, test_index in LeaveOneOut().split(features):\n",
    "    x_train, x_test = features.iloc[train_index,:], features.iloc[test_index,:]\n",
    "    y_train, y_test = classes.iloc[train_index,:], classes.iloc[test_index,:]\n",
    "    model.load_weights('model_weights/initial_weights_colonoscopy')\n",
    "    with io.capture_output() as captured:\n",
    "        model.fit(x_train, y_train, epochs=500)\n",
    "    acc += model.evaluate(x_test, y_test)[1]\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe3a4412",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fe3a4412",
    "outputId": "b44ef05d-9ea5-4320-b50b-21fd9d5bcd18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.868421052631579\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', acc/j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4978bff8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4978bff8",
    "outputId": "c6f66ebb-71dc-4423-c4ba-25174f0935e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0815 - accuracy: 0.9934\n",
      "Epoch 2/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0810 - accuracy: 0.9934\n",
      "Epoch 3/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0805 - accuracy: 0.9934\n",
      "Epoch 4/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0800 - accuracy: 0.9934\n",
      "Epoch 5/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0796 - accuracy: 0.9934\n",
      "Epoch 6/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0791 - accuracy: 1.0000\n",
      "Epoch 7/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0786 - accuracy: 1.0000\n",
      "Epoch 8/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0783 - accuracy: 1.0000\n",
      "Epoch 9/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0779 - accuracy: 1.0000\n",
      "Epoch 10/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0775 - accuracy: 1.0000\n",
      "Epoch 11/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0771 - accuracy: 1.0000\n",
      "Epoch 12/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0768 - accuracy: 1.0000\n",
      "Epoch 13/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0764 - accuracy: 1.0000\n",
      "Epoch 14/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0761 - accuracy: 1.0000\n",
      "Epoch 15/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0757 - accuracy: 1.0000\n",
      "Epoch 16/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0754 - accuracy: 1.0000\n",
      "Epoch 17/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0750 - accuracy: 1.0000\n",
      "Epoch 18/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0747 - accuracy: 1.0000\n",
      "Epoch 19/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0744 - accuracy: 1.0000\n",
      "Epoch 20/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0740 - accuracy: 1.0000\n",
      "Epoch 21/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0737 - accuracy: 1.0000\n",
      "Epoch 22/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0734 - accuracy: 1.0000\n",
      "Epoch 23/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0730 - accuracy: 1.0000\n",
      "Epoch 24/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0727 - accuracy: 1.0000\n",
      "Epoch 25/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 1.0000\n",
      "Epoch 26/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0721 - accuracy: 1.0000\n",
      "Epoch 27/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 1.0000\n",
      "Epoch 28/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0714 - accuracy: 1.0000\n",
      "Epoch 29/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 1.0000\n",
      "Epoch 30/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0708 - accuracy: 1.0000\n",
      "Epoch 31/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0705 - accuracy: 1.0000\n",
      "Epoch 32/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0702 - accuracy: 1.0000\n",
      "Epoch 33/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 1.0000\n",
      "Epoch 34/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 1.0000\n",
      "Epoch 35/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0693 - accuracy: 1.0000\n",
      "Epoch 36/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 1.0000\n",
      "Epoch 37/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 1.0000\n",
      "Epoch 38/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 1.0000\n",
      "Epoch 39/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 1.0000\n",
      "Epoch 41/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 1.0000\n",
      "Epoch 42/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 1.0000\n",
      "Epoch 43/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0617 - accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0612 - accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0609 - accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0607 - accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0587 - accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 1.0000\n",
      "Epoch 84/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0566 - accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0560 - accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0548 - accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0536 - accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0531 - accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0527 - accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0525 - accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0521 - accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0517 - accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0515 - accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0511 - accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0501 - accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0499 - accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 1.0000\n",
      "Epoch 119/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0493 - accuracy: 1.0000\n",
      "Epoch 120/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0492 - accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0490 - accuracy: 1.0000\n",
      "Epoch 122/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 1.0000\n",
      "Epoch 123/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 1.0000\n",
      "Epoch 124/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0484 - accuracy: 1.0000\n",
      "Epoch 125/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 1.0000\n",
      "Epoch 126/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0480 - accuracy: 1.0000\n",
      "Epoch 127/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0479 - accuracy: 1.0000\n",
      "Epoch 128/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0477 - accuracy: 1.0000\n",
      "Epoch 129/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0475 - accuracy: 1.0000\n",
      "Epoch 130/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0473 - accuracy: 1.0000\n",
      "Epoch 131/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0471 - accuracy: 1.0000\n",
      "Epoch 132/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0470 - accuracy: 1.0000\n",
      "Epoch 133/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 1.0000\n",
      "Epoch 134/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0464 - accuracy: 1.0000\n",
      "Epoch 136/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 1.0000\n",
      "Epoch 137/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0461 - accuracy: 1.0000\n",
      "Epoch 138/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 1.0000\n",
      "Epoch 139/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 1.0000\n",
      "Epoch 140/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0456 - accuracy: 1.0000\n",
      "Epoch 141/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0454 - accuracy: 1.0000\n",
      "Epoch 142/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0452 - accuracy: 1.0000\n",
      "Epoch 143/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 1.0000\n",
      "Epoch 144/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0449 - accuracy: 1.0000\n",
      "Epoch 145/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0447 - accuracy: 1.0000\n",
      "Epoch 146/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0446 - accuracy: 1.0000\n",
      "Epoch 147/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0444 - accuracy: 1.0000\n",
      "Epoch 148/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0442 - accuracy: 1.0000\n",
      "Epoch 149/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 1.0000\n",
      "Epoch 150/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0437 - accuracy: 1.0000\n",
      "Epoch 152/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0436 - accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0434 - accuracy: 1.0000\n",
      "Epoch 154/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0433 - accuracy: 1.0000\n",
      "Epoch 155/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0431 - accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0430 - accuracy: 1.0000\n",
      "Epoch 157/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0428 - accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0426 - accuracy: 1.0000\n",
      "Epoch 159/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0425 - accuracy: 1.0000\n",
      "Epoch 160/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 1.0000\n",
      "Epoch 161/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0422 - accuracy: 1.0000\n",
      "Epoch 162/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 1.0000\n",
      "Epoch 163/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0419 - accuracy: 1.0000\n",
      "Epoch 164/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0417 - accuracy: 1.0000\n",
      "Epoch 165/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0416 - accuracy: 1.0000\n",
      "Epoch 166/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0414 - accuracy: 1.0000\n",
      "Epoch 167/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0413 - accuracy: 1.0000\n",
      "Epoch 168/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0411 - accuracy: 1.0000\n",
      "Epoch 169/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 1.0000\n",
      "Epoch 170/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0408 - accuracy: 1.0000\n",
      "Epoch 171/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 1.0000\n",
      "Epoch 172/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0405 - accuracy: 1.0000\n",
      "Epoch 173/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0404 - accuracy: 1.0000\n",
      "Epoch 174/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0402 - accuracy: 1.0000\n",
      "Epoch 175/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0399 - accuracy: 1.0000\n",
      "Epoch 177/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0398 - accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 1.0000\n",
      "Epoch 179/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0394 - accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0391 - accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 1.0000\n",
      "Epoch 184/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0387 - accuracy: 1.0000\n",
      "Epoch 186/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 1.0000\n",
      "Epoch 187/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0384 - accuracy: 1.0000\n",
      "Epoch 188/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 1.0000\n",
      "Epoch 189/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0381 - accuracy: 1.0000\n",
      "Epoch 190/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0380 - accuracy: 1.0000\n",
      "Epoch 191/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 1.0000\n",
      "Epoch 192/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 1.0000\n",
      "Epoch 197/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0368 - accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0366 - accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0360 - accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 1.0000\n",
      "Epoch 213/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 1.0000\n",
      "Epoch 214/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0348 - accuracy: 1.0000\n",
      "Epoch 216/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0345 - accuracy: 1.0000\n",
      "Epoch 218/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 1.0000\n",
      "Epoch 221/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0339 - accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 1.0000\n",
      "Epoch 224/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 1.0000\n",
      "Epoch 225/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0335 - accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0333 - accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 1.0000\n",
      "Epoch 230/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 1.0000\n",
      "Epoch 231/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 1.0000\n",
      "Epoch 232/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0328 - accuracy: 1.0000\n",
      "Epoch 233/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 1.0000\n",
      "Epoch 234/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 1.0000\n",
      "Epoch 235/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0323 - accuracy: 1.0000\n",
      "Epoch 237/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0321 - accuracy: 1.0000\n",
      "Epoch 239/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 1.0000\n",
      "Epoch 241/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0318 - accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 1.0000\n",
      "Epoch 246/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0311 - accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0310 - accuracy: 1.0000\n",
      "Epoch 249/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0305 - accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0304 - accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0297 - accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0292 - accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0291 - accuracy: 1.0000\n",
      "Epoch 268/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0286 - accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0281 - accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0279 - accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0279 - accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0277 - accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0276 - accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0274 - accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0273 - accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0269 - accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0268 - accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0267 - accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0262 - accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0262 - accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0260 - accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0258 - accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0257 - accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0256 - accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0256 - accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0255 - accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0254 - accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0253 - accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0250 - accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0248 - accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0247 - accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0247 - accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0246 - accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0244 - accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0242 - accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0240 - accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0239 - accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0238 - accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 1.0000\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0235 - accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0234 - accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0232 - accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0230 - accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0230 - accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0229 - accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0226 - accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0225 - accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0221 - accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0220 - accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0218 - accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0216 - accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0212 - accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0206 - accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0204 - accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0187 - accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0187 - accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0186 - accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0186 - accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0183 - accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0183 - accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 1.0000\n",
      "Epoch 413/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0176 - accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0176 - accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0174 - accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0174 - accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0168 - accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0168 - accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 1.0000\n",
      "Epoch 495/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa7a0437fd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(features, classes, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46c38512",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46c38512",
    "outputId": "84d0c201-6816-4c52-8119-96d1b11471a7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 700/700 [07:05<00:00,  1.65it/s]\n"
     ]
    }
   ],
   "source": [
    "grad_sum = 0\n",
    "for col_name in tqdm(features.columns):\n",
    "    pointFrame = features.loc[:, features.columns != col_name]\n",
    "    for i in features[col_name]:\n",
    "        pointFrame[col_name] = i*np.ones(len(features.index))\n",
    "        points = tf.Variable(pointFrame, dtype='float')\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = model(points, training=False)\n",
    "        grads = tape.gradient(pred, points)\n",
    "        grad_sum += np.abs(grads.numpy())\n",
    "saliency_order = np.argsort(-np.sum(np.abs(grad_sum), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5082fe64",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "5082fe64",
    "outputId": "b7dad1d9-2a0b-41e9-ffdd-b314c77f0539"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features arranged in order of saliency are: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>547</th>\n",
       "      <th>464</th>\n",
       "      <th>146</th>\n",
       "      <th>571</th>\n",
       "      <th>545</th>\n",
       "      <th>549</th>\n",
       "      <th>459</th>\n",
       "      <th>546</th>\n",
       "      <th>466</th>\n",
       "      <th>...</th>\n",
       "      <th>249</th>\n",
       "      <th>257</th>\n",
       "      <th>353</th>\n",
       "      <th>404</th>\n",
       "      <th>385</th>\n",
       "      <th>260</th>\n",
       "      <th>214</th>\n",
       "      <th>182</th>\n",
       "      <th>359</th>\n",
       "      <th>416</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.019453</td>\n",
       "      <td>0.156682</td>\n",
       "      <td>0.014037</td>\n",
       "      <td>-0.000891</td>\n",
       "      <td>0.020956</td>\n",
       "      <td>0.013944</td>\n",
       "      <td>-0.031571</td>\n",
       "      <td>0.017661</td>\n",
       "      <td>0.037353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.019453</td>\n",
       "      <td>-0.071990</td>\n",
       "      <td>0.009191</td>\n",
       "      <td>-0.000891</td>\n",
       "      <td>0.020956</td>\n",
       "      <td>0.013944</td>\n",
       "      <td>-0.031571</td>\n",
       "      <td>0.017661</td>\n",
       "      <td>0.278855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.012418</td>\n",
       "      <td>-0.131291</td>\n",
       "      <td>0.008758</td>\n",
       "      <td>0.008760</td>\n",
       "      <td>0.007180</td>\n",
       "      <td>0.016346</td>\n",
       "      <td>-0.031571</td>\n",
       "      <td>-0.007271</td>\n",
       "      <td>0.171833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.012418</td>\n",
       "      <td>-0.140440</td>\n",
       "      <td>0.066090</td>\n",
       "      <td>0.008760</td>\n",
       "      <td>0.007180</td>\n",
       "      <td>0.016346</td>\n",
       "      <td>-0.031571</td>\n",
       "      <td>-0.007271</td>\n",
       "      <td>-0.195110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.018683</td>\n",
       "      <td>-0.029781</td>\n",
       "      <td>-0.104275</td>\n",
       "      <td>0.011717</td>\n",
       "      <td>0.012956</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>-0.031571</td>\n",
       "      <td>0.021297</td>\n",
       "      <td>0.284429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.006751</td>\n",
       "      <td>0.063551</td>\n",
       "      <td>-0.029268</td>\n",
       "      <td>-0.016223</td>\n",
       "      <td>0.018410</td>\n",
       "      <td>-0.003144</td>\n",
       "      <td>-0.031571</td>\n",
       "      <td>0.006035</td>\n",
       "      <td>0.280373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.009858</td>\n",
       "      <td>-0.040653</td>\n",
       "      <td>-0.007182</td>\n",
       "      <td>0.012807</td>\n",
       "      <td>0.009247</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.586617</td>\n",
       "      <td>0.009186</td>\n",
       "      <td>0.193040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.009858</td>\n",
       "      <td>-0.026035</td>\n",
       "      <td>0.030283</td>\n",
       "      <td>0.012807</td>\n",
       "      <td>0.009247</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>-0.031571</td>\n",
       "      <td>0.009186</td>\n",
       "      <td>-0.075700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.044736</td>\n",
       "      <td>-0.140440</td>\n",
       "      <td>-0.007820</td>\n",
       "      <td>0.009538</td>\n",
       "      <td>-0.043478</td>\n",
       "      <td>-0.039516</td>\n",
       "      <td>-0.031571</td>\n",
       "      <td>-0.050214</td>\n",
       "      <td>-0.195110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.044736</td>\n",
       "      <td>-0.136928</td>\n",
       "      <td>-0.029013</td>\n",
       "      <td>0.009538</td>\n",
       "      <td>-0.043478</td>\n",
       "      <td>-0.039516</td>\n",
       "      <td>-0.031571</td>\n",
       "      <td>-0.050214</td>\n",
       "      <td>-0.104243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows Ã— 700 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         547       464       146       571       545       549  \\\n",
       "0    0.250000  0.019453  0.156682  0.014037 -0.000891  0.020956  0.013944   \n",
       "1    0.250000  0.019453 -0.071990  0.009191 -0.000891  0.020956  0.013944   \n",
       "2    0.250000  0.012418 -0.131291  0.008758  0.008760  0.007180  0.016346   \n",
       "3    0.250000  0.012418 -0.140440  0.066090  0.008760  0.007180  0.016346   \n",
       "4    0.250000  0.018683 -0.029781 -0.104275  0.011717  0.012956  0.017094   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "147 -0.083333  0.006751  0.063551 -0.029268 -0.016223  0.018410 -0.003144   \n",
       "148 -0.083333  0.009858 -0.040653 -0.007182  0.012807  0.009247  0.007949   \n",
       "149 -0.083333  0.009858 -0.026035  0.030283  0.012807  0.009247  0.007949   \n",
       "150 -0.083333 -0.044736 -0.140440 -0.007820  0.009538 -0.043478 -0.039516   \n",
       "151 -0.083333 -0.044736 -0.136928 -0.029013  0.009538 -0.043478 -0.039516   \n",
       "\n",
       "          459       546       466  ...  249  257  353  404  385  260  214  \\\n",
       "0   -0.031571  0.017661  0.037353  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1   -0.031571  0.017661  0.278855  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2   -0.031571 -0.007271  0.171833  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3   -0.031571 -0.007271 -0.195110  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4   -0.031571  0.021297  0.284429  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "..        ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "147 -0.031571  0.006035  0.280373  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "148  0.586617  0.009186  0.193040  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "149 -0.031571  0.009186 -0.075700  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "150 -0.031571 -0.050214 -0.195110  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "151 -0.031571 -0.050214 -0.104243  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "     182  359  416  \n",
       "0    0.0  0.0  0.0  \n",
       "1    0.0  0.0  0.0  \n",
       "2    0.0  0.0  0.0  \n",
       "3    0.0  0.0  0.0  \n",
       "4    0.0  0.0  0.0  \n",
       "..   ...  ...  ...  \n",
       "147  0.0  0.0  0.0  \n",
       "148  0.0  0.0  0.0  \n",
       "149  0.0  0.0  0.0  \n",
       "150  0.0  0.0  0.0  \n",
       "151  0.0  0.0  0.0  \n",
       "\n",
       "[152 rows x 700 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The features arranged in order of saliency are: \\n')\n",
    "features[saliency_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74075456",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "74075456",
    "outputId": "b0b04eb0-4b40-40d6-8338-43047e52ced9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_features = 100\n",
    "salient_features = features.iloc[:,saliency_order[0:num_features]]\n",
    "A = np.zeros((features.shape[0], features.shape[0]))\n",
    "for i in features.index:\n",
    "    for j in range(i):\n",
    "        A[i,j] = np.linalg.norm(salient_features.iloc[i,:] - salient_features.iloc[j,:])\n",
    "A = A + np.transpose(A)\n",
    "p = 1.3\n",
    "A = (A < p)\n",
    "A = A - np.eye(A.shape[0])\n",
    "rows, cols = np.where(A==1)\n",
    "edges = zip(rows.tolist(), cols.tolist())\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(edges, node_size=1)\n",
    "color_map = np.array([])\n",
    "for node in G:\n",
    "    if (class_label[node]==0):\n",
    "        color_map = np.append(color_map, 'red')\n",
    "    elif (class_label[node]==1):\n",
    "        color_map = np.append(color_map, 'blue')\n",
    "    else:\n",
    "        color_map = np.append(color_map, 'yellow')\n",
    "nx.draw(G, node_color=color_map)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "CZQuhjgE2J34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CZQuhjgE2J34",
    "outputId": "d7f83110-f24e-4877-a9f7-22f1c3737803"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.is_connected(G) # tells whether or not the graph is connected\n",
    "# nx.clustering(G) # gives the clustering value of each vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "Rc3dliY3CKcW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rc3dliY3CKcW",
    "outputId": "1623759b-d818-4094-a17b-29fe89be7035"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.number_connected_components(G) # number of different connected components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "SZIxz2ELCKno",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SZIxz2ELCKno",
    "outputId": "b687c5d9-7ebf-4275-9d62-f06f52db800f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38791946308724834"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.density(G) # this tells how close the graph is to being fully connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "Y1g5OOrXCKxf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y1g5OOrXCKxf",
    "outputId": "07a2e3c4-e9a9-4f26-969b-d998339cc226"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7081425611264923"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.average_clustering(G) # clustering value for the whole graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "KwfxV_O2CK73",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KwfxV_O2CK73",
    "outputId": "16c179f0-0ac2-431e-fb01-de87e2c0670f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7534515406095325"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.transitivity(G) # 3* number of triangles in G/ number of connected triads in G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04de62bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "04de62bc",
    "outputId": "457fb95f-13f7-4a90-db31-c095059b9ae9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "giant_component = G.subgraph(max(nx.connected_components(G), key=len))\n",
    "color_map_GC = np.array([])\n",
    "for node in G:\n",
    "    if node in giant_component:\n",
    "        color_map_GC = np.append(color_map_GC, 'blue')\n",
    "    else:\n",
    "        color_map_GC = np.append(color_map_GC, 'red')\n",
    "nx.draw(G, node_color=color_map_GC)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cf69a78",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1cf69a78",
    "outputId": "69436881-368e-46bd-fed4-aa1f611ce84d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 4,\n",
       " 1: 4,\n",
       " 3: 4,\n",
       " 5: 4,\n",
       " 6: 4,\n",
       " 7: 4,\n",
       " 8: 4,\n",
       " 9: 4,\n",
       " 10: 4,\n",
       " 11: 4,\n",
       " 13: 4,\n",
       " 14: 4,\n",
       " 15: 4,\n",
       " 16: 4,\n",
       " 17: 4,\n",
       " 18: 5,\n",
       " 20: 4,\n",
       " 21: 4,\n",
       " 22: 4,\n",
       " 24: 4,\n",
       " 26: 4,\n",
       " 27: 4,\n",
       " 28: 4,\n",
       " 30: 4,\n",
       " 31: 4,\n",
       " 32: 4,\n",
       " 33: 4,\n",
       " 34: 4,\n",
       " 35: 4,\n",
       " 36: 5,\n",
       " 38: 4,\n",
       " 42: 4,\n",
       " 43: 4,\n",
       " 46: 4,\n",
       " 47: 4,\n",
       " 49: 5,\n",
       " 50: 4,\n",
       " 54: 4,\n",
       " 56: 4,\n",
       " 57: 4,\n",
       " 58: 4,\n",
       " 59: 4,\n",
       " 60: 5,\n",
       " 62: 4,\n",
       " 64: 4,\n",
       " 66: 4,\n",
       " 72: 4,\n",
       " 76: 4,\n",
       " 78: 4,\n",
       " 124: 4,\n",
       " 127: 4,\n",
       " 128: 3,\n",
       " 132: 4,\n",
       " 136: 4,\n",
       " 137: 4,\n",
       " 138: 4,\n",
       " 140: 4,\n",
       " 141: 4,\n",
       " 142: 4,\n",
       " 144: 4,\n",
       " 146: 4,\n",
       " 149: 3,\n",
       " 150: 4,\n",
       " 2: 4,\n",
       " 4: 4,\n",
       " 12: 4,\n",
       " 23: 4,\n",
       " 25: 4,\n",
       " 29: 4,\n",
       " 37: 4,\n",
       " 39: 4,\n",
       " 41: 4,\n",
       " 51: 4,\n",
       " 53: 4,\n",
       " 55: 4,\n",
       " 61: 4,\n",
       " 63: 4,\n",
       " 65: 4,\n",
       " 67: 4,\n",
       " 73: 4,\n",
       " 75: 4,\n",
       " 77: 4,\n",
       " 89: 4,\n",
       " 99: 4,\n",
       " 102: 4,\n",
       " 116: 4,\n",
       " 123: 4,\n",
       " 125: 4,\n",
       " 126: 4,\n",
       " 129: 4,\n",
       " 133: 4,\n",
       " 139: 4,\n",
       " 143: 4,\n",
       " 145: 4,\n",
       " 147: 4,\n",
       " 148: 4,\n",
       " 151: 4,\n",
       " 52: 4,\n",
       " 69: 4,\n",
       " 96: 4,\n",
       " 97: 4,\n",
       " 113: 4,\n",
       " 40: 4,\n",
       " 90: 5,\n",
       " 122: 4,\n",
       " 108: 4,\n",
       " 131: 4,\n",
       " 68: 5,\n",
       " 74: 5,\n",
       " 80: 4,\n",
       " 100: 3,\n",
       " 19: 5,\n",
       " 81: 4,\n",
       " 87: 4,\n",
       " 101: 4,\n",
       " 85: 4,\n",
       " 91: 4,\n",
       " 95: 4,\n",
       " 121: 4,\n",
       " 88: 4,\n",
       " 114: 4,\n",
       " 82: 4,\n",
       " 92: 4,\n",
       " 115: 4,\n",
       " 83: 4,\n",
       " 84: 4,\n",
       " 79: 5,\n",
       " 48: 6,\n",
       " 105: 4,\n",
       " 98: 4,\n",
       " 103: 4,\n",
       " 120: 4,\n",
       " 109: 4,\n",
       " 118: 4,\n",
       " 119: 4,\n",
       " 130: 5,\n",
       " 111: 5,\n",
       " 112: 4,\n",
       " 86: 5,\n",
       " 117: 4,\n",
       " 93: 4,\n",
       " 104: 5,\n",
       " 106: 5,\n",
       " 110: 5,\n",
       " 134: 5,\n",
       " 135: 6}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.eccentricity(giant_component) # largest possible shortest path distance between a vertex and all other vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebe7dc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.diameter(giant_component) # maximum shortest distance between a pair of vertices in G, it is the largest possible eccentricity value of a vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47d3ed7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.radius(giant_component) #  minimum eccentricity value of a vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e690f24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.4161073825503356,\n",
       " 1: 0.5234899328859061,\n",
       " 3: 0.5369127516778524,\n",
       " 5: 0.4563758389261745,\n",
       " 6: 0.5704697986577181,\n",
       " 7: 0.2953020134228188,\n",
       " 8: 0.6442953020134228,\n",
       " 9: 0.3825503355704698,\n",
       " 10: 0.697986577181208,\n",
       " 11: 0.6174496644295302,\n",
       " 13: 0.5570469798657718,\n",
       " 14: 0.6644295302013423,\n",
       " 15: 0.6040268456375839,\n",
       " 16: 0.5503355704697986,\n",
       " 17: 0.3624161073825503,\n",
       " 18: 0.2080536912751678,\n",
       " 20: 0.5637583892617449,\n",
       " 21: 0.6577181208053691,\n",
       " 22: 0.6577181208053691,\n",
       " 24: 0.6241610738255033,\n",
       " 26: 0.5302013422818792,\n",
       " 27: 0.5973154362416108,\n",
       " 28: 0.5436241610738255,\n",
       " 30: 0.42953020134228187,\n",
       " 31: 0.5570469798657718,\n",
       " 32: 0.5704697986577181,\n",
       " 33: 0.5302013422818792,\n",
       " 34: 0.5973154362416108,\n",
       " 35: 0.6308724832214765,\n",
       " 36: 0.28187919463087246,\n",
       " 38: 0.5906040268456376,\n",
       " 42: 0.35570469798657717,\n",
       " 43: 0.6912751677852349,\n",
       " 46: 0.348993288590604,\n",
       " 47: 0.6241610738255033,\n",
       " 49: 0.020134228187919462,\n",
       " 50: 0.5906040268456376,\n",
       " 54: 0.6577181208053691,\n",
       " 56: 0.5704697986577181,\n",
       " 57: 0.7114093959731543,\n",
       " 58: 0.6845637583892618,\n",
       " 59: 0.6174496644295302,\n",
       " 60: 0.08053691275167785,\n",
       " 62: 0.5838926174496644,\n",
       " 64: 0.6241610738255033,\n",
       " 66: 0.4899328859060403,\n",
       " 72: 0.46308724832214765,\n",
       " 76: 0.6375838926174496,\n",
       " 78: 0.6040268456375839,\n",
       " 124: 0.5436241610738255,\n",
       " 127: 0.5302013422818792,\n",
       " 128: 0.7315436241610738,\n",
       " 132: 0.2885906040268456,\n",
       " 136: 0.7516778523489933,\n",
       " 137: 0.6510067114093959,\n",
       " 138: 0.5704697986577181,\n",
       " 140: 0.6308724832214765,\n",
       " 141: 0.5704697986577181,\n",
       " 142: 0.6711409395973155,\n",
       " 144: 0.5838926174496644,\n",
       " 146: 0.46308724832214765,\n",
       " 149: 0.5906040268456376,\n",
       " 150: 0.4832214765100671,\n",
       " 2: 0.5704697986577181,\n",
       " 4: 0.6308724832214765,\n",
       " 12: 0.5771812080536912,\n",
       " 23: 0.6375838926174496,\n",
       " 25: 0.5771812080536912,\n",
       " 29: 0.6040268456375839,\n",
       " 37: 0.6040268456375839,\n",
       " 39: 0.5302013422818792,\n",
       " 41: 0.4832214765100671,\n",
       " 51: 0.5838926174496644,\n",
       " 53: 0.4966442953020134,\n",
       " 55: 0.4832214765100671,\n",
       " 61: 0.5771812080536912,\n",
       " 63: 0.3422818791946309,\n",
       " 65: 0.5771812080536912,\n",
       " 67: 0.5369127516778524,\n",
       " 73: 0.15436241610738255,\n",
       " 75: 0.3825503355704698,\n",
       " 77: 0.4228187919463087,\n",
       " 89: 0.5637583892617449,\n",
       " 99: 0.2751677852348993,\n",
       " 102: 0.348993288590604,\n",
       " 116: 0.6845637583892618,\n",
       " 123: 0.30201342281879195,\n",
       " 125: 0.610738255033557,\n",
       " 126: 0.40268456375838924,\n",
       " 129: 0.6040268456375839,\n",
       " 133: 0.22818791946308725,\n",
       " 139: 0.5503355704697986,\n",
       " 143: 0.5704697986577181,\n",
       " 145: 0.348993288590604,\n",
       " 147: 0.40268456375838924,\n",
       " 148: 0.5100671140939598,\n",
       " 151: 0.6778523489932886,\n",
       " 52: 0.44966442953020136,\n",
       " 69: 0.2751677852348993,\n",
       " 96: 0.42953020134228187,\n",
       " 97: 0.5436241610738255,\n",
       " 113: 0.3422818791946309,\n",
       " 40: 0.174496644295302,\n",
       " 90: 0.15436241610738255,\n",
       " 122: 0.28187919463087246,\n",
       " 108: 0.16778523489932887,\n",
       " 131: 0.060402684563758385,\n",
       " 68: 0.1476510067114094,\n",
       " 74: 0.15436241610738255,\n",
       " 80: 0.0738255033557047,\n",
       " 100: 0.4161073825503356,\n",
       " 19: 0.013422818791946308,\n",
       " 81: 0.2885906040268456,\n",
       " 87: 0.1476510067114094,\n",
       " 101: 0.2885906040268456,\n",
       " 85: 0.1476510067114094,\n",
       " 91: 0.19463087248322147,\n",
       " 95: 0.40268456375838924,\n",
       " 121: 0.2550335570469799,\n",
       " 88: 0.10738255033557047,\n",
       " 114: 0.10067114093959731,\n",
       " 82: 0.22147651006711408,\n",
       " 92: 0.1342281879194631,\n",
       " 115: 0.16778523489932887,\n",
       " 83: 0.12080536912751677,\n",
       " 84: 0.12080536912751677,\n",
       " 79: 0.013422818791946308,\n",
       " 44: 0.006711409395973154,\n",
       " 45: 0.006711409395973154,\n",
       " 48: 0.006711409395973154,\n",
       " 105: 0.11409395973154363,\n",
       " 98: 0.087248322147651,\n",
       " 103: 0.053691275167785234,\n",
       " 120: 0.0738255033557047,\n",
       " 109: 0.10067114093959731,\n",
       " 118: 0.14093959731543623,\n",
       " 119: 0.1342281879194631,\n",
       " 70: 0.006711409395973154,\n",
       " 71: 0.006711409395973154,\n",
       " 130: 0.03355704697986577,\n",
       " 111: 0.026845637583892617,\n",
       " 112: 0.10738255033557047,\n",
       " 86: 0.006711409395973154,\n",
       " 117: 0.04697986577181208,\n",
       " 93: 0.04697986577181208,\n",
       " 104: 0.03355704697986577,\n",
       " 106: 0.006711409395973154,\n",
       " 110: 0.006711409395973154,\n",
       " 134: 0.013422818791946308,\n",
       " 135: 0.006711409395973154}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# below gives us the different centrality measures for the vertices of the graphs\n",
    "nx.degree_centrality(G) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10e8930a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(nx.degree_centrality(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58ab69c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.07723818634541459,\n",
       " 1: 0.09986711432002111,\n",
       " 3: 0.1017055103823074,\n",
       " 5: 0.08168307351286896,\n",
       " 6: 0.10883963061137839,\n",
       " 7: 0.058003821081016614,\n",
       " 8: 0.11747484877223915,\n",
       " 9: 0.07102297749350296,\n",
       " 10: 0.12226641040199668,\n",
       " 11: 0.11266389666245914,\n",
       " 13: 0.10441418433291422,\n",
       " 14: 0.11999210393063231,\n",
       " 15: 0.1109849524316201,\n",
       " 16: 0.1058070989167064,\n",
       " 17: 0.06834788565420588,\n",
       " 18: 0.03621810660546493,\n",
       " 20: 0.10558642843090094,\n",
       " 21: 0.1193474362031259,\n",
       " 22: 0.118504573459797,\n",
       " 24: 0.11525728540389939,\n",
       " 26: 0.09865517261543875,\n",
       " 27: 0.10985298039501518,\n",
       " 28: 0.10136776786072413,\n",
       " 30: 0.07976398947831366,\n",
       " 31: 0.10510753902295028,\n",
       " 32: 0.10721852640814587,\n",
       " 33: 0.10061528995878627,\n",
       " 34: 0.10882881373670086,\n",
       " 35: 0.11604915863510672,\n",
       " 36: 0.04915386856792384,\n",
       " 38: 0.11058811830927413,\n",
       " 42: 0.0662477693179741,\n",
       " 43: 0.12183106815535338,\n",
       " 46: 0.06965894966810064,\n",
       " 47: 0.11490266465058062,\n",
       " 49: 0.002355435010610335,\n",
       " 50: 0.11172853367314348,\n",
       " 54: 0.11991054426987308,\n",
       " 56: 0.10263298732190534,\n",
       " 57: 0.12324589473980109,\n",
       " 58: 0.11908181687694469,\n",
       " 59: 0.11423877259608373,\n",
       " 60: 0.014005949488556,\n",
       " 62: 0.10956387546833961,\n",
       " 64: 0.11067233348784533,\n",
       " 66: 0.09041286751786755,\n",
       " 72: 0.08432988614478099,\n",
       " 76: 0.11403568861855351,\n",
       " 78: 0.11061435257718631,\n",
       " 124: 0.09748799134558124,\n",
       " 127: 0.0957584196346082,\n",
       " 128: 0.12161101850378024,\n",
       " 132: 0.05293893305352711,\n",
       " 136: 0.1230239060119064,\n",
       " 137: 0.113861060049689,\n",
       " 138: 0.10904034841142184,\n",
       " 140: 0.11469530898973646,\n",
       " 141: 0.1065011196714077,\n",
       " 142: 0.12053224923239236,\n",
       " 144: 0.10681642429949605,\n",
       " 146: 0.08390811531535698,\n",
       " 149: 0.10325940424864383,\n",
       " 150: 0.0882556309644689,\n",
       " 2: 0.10962513084464931,\n",
       " 4: 0.11415428047162411,\n",
       " 12: 0.10942394030342673,\n",
       " 23: 0.11515786837768077,\n",
       " 25: 0.1088539298208403,\n",
       " 29: 0.11080942381622585,\n",
       " 37: 0.11123630156021885,\n",
       " 39: 0.10211314919949815,\n",
       " 41: 0.0964287432780839,\n",
       " 51: 0.10851250098250272,\n",
       " 53: 0.09923594784462028,\n",
       " 55: 0.09642997460617907,\n",
       " 61: 0.10939093178907829,\n",
       " 63: 0.06653476918814605,\n",
       " 65: 0.10471549728242828,\n",
       " 67: 0.10239014475088537,\n",
       " 73: 0.030520028845653555,\n",
       " 75: 0.07292919647543847,\n",
       " 77: 0.08086233084483281,\n",
       " 89: 0.09159232671709702,\n",
       " 99: 0.04406923588266395,\n",
       " 102: 0.056251601999854316,\n",
       " 116: 0.11028438468948476,\n",
       " 123: 0.056259379749011434,\n",
       " 125: 0.10746797268633251,\n",
       " 126: 0.07572083021232727,\n",
       " 129: 0.10446064415854961,\n",
       " 133: 0.04239071031052548,\n",
       " 139: 0.10301332543719169,\n",
       " 143: 0.10647999515634672,\n",
       " 145: 0.06677765166335,\n",
       " 147: 0.07824116324799853,\n",
       " 148: 0.09577328759645025,\n",
       " 151: 0.11780227210950431,\n",
       " 52: 0.08762934143739472,\n",
       " 69: 0.05240118523131869,\n",
       " 96: 0.07072525954473133,\n",
       " 97: 0.08323202890973715,\n",
       " 113: 0.05392346098713224,\n",
       " 40: 0.03395751874158201,\n",
       " 90: 0.02735567304248111,\n",
       " 122: 0.055049684502045455,\n",
       " 108: 0.02550925027657737,\n",
       " 131: 0.011486459862641156,\n",
       " 68: 0.025375398900325797,\n",
       " 74: 0.02467480162269492,\n",
       " 80: 0.00794504533354156,\n",
       " 100: 0.05904859126703928,\n",
       " 19: 0.0015763041960725522,\n",
       " 81: 0.04485348659822602,\n",
       " 87: 0.024267776685869533,\n",
       " 101: 0.046675521314908056,\n",
       " 85: 0.015988488371569597,\n",
       " 91: 0.02971160083865663,\n",
       " 95: 0.06220115692470667,\n",
       " 121: 0.034914605495480845,\n",
       " 88: 0.015206695821778592,\n",
       " 114: 0.012080604591335352,\n",
       " 82: 0.02471982994081551,\n",
       " 92: 0.01966648634943795,\n",
       " 115: 0.02223476980479972,\n",
       " 83: 0.012830709933965673,\n",
       " 84: 0.01565488160789301,\n",
       " 79: 0.0017257643251476433,\n",
       " 44: 1.4682212455144365e-14,\n",
       " 45: 1.4682212455144365e-14,\n",
       " 48: 2.9811997305581773e-05,\n",
       " 105: 0.012679165448896633,\n",
       " 98: 0.006007942945141574,\n",
       " 103: 0.003557995110293788,\n",
       " 120: 0.008221996695969751,\n",
       " 109: 0.011817538475203058,\n",
       " 118: 0.014249873947763109,\n",
       " 119: 0.013649755306987863,\n",
       " 70: 1.4682212455144365e-14,\n",
       " 71: 1.4682212455144365e-14,\n",
       " 130: 0.005885312411026818,\n",
       " 111: 0.002626114098788455,\n",
       " 112: 0.009087790735811804,\n",
       " 86: 0.00019248128362681793,\n",
       " 117: 0.006055333853935501,\n",
       " 93: 0.002907558122531668,\n",
       " 104: 0.0005687686182286949,\n",
       " 106: 3.680502474680233e-05,\n",
       " 110: 4.5038018629513146e-05,\n",
       " 134: 0.00011505631628309919,\n",
       " 135: 1.456967287169445e-06}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.eigenvector_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e015e753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(nx.eigenvector_centrality(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f6a80f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5953897997904455,\n",
       " 1: 0.6413971934106162,\n",
       " 3: 0.6413971934106162,\n",
       " 5: 0.6082214765100671,\n",
       " 6: 0.6593802922912878,\n",
       " 7: 0.5324806888691909,\n",
       " 8: 0.6985513987640375,\n",
       " 9: 0.5806888170795702,\n",
       " 10: 0.727357642012039,\n",
       " 11: 0.6816781765716694,\n",
       " 13: 0.6502644357158321,\n",
       " 14: 0.7090823243735457,\n",
       " 15: 0.6719399169063599,\n",
       " 16: 0.6532749192145165,\n",
       " 17: 0.5689813812513531,\n",
       " 18: 0.4899561894108874,\n",
       " 20: 0.6532749192145165,\n",
       " 21: 0.7055369127516778,\n",
       " 22: 0.7055369127516778,\n",
       " 24: 0.6883286953674905,\n",
       " 26: 0.6384949436666768,\n",
       " 27: 0.6751549404322276,\n",
       " 28: 0.6443259477184273,\n",
       " 30: 0.5953897997904455,\n",
       " 31: 0.6563134072108632,\n",
       " 32: 0.6624759744147211,\n",
       " 33: 0.6443259477184273,\n",
       " 34: 0.6751549404322276,\n",
       " 35: 0.6917028556388999,\n",
       " 36: 0.5226199353716133,\n",
       " 38: 0.6687553675371354,\n",
       " 42: 0.5712849495965003,\n",
       " 43: 0.7236276028222337,\n",
       " 46: 0.5621808069734485,\n",
       " 47: 0.6883286953674905,\n",
       " 49: 0.40548098434004476,\n",
       " 50: 0.6687553675371354,\n",
       " 54: 0.7055369127516778,\n",
       " 56: 0.6656008610864885,\n",
       " 57: 0.7349342841163312,\n",
       " 58: 0.7236276028222337,\n",
       " 59: 0.6849872939336679,\n",
       " 60: 0.43686496145614734,\n",
       " 62: 0.6687553675371354,\n",
       " 64: 0.6883286953674905,\n",
       " 66: 0.6216184253318747,\n",
       " 72: 0.6082214765100671,\n",
       " 76: 0.6917028556388999,\n",
       " 78: 0.6751549404322276,\n",
       " 124: 0.6443259477184273,\n",
       " 127: 0.6356188403168269,\n",
       " 128: 0.766887948643128,\n",
       " 132: 0.546927839342386,\n",
       " 136: 0.766887948643128,\n",
       " 137: 0.702026778857391,\n",
       " 138: 0.6563134072108632,\n",
       " 140: 0.6917028556388999,\n",
       " 141: 0.6624759744147211,\n",
       " 142: 0.7126635482340181,\n",
       " 144: 0.6656008610864885,\n",
       " 146: 0.6135103589145026,\n",
       " 149: 0.6719399169063599,\n",
       " 150: 0.6216184253318747,\n",
       " 2: 0.6624759744147211,\n",
       " 4: 0.6917028556388999,\n",
       " 12: 0.6656008610864885,\n",
       " 23: 0.6985513987640375,\n",
       " 25: 0.6656008610864885,\n",
       " 29: 0.6784008776458441,\n",
       " 37: 0.6784008776458441,\n",
       " 39: 0.6443259477184273,\n",
       " 41: 0.618892028729542,\n",
       " 51: 0.6719399169063599,\n",
       " 53: 0.627143922445936,\n",
       " 55: 0.624368949337768,\n",
       " 61: 0.6656008610864885,\n",
       " 63: 0.557736689922275,\n",
       " 65: 0.6656008610864885,\n",
       " 67: 0.6472815713318146,\n",
       " 73: 0.49166335383392185,\n",
       " 75: 0.5736072461395756,\n",
       " 77: 0.5979126379251508,\n",
       " 89: 0.6624759744147211,\n",
       " 99: 0.5365299716742798,\n",
       " 102: 0.5666963154631951,\n",
       " 116: 0.7236276028222337,\n",
       " 123: 0.5406413124533931,\n",
       " 125: 0.6849872939336679,\n",
       " 126: 0.5855078114121808,\n",
       " 129: 0.6816781765716694,\n",
       " 133: 0.5187771417291749,\n",
       " 139: 0.6532749192145165,\n",
       " 143: 0.6624759744147211,\n",
       " 145: 0.5644295302013422,\n",
       " 147: 0.5879474272930648,\n",
       " 148: 0.6356188403168269,\n",
       " 151: 0.7199356252568142,\n",
       " 52: 0.6082214765100671,\n",
       " 69: 0.5344976611755134,\n",
       " 96: 0.5953897997904455,\n",
       " 97: 0.6443259477184273,\n",
       " 113: 0.5689813812513531,\n",
       " 40: 0.5057612277789806,\n",
       " 90: 0.4882608392745176,\n",
       " 122: 0.546927839342386,\n",
       " 108: 0.4986126591884649,\n",
       " 131: 0.4423428920073215,\n",
       " 68: 0.48324446078882044,\n",
       " 74: 0.4719310453188481,\n",
       " 80: 0.47351470654475025,\n",
       " 100: 0.6082214765100671,\n",
       " 19: 0.36556316722884863,\n",
       " 81: 0.5406413124533931,\n",
       " 87: 0.4986126591884649,\n",
       " 101: 0.5406413124533931,\n",
       " 85: 0.49685698081104074,\n",
       " 91: 0.5112586324287521,\n",
       " 95: 0.5904074583696048,\n",
       " 121: 0.5344976611755134,\n",
       " 88: 0.4899561894108874,\n",
       " 114: 0.47995708350454275,\n",
       " 82: 0.5304788817681788,\n",
       " 92: 0.49511362298363365,\n",
       " 115: 0.5112586324287521,\n",
       " 83: 0.48324446078882044,\n",
       " 84: 0.49685698081104074,\n",
       " 79: 0.39196495152870997,\n",
       " 44: 0.006711409395973154,\n",
       " 45: 0.006711409395973154,\n",
       " 48: 0.2868036230697878,\n",
       " 105: 0.4815951622878347,\n",
       " 98: 0.47833011034012063,\n",
       " 103: 0.46570093250935835,\n",
       " 120: 0.4815951622878347,\n",
       " 109: 0.4899561894108874,\n",
       " 118: 0.5021615037378491,\n",
       " 119: 0.49511362298363365,\n",
       " 70: 0.006711409395973154,\n",
       " 71: 0.006711409395973154,\n",
       " 130: 0.4423428920073215,\n",
       " 111: 0.39525877465079995,\n",
       " 112: 0.4865771812080537,\n",
       " 86: 0.32663745960725826,\n",
       " 117: 0.46724298857727015,\n",
       " 93: 0.4581408524361545,\n",
       " 104: 0.3510133894286955,\n",
       " 106: 0.312184474668884,\n",
       " 110: 0.31567647102983354,\n",
       " 134: 0.32663745960725826,\n",
       " 135: 0.2449780947054437}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.closeness_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98c403fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(nx.closeness_centrality(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ecc554e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.01037935915179116,\n",
       " 1: 0.0016091929015440048,\n",
       " 3: 0.0018520946988251812,\n",
       " 5: 0.003572847878940805,\n",
       " 6: 0.0018413930676144047,\n",
       " 7: 0.00567711453439371,\n",
       " 8: 0.0040221834613796345,\n",
       " 9: 0.0012970836417924634,\n",
       " 10: 0.007310746107880942,\n",
       " 11: 0.005231234949753208,\n",
       " 13: 0.0023836675173915752,\n",
       " 14: 0.004378131883988671,\n",
       " 15: 0.003625550419719558,\n",
       " 16: 0.0014397903056928094,\n",
       " 17: 0.0008110743731963044,\n",
       " 18: 0.00025071100848277956,\n",
       " 20: 0.003078025942384054,\n",
       " 21: 0.004267682134281057,\n",
       " 22: 0.006213825652991875,\n",
       " 24: 0.0034103396722924965,\n",
       " 26: 0.002918990404524792,\n",
       " 27: 0.003704064296407462,\n",
       " 28: 0.0025047674606430543,\n",
       " 30: 0.0017907530732116249,\n",
       " 31: 0.002955816896574165,\n",
       " 32: 0.0022721073715556536,\n",
       " 33: 0.0018206805115335363,\n",
       " 34: 0.02210492669220816,\n",
       " 35: 0.003899490824939534,\n",
       " 36: 0.0012481221556012304,\n",
       " 38: 0.0030875857548232294,\n",
       " 42: 0.0017126533648128316,\n",
       " 43: 0.007572446116479692,\n",
       " 46: 0.0002775469732669213,\n",
       " 47: 0.005069540158561021,\n",
       " 49: 0.013060039905677489,\n",
       " 50: 0.002138712242518846,\n",
       " 54: 0.004017557882660229,\n",
       " 56: 0.016674224118639953,\n",
       " 57: 0.00838754615223347,\n",
       " 58: 0.011001983551593576,\n",
       " 59: 0.003271446957200504,\n",
       " 60: 0.0,\n",
       " 62: 0.00264786050745485,\n",
       " 64: 0.008245510205629069,\n",
       " 66: 0.002583435467097275,\n",
       " 72: 0.003970790446336178,\n",
       " 76: 0.008532034417373978,\n",
       " 78: 0.005161159717014806,\n",
       " 124: 0.005318558324195928,\n",
       " 127: 0.005162818499221874,\n",
       " 128: 0.04182340890327744,\n",
       " 132: 0.0006142084883776911,\n",
       " 136: 0.029908804568133215,\n",
       " 137: 0.007608369941513495,\n",
       " 138: 0.0018439582489806986,\n",
       " 140: 0.005635455054636893,\n",
       " 141: 0.003508837462461038,\n",
       " 142: 0.0054399660833507535,\n",
       " 144: 0.005380207671017576,\n",
       " 146: 0.003349665650622614,\n",
       " 149: 0.013335614036781353,\n",
       " 150: 0.0037389678746941922,\n",
       " 2: 0.0014841414398438877,\n",
       " 4: 0.005601547904962056,\n",
       " 12: 0.0022145380592926917,\n",
       " 23: 0.007069790407352581,\n",
       " 25: 0.002106245153105932,\n",
       " 29: 0.004206110486151652,\n",
       " 37: 0.004568985921306486,\n",
       " 39: 0.0014983743558867318,\n",
       " 41: 0.0005227343406809644,\n",
       " 51: 0.003896437007831852,\n",
       " 53: 0.0005995189616241392,\n",
       " 55: 0.0005876999528772882,\n",
       " 61: 0.0019867297072952376,\n",
       " 63: 0.0076506130403236755,\n",
       " 65: 0.0054845362486228896,\n",
       " 67: 0.011689723618253864,\n",
       " 73: 3.835473216571253e-05,\n",
       " 75: 0.0009175794344903896,\n",
       " 77: 0.0060883307339105,\n",
       " 89: 0.015726562929594266,\n",
       " 99: 0.0016483307427330397,\n",
       " 102: 0.00975490125395273,\n",
       " 116: 0.020227222557790685,\n",
       " 123: 0.0007782382107034027,\n",
       " 125: 0.011238025155445398,\n",
       " 126: 0.0015478766099794854,\n",
       " 129: 0.010046650710955903,\n",
       " 133: 0.00046978570270549326,\n",
       " 139: 0.0023656365600201474,\n",
       " 143: 0.0025645031158175215,\n",
       " 145: 0.0006521944130865152,\n",
       " 147: 0.0005397247383183809,\n",
       " 148: 0.001926813824890946,\n",
       " 151: 0.009896061100178594,\n",
       " 52: 0.0030864808795741704,\n",
       " 69: 0.0008720716283555544,\n",
       " 96: 0.007580472819521887,\n",
       " 97: 0.014825169750779408,\n",
       " 113: 0.005375885350805389,\n",
       " 40: 0.0025782698498979083,\n",
       " 90: 0.000210618643759883,\n",
       " 122: 0.0013276413596591083,\n",
       " 108: 0.0019425354558328643,\n",
       " 131: 0.0,\n",
       " 68: 0.0001325823678843579,\n",
       " 74: 0.00031022172704714776,\n",
       " 80: 0.0009414090965113266,\n",
       " 100: 0.024370395000978356,\n",
       " 19: 0.0,\n",
       " 81: 0.005121946733710608,\n",
       " 87: 0.00026380939315850667,\n",
       " 101: 0.0016675201348189993,\n",
       " 85: 0.0010110453722992822,\n",
       " 91: 0.0026746441323752335,\n",
       " 95: 0.007959587537074665,\n",
       " 121: 0.003183637733980184,\n",
       " 88: 0.013285216408418865,\n",
       " 114: 0.0002069594053288157,\n",
       " 82: 0.006675942119901537,\n",
       " 92: 0.0007148447267817041,\n",
       " 115: 0.002141630931762679,\n",
       " 83: 0.0006933847588082455,\n",
       " 84: 0.0005547363616965757,\n",
       " 79: 0.0,\n",
       " 44: 0.0,\n",
       " 45: 0.0,\n",
       " 48: 0.0,\n",
       " 105: 0.004107689352970869,\n",
       " 98: 0.002052906669933353,\n",
       " 103: 0.013160487441804904,\n",
       " 120: 0.0003579062450427616,\n",
       " 109: 0.0005095266633874838,\n",
       " 118: 0.005312211155281468,\n",
       " 119: 0.000820049485951605,\n",
       " 70: 0.0,\n",
       " 71: 0.0,\n",
       " 130: 0.0,\n",
       " 111: 0.0,\n",
       " 112: 0.028603418437391417,\n",
       " 86: 0.0,\n",
       " 117: 0.0002272376349289329,\n",
       " 93: 0.013930580926884557,\n",
       " 104: 0.0004743853617295611,\n",
       " 106: 0.0,\n",
       " 110: 0.0,\n",
       " 134: 0.013060039905677489,\n",
       " 135: 0.0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.betweenness_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29abcfda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(nx.betweenness_centrality(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a21a45c5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a21a45c5",
    "outputId": "78d12c1f-40bc-4d27-9114-91b23aa37f41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Iterations:  10\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(salient_features)\n",
    "predicted_label = kmeans.labels_\n",
    "print('Number of Iterations: ', kmeans.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "r4pMZU70CW7z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r4pMZU70CW7z",
    "outputId": "7b36f8cc-3f86-467c-eb18-039437289c0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Centers:  [[-4.16666667e-01 -1.12490608e-02  6.77980650e-02  1.05648660e-02\n",
      "  -3.64523405e-03 -1.18386724e-02 -8.30185481e-03 -2.11062594e-02\n",
      "  -1.00279710e-02  8.38850923e-03 -8.40249361e-03 -8.14373591e-03\n",
      "  -7.35033779e-03 -3.48474946e-03 -1.92541212e-03 -1.66959100e-02\n",
      "   8.64306479e-02 -2.32171334e-04 -3.89375997e-02 -9.89377512e-03\n",
      "  -4.78131333e-03 -5.39271554e-03 -1.69750674e-03  2.34906218e-02\n",
      "   1.05616485e-02 -5.73532690e-02 -2.74300937e-03 -1.03399780e-02\n",
      "   8.59845589e-02  7.02793902e-02 -2.19670122e-02  7.79994721e-02\n",
      "  -1.24277887e-02 -1.12954979e-01 -3.28154472e-02 -1.76429055e-03\n",
      "  -3.87764755e-02 -1.44105546e-01  7.07704430e-02 -1.17681573e-02\n",
      "  -1.12392753e-02  1.87411576e-02 -1.89196563e-03  4.49203978e-02\n",
      "  -2.73938867e-02  2.10222412e-02 -1.01036413e-02 -1.37113437e-03\n",
      "   4.52603377e-02 -3.12747258e-02  3.71309722e-02 -2.48084979e-02\n",
      "   1.72930886e-02  4.49900306e-02  7.36356483e-03 -6.30517346e-02\n",
      "  -7.58912273e-02 -2.06363534e-02  7.35923949e-02 -4.44141371e-03\n",
      "   1.36176825e-01  2.78760998e-02 -8.20255327e-04  5.11190110e-03\n",
      "  -3.46845652e-03 -1.43902108e-03  4.03429126e-04 -7.62422545e-03\n",
      "   3.00454577e-03 -3.27867161e-03  8.95420149e-02 -1.98415942e-02\n",
      "  -4.18881047e-02  1.02369049e-01 -4.68959219e-02 -1.15055196e-02\n",
      "  -9.97674573e-03 -3.45933920e-02 -9.89416061e-02 -9.84893062e-03\n",
      "  -8.54744136e-04 -6.10684341e-02 -1.06523603e-02  6.09756098e-03\n",
      "  -2.11124804e-02 -4.82474841e-03 -7.69036446e-03 -2.53555841e-02\n",
      "  -1.33129403e-03 -7.61170985e-03 -6.95689840e-02 -1.16092626e-02\n",
      "   2.85251311e-02 -7.27312585e-03 -1.77754773e-02 -5.45142918e-02\n",
      "   2.82765779e-02  4.27904687e-02 -1.50233779e-02 -1.32984907e-02]\n",
      " [ 1.60714286e-01  3.91734171e-03 -3.72054319e-02 -1.44496187e-02\n",
      "   1.62039760e-03  4.03632283e-03  2.66858454e-03  4.64600508e-02\n",
      "   3.38444201e-03  6.12366246e-02  2.65435121e-03 -3.89645272e-03\n",
      "   2.61314457e-03  1.07707012e-03  1.00948018e-03  3.69327819e-02\n",
      "  -4.96302989e-02  3.80652036e-04  1.34709448e-02  3.44803095e-03\n",
      "   1.54228192e-02 -3.54414402e-03  9.72452459e-04 -1.97481447e-02\n",
      "  -4.29765377e-03  3.41961877e-02  1.03516996e-03  7.84948258e-02\n",
      "  -5.03112530e-02 -4.94858001e-02  1.24435042e-02 -1.44695697e-02\n",
      "   1.06886384e-02  4.70843339e-02  1.49329794e-02  4.82524659e-04\n",
      "   2.52513221e-02  8.08222462e-02 -1.40846497e-02  4.19973275e-03\n",
      "   3.87245939e-03 -6.92240955e-03  9.89704123e-04 -3.27314925e-02\n",
      "   1.68824302e-02 -2.09792138e-02  3.47255072e-03  6.89355425e-04\n",
      "  -3.21586508e-02  1.43397398e-02  1.23625207e-02  1.51056711e-02\n",
      "  -1.89192976e-02 -3.41202751e-02 -1.28330038e-02  1.45548136e-02\n",
      "   2.83506932e-02  4.56326450e-03 -5.21534150e-02  9.31875830e-04\n",
      "  -8.71466302e-02 -1.06000468e-02  6.20144937e-04 -1.73340051e-03\n",
      "   1.35153399e-03  5.89438263e-04  4.96022959e-05  2.57097637e-03\n",
      "  -9.52304058e-04  1.16769865e-03 -5.19727819e-02  1.47438295e-02\n",
      "   2.14791338e-02 -4.22930528e-02  2.48761480e-02  4.16224976e-03\n",
      "   3.31413246e-03  9.92573464e-03  3.79887917e-02  2.89206751e-03\n",
      "   8.44898550e-03  2.56249715e-02  3.51654455e-03  2.41071429e-01\n",
      "   1.76072972e-02  1.43689256e-03  2.83309222e-03  1.35635960e-02\n",
      "   5.41055939e-04  2.72711835e-03  1.10756936e-02  4.35666541e-03\n",
      "  -1.87274597e-02  2.40169478e-03  5.44393474e-03 -1.71482488e-01\n",
      "  -5.84721970e-03 -1.42786616e-02  5.25789285e-03  5.12385249e-03]\n",
      " [ 1.46969697e-01  4.39709737e-03 -1.26584814e-02  6.83671166e-03\n",
      "   1.06749692e-03  4.71548166e-03  3.47155114e-03 -3.15710220e-02\n",
      "   4.02941925e-03 -6.86032701e-02  3.56106491e-03  1.00380823e-02\n",
      "   2.81868643e-03  1.50106911e-03  4.07472856e-04 -2.51582451e-02\n",
      "  -1.38974513e-02 -2.14499806e-04  1.53103396e-02  3.86463721e-03\n",
      "  -1.21389823e-02  7.62860731e-03  2.75280704e-04  2.59601106e-03\n",
      "  -3.49743595e-03  7.93631851e-03  9.90797577e-04 -7.22140209e-02\n",
      "  -1.28715772e-02 -2.00454899e-03  3.70565937e-03 -4.34124082e-02\n",
      "  -1.61862571e-03  3.62623897e-02  9.25793623e-03  8.23900578e-04\n",
      "   3.19566287e-03  2.51323923e-02 -3.84154142e-02  4.49653485e-03\n",
      "   4.43550111e-03 -6.92240955e-03  4.02675638e-04 -1.59504172e-04\n",
      "   3.23151387e-03  5.68952882e-03  3.99611729e-03  3.20229185e-04\n",
      "  -9.96170977e-04  8.71342414e-03 -4.02667458e-02  3.11328779e-03\n",
      "   6.37207334e-03  1.20262100e-03  7.57712826e-03  3.21827556e-02\n",
      "   2.77072999e-02  1.07372305e-02 -1.75812640e-03  2.36205301e-03\n",
      "  -1.27825191e-02 -9.98759044e-03 -1.99572371e-05 -2.04577303e-03\n",
      "   1.20946934e-03  4.72569485e-04 -3.51242232e-04  3.06579213e-03\n",
      "  -1.27013363e-03  1.25517112e-03 -1.38317604e-02 -2.20892586e-04\n",
      "   9.35601455e-03 -3.32494558e-02  9.63033655e-03  4.33891483e-03\n",
      "   4.06282104e-03  1.56815988e-02  3.50769730e-02  4.39727954e-03\n",
      "  -7.96543052e-03  1.94328618e-02  4.36036869e-03 -2.50000000e-01\n",
      "  -2.18903535e-03  2.13361276e-03  2.84821415e-03  5.09122863e-03\n",
      "   4.41525868e-04  2.89748139e-03  4.05834454e-02  4.21830007e-03\n",
      "  -2.19622969e-03  2.97642277e-03  7.70789499e-03  2.15238278e-01\n",
      "  -1.51253707e-02 -1.73600758e-02  5.84575440e-03  4.69640692e-03]]\n"
     ]
    }
   ],
   "source": [
    "print('Cluster Centers: ', kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "BRGO62KOCXHz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BRGO62KOCXHz",
    "outputId": "0b9455a8-9230-4cda-a5d9-e77d91567a48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inertia:  135.0862500161339\n"
     ]
    }
   ],
   "source": [
    "print('Inertia: ', kmeans.inertia_) # SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "19f946f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "19f946f0",
    "outputId": "aad613b6-c8c5-48f9-f627-6c35841e57f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans accuracy for 3 classes:  0.625\n"
     ]
    }
   ],
   "source": [
    "compared_classes = np.array([])\n",
    "for i in classes.iterrows():\n",
    "    if i[1]['adenoma']==1:\n",
    "        compared_classes = np.append(compared_classes, 2)\n",
    "    elif i[1]['hyperplasic']==1:\n",
    "        compared_classes = np.append(compared_classes, 0)\n",
    "    else:\n",
    "        compared_classes = np.append(compared_classes, 1)\n",
    "print('KMeans accuracy for 3 classes: ', np.count_nonzero(compared_classes==predicted_label)/ len(predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5069e44",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d5069e44",
    "outputId": "75f13e25-4a43-4223-d281-e5f46e45e42b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Iterations:  5\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(salient_features)\n",
    "predicted_label = kmeans.labels_\n",
    "print('Number of Iterations: ', kmeans.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "kEgc-bXBCeHP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kEgc-bXBCeHP",
    "outputId": "44874d44-ad8a-44e7-dd55-1a3b06b87c15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Centers:  [[-3.16666667e-01 -1.64343827e-02  5.50725818e-02  1.41013705e-02\n",
      "  -5.05155019e-03 -1.62280447e-02 -1.44529404e-02 -2.98342938e-02\n",
      "  -1.53839183e-02  4.25953920e-03 -3.86170184e-02 -8.14373591e-03\n",
      "  -1.42764601e-02 -1.13541303e-02  3.34851961e-03 -7.56246863e-03\n",
      "   7.01458389e-02  2.24311503e-03 -3.00878922e-02 -1.58679609e-02\n",
      "  -1.52066541e-02  8.15512823e-03  3.12004364e-03  3.77982259e-02\n",
      "  -3.67281909e-02 -5.05873077e-02 -5.58471499e-03 -2.19173105e-02\n",
      "   9.45867158e-02  8.14247122e-02 -1.75401026e-02  6.41899414e-02\n",
      "  -1.19632155e-02 -1.13939102e-01 -4.61272869e-02 -6.86666240e-03\n",
      "  -2.79616572e-02 -1.24290489e-01  5.80147556e-02 -1.54352689e-02\n",
      "  -1.59772484e-02  1.41217155e-02  1.18575198e-03  3.77400569e-02\n",
      "  -2.49601399e-02  2.75926042e-02 -1.43358750e-02  4.48727789e-03\n",
      "   3.78028715e-02 -2.89430892e-02  2.26614803e-02 -2.10109630e-02\n",
      "   2.94406403e-02  3.80374332e-02  1.75203810e-02 -2.90474345e-02\n",
      "  -6.91067117e-02 -1.66208272e-02  6.51595429e-02 -3.30704506e-02\n",
      "   1.14626151e-01 -4.42505857e-02 -1.55027169e-03  1.11303515e-02\n",
      "  -3.46888093e-02  1.08130097e-04  6.21991532e-03 -3.51159140e-02\n",
      "   8.89727583e-03 -1.06111320e-02  7.30803587e-02 -1.98848576e-02\n",
      "  -3.67573450e-02  8.82292133e-02 -6.02313874e-02 -2.53936986e-02\n",
      "  -4.16835234e-02 -1.03399395e-01 -1.04723635e-01 -3.29400530e-02\n",
      "  -1.29884465e-02 -4.02544501e-02 -3.37214146e-02 -2.00000000e-02\n",
      "  -3.67745813e-02 -1.36074747e-02 -2.50035034e-02 -3.37963889e-02\n",
      "  -2.22673302e-03 -3.78590573e-02 -4.62112349e-02 -1.80059463e-02\n",
      "   3.37144540e-02 -3.28641429e-02 -5.22769381e-03 -4.41533605e-03\n",
      "   2.17657387e-02 -4.62337226e-02 -2.02871418e-02  8.86159767e-04]\n",
      " [ 1.55228758e-01  8.05606996e-03 -2.69963636e-02 -6.91243651e-03\n",
      "   2.47625009e-03  7.95492385e-03  7.08477468e-03  1.46246538e-02\n",
      "   7.54113641e-03 -2.08800941e-03  1.89299110e-02  3.99202741e-03\n",
      "   6.99826475e-03  5.56575014e-03 -1.64143118e-03  3.70709247e-03\n",
      "  -3.43852152e-02 -1.09956619e-03  1.47489668e-02  7.77841222e-03\n",
      "   7.45424220e-03 -3.99761188e-03 -1.52943316e-03 -1.85285421e-02\n",
      "   1.80040151e-02  2.47976998e-02  2.73760539e-03  1.07437797e-02\n",
      "  -4.63660372e-02 -3.99140746e-02  8.59808952e-03 -3.14656576e-02\n",
      "   5.86432132e-03  5.58525008e-02  2.26114151e-02  3.36601098e-03\n",
      "   1.37066947e-02  6.09267105e-02 -2.84386057e-02  7.56630830e-03\n",
      "   7.83198449e-03 -6.92240955e-03 -5.81250971e-04 -1.85000279e-02\n",
      "   1.22353627e-02 -1.35257864e-02  7.02738968e-03 -2.19964603e-03\n",
      "  -1.85308194e-02  1.41877888e-02 -1.11085688e-02  1.02994917e-02\n",
      "  -1.44316864e-02 -1.86458006e-02 -8.58842206e-03  1.42389385e-02\n",
      "   3.38758391e-02  8.14746432e-03 -3.19409524e-02  1.62110052e-02\n",
      "  -5.61892897e-02  2.16914636e-02  7.59937101e-04 -5.45605467e-03\n",
      "   1.70043183e-02 -5.30049495e-05 -3.04897810e-03  1.72136833e-02\n",
      "  -4.36140972e-03  5.20153530e-03 -3.58237052e-02  9.74747921e-03\n",
      "   1.80183064e-02 -4.32496144e-02  2.95251899e-02  1.24478915e-02\n",
      "   2.04330997e-02  5.06859778e-02  5.13351153e-02  1.61470848e-02\n",
      "   6.36688552e-03  1.97325736e-02  1.65301052e-02  9.80392157e-03\n",
      "   1.80267555e-02  6.67033074e-03  1.22566193e-02  1.65668573e-02\n",
      "   1.09153579e-03  1.85583614e-02  2.26525661e-02  8.82644427e-03\n",
      "  -1.65266932e-02  1.61098740e-02  2.56259500e-03  2.16438042e-03\n",
      "  -1.06694798e-02  2.26635895e-02  9.94467735e-03 -4.34392043e-04]]\n"
     ]
    }
   ],
   "source": [
    "print('Cluster Centers: ', kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "RV1oqdgtCgR1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RV1oqdgtCgR1",
    "outputId": "4c21a7d9-e683-4af6-fd15-09a2caead313"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inertia:  147.65095104199597\n"
     ]
    }
   ],
   "source": [
    "print('Inertia: ', kmeans.inertia_) # SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4bd2148b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4bd2148b",
    "outputId": "e30f7edf-5e12-4e0a-9bfc-0737a13cbccf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans accuracy for 2 classes:  0.9342105263157895\n"
     ]
    }
   ],
   "source": [
    "compared_classes = np.array([])\n",
    "for i in classes.iterrows():\n",
    "    if i[1]['adenoma']==1:\n",
    "        compared_classes = np.append(compared_classes, 1)\n",
    "    elif i[1]['hyperplasic']==1:\n",
    "        compared_classes = np.append(compared_classes, 0)\n",
    "    else:\n",
    "        compared_classes = np.append(compared_classes, 1)\n",
    "print('KMeans accuracy for 2 classes: ', np.count_nonzero(compared_classes==predicted_label)/ len(predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2c92d9eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "2c92d9eb",
    "outputId": "978e178b-2a77-4f0e-e96f-acd030ed24d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "color_map_cluster = np.array([])\n",
    "for node in G:\n",
    "    if (predicted_label[node]==0):\n",
    "        color_map_cluster = np.append(color_map_cluster, 'red')\n",
    "    elif (predicted_label[node]==1):\n",
    "        color_map_cluster = np.append(color_map_cluster, 'blue')\n",
    "    else:\n",
    "        color_map_cluster = np.append(color_map_cluster, 'yellow')\n",
    "nx.draw(G, node_color=color_map_cluster)\n",
    "plt.plot()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MLPColonoscopy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
