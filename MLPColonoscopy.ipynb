{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ef3116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from IPython.utils import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b2a82fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('Dataset/gastrointestinal_colonoscopy_lesions_dataset.csv')\n",
    "features = features.T\n",
    "class_label = pd.Series(features.index)\n",
    "features.index = range(features.shape[0])\n",
    "classes = np.zeros((features.shape[0], 3))\n",
    "for i in range(classes.shape[0]):\n",
    "    if 'adenoma' in class_label[i]:\n",
    "        classes[i,0] = 1.0\n",
    "        class_label[i] = 0\n",
    "    elif 'serrated' in class_label[i]:\n",
    "        classes[i,2] = 1.0\n",
    "        class_label[i] = 2\n",
    "    else:\n",
    "        classes[i,1] = 1.0\n",
    "        class_label[i] = 1\n",
    "classes = {'adenoma': classes[:,0], 'hyperplasic': classes[:,1], 'serrated': classes[:,2]}\n",
    "classes = pd.DataFrame(classes)\n",
    "class_label = class_label.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d3a520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in features.columns:\n",
    "    if features[col].abs().max()==0:\n",
    "        continue\n",
    "    features[col] = (features[col] - features[col].mean())/features[col].abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb3de32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 7)                 4907      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,965\n",
      "Trainable params: 4,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    \n",
    "    InputLayer(input_shape=(features.shape[1])),\n",
    "    \n",
    "    Dense(7, activation='sigmoid'),\n",
    "    \n",
    "    Dense(5, activation='sigmoid'),\n",
    "    \n",
    "    Dense(3, activation='relu')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "model.summary()\n",
    "model.save_weights('model_weights/initial_weights_colonoscopy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "406c8d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-cbf2c7ffa279>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_weights/initial_weights_colonoscopy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcaptured\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mj\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m-> 2955\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3243\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3244\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonicalize_function_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3245\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3246\u001b[0m       \u001b[0mflat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcanonicalize_function_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2766\u001b[0;31m       \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_numpy_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2767\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_numpy_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2768\u001b[0m       \u001b[0mflat_inputs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mflat_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_convert_numpy_inputs\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   2784\u001b[0m   \u001b[0;31m# are eventually passed to ConcreteFunction()._call_flat, which requires\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2785\u001b[0m   \u001b[0;31m# expanded composites.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2786\u001b[0;31m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2788\u001b[0m   \u001b[0;31m# Check for NumPy arrays in arguments and convert them to Tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mflatten\u001b[0;34m(structure, expand_composites)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m   \u001b[0mexpand_composites\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_to_components\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_components\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0muse_anonymous_iterator_v3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36muse_anonymous_iterator_v3\u001b[0;34m()\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0muse_anonymous_iterator_v3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m   return (forward_compat.forward_compatible(2022, 1, 6) or\n\u001b[0m\u001b[1;32m    702\u001b[0m           context.run_eager_op_as_function_enabled())\n\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/compat/compat.py\u001b[0m in \u001b[0;36mforward_compatible\u001b[0;34m(year, month, day)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0msource\u001b[0m \u001b[0mcode\u001b[0m \u001b[0mafter\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mday\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m   \"\"\"\n\u001b[0;32m--> 121\u001b[0;31m   return _FORWARD_COMPATIBILITY_DATE_NUMBER > _date_to_date_number(\n\u001b[0m\u001b[1;32m    122\u001b[0m       year, month, day)\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "j = 0\n",
    "for train_index, test_index in LeaveOneOut().split(features):\n",
    "    x_train, x_test = features.iloc[train_index,:], features.iloc[test_index,:]\n",
    "    y_train, y_test = classes.iloc[train_index,:], classes.iloc[test_index,:]\n",
    "    model.load_weights('model_weights/initial_weights_colonoscopy')\n",
    "    with io.capture_output() as captured:\n",
    "        model.fit(x_train, y_train, epochs=500)\n",
    "    acc += model.evaluate(x_test, y_test)[1]\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe3a4412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.743421052631579"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc/j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4978bff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6567 - accuracy: 0.5263\n",
      "Epoch 2/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6253 - accuracy: 0.5263\n",
      "Epoch 3/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6052 - accuracy: 0.5263\n",
      "Epoch 4/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5901 - accuracy: 0.5263\n",
      "Epoch 5/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.5263\n",
      "Epoch 6/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.5263\n",
      "Epoch 7/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.5263\n",
      "Epoch 8/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.5263\n",
      "Epoch 9/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.5263\n",
      "Epoch 10/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.5263\n",
      "Epoch 11/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.5263\n",
      "Epoch 12/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.5263\n",
      "Epoch 13/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.5263\n",
      "Epoch 14/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.5263\n",
      "Epoch 15/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5316 - accuracy: 0.5263\n",
      "Epoch 16/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.5263\n",
      "Epoch 17/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.5263\n",
      "Epoch 18/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.5263\n",
      "Epoch 19/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.5263\n",
      "Epoch 20/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.5263\n",
      "Epoch 21/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.5197\n",
      "Epoch 22/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.5197\n",
      "Epoch 23/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.5197\n",
      "Epoch 24/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.5197\n",
      "Epoch 25/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.5197\n",
      "Epoch 26/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.5263\n",
      "Epoch 27/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.5329\n",
      "Epoch 28/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5010 - accuracy: 0.5329\n",
      "Epoch 29/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.5329\n",
      "Epoch 30/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4969 - accuracy: 0.5395\n",
      "Epoch 31/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.5395\n",
      "Epoch 32/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.5461\n",
      "Epoch 33/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.5461\n",
      "Epoch 34/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.5461\n",
      "Epoch 35/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.5461\n",
      "Epoch 36/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.5526\n",
      "Epoch 37/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.5526\n",
      "Epoch 38/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.5526\n",
      "Epoch 39/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.5526\n",
      "Epoch 40/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.5592\n",
      "Epoch 41/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.5526\n",
      "Epoch 42/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.5526\n",
      "Epoch 43/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.5526\n",
      "Epoch 44/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.5526\n",
      "Epoch 45/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.5526\n",
      "Epoch 46/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.5526\n",
      "Epoch 47/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.5526\n",
      "Epoch 48/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.5526\n",
      "Epoch 49/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.5526\n",
      "Epoch 50/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.5526\n",
      "Epoch 51/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.5526\n",
      "Epoch 52/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.5526\n",
      "Epoch 53/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.5526\n",
      "Epoch 54/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.5526\n",
      "Epoch 55/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.5592\n",
      "Epoch 56/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.5658\n",
      "Epoch 57/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.5658\n",
      "Epoch 58/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.5724\n",
      "Epoch 59/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.5724\n",
      "Epoch 60/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.5724\n",
      "Epoch 61/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.5724\n",
      "Epoch 62/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.5789\n",
      "Epoch 63/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.5658\n",
      "Epoch 64/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.5789\n",
      "Epoch 65/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.5855\n",
      "Epoch 66/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.5921\n",
      "Epoch 67/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.5921\n",
      "Epoch 68/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.5987\n",
      "Epoch 69/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.6053\n",
      "Epoch 70/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.6250\n",
      "Epoch 71/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.6250\n",
      "Epoch 72/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.6316\n",
      "Epoch 73/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.6447\n",
      "Epoch 74/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4114 - accuracy: 0.6645\n",
      "Epoch 75/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.6711\n",
      "Epoch 76/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4076 - accuracy: 0.6908\n",
      "Epoch 77/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.7039\n",
      "Epoch 78/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4039 - accuracy: 0.7237\n",
      "Epoch 79/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4022 - accuracy: 0.7303\n",
      "Epoch 80/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4003 - accuracy: 0.7500\n",
      "Epoch 81/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.7500\n",
      "Epoch 82/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3965 - accuracy: 0.7566\n",
      "Epoch 83/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.7697\n",
      "Epoch 84/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3929 - accuracy: 0.7697\n",
      "Epoch 85/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.7763\n",
      "Epoch 86/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.7829\n",
      "Epoch 87/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.7895\n",
      "Epoch 88/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3853 - accuracy: 0.7895\n",
      "Epoch 89/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3833 - accuracy: 0.7961\n",
      "Epoch 90/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3814 - accuracy: 0.8158\n",
      "Epoch 91/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3793 - accuracy: 0.8092\n",
      "Epoch 92/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3773 - accuracy: 0.8092\n",
      "Epoch 93/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8158\n",
      "Epoch 94/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8224\n",
      "Epoch 95/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8224\n",
      "Epoch 96/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8289\n",
      "Epoch 97/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8289\n",
      "Epoch 98/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8289\n",
      "Epoch 99/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8289\n",
      "Epoch 100/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8289\n",
      "Epoch 101/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8355\n",
      "Epoch 102/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3564 - accuracy: 0.8355\n",
      "Epoch 103/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.8355\n",
      "Epoch 104/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.8355\n",
      "Epoch 105/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3498 - accuracy: 0.8487\n",
      "Epoch 106/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3476 - accuracy: 0.8553\n",
      "Epoch 107/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3455 - accuracy: 0.8553\n",
      "Epoch 108/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3435 - accuracy: 0.8553\n",
      "Epoch 109/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8684\n",
      "Epoch 110/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3386 - accuracy: 0.8618\n",
      "Epoch 111/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.8618\n",
      "Epoch 112/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8618\n",
      "Epoch 113/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8684\n",
      "Epoch 114/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8750\n",
      "Epoch 115/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8750\n",
      "Epoch 116/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3249 - accuracy: 0.8750\n",
      "Epoch 117/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3226 - accuracy: 0.8750\n",
      "Epoch 118/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3202 - accuracy: 0.8816\n",
      "Epoch 119/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3179 - accuracy: 0.8816\n",
      "Epoch 120/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3154 - accuracy: 0.8882\n",
      "Epoch 121/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3133 - accuracy: 0.8947\n",
      "Epoch 122/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3109 - accuracy: 0.8882\n",
      "Epoch 123/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3087 - accuracy: 0.8947\n",
      "Epoch 124/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3063 - accuracy: 0.8947\n",
      "Epoch 125/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3039 - accuracy: 0.8947\n",
      "Epoch 126/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3016 - accuracy: 0.8947\n",
      "Epoch 127/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2994 - accuracy: 0.8947\n",
      "Epoch 128/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.8947\n",
      "Epoch 129/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2947 - accuracy: 0.8947\n",
      "Epoch 130/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2926 - accuracy: 0.9013\n",
      "Epoch 131/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2900 - accuracy: 0.9013\n",
      "Epoch 132/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2878 - accuracy: 0.9079\n",
      "Epoch 133/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2855 - accuracy: 0.9013\n",
      "Epoch 134/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2832 - accuracy: 0.9079\n",
      "Epoch 135/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2808 - accuracy: 0.9079\n",
      "Epoch 136/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2787 - accuracy: 0.9079\n",
      "Epoch 137/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2765 - accuracy: 0.9013\n",
      "Epoch 138/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2742 - accuracy: 0.9013\n",
      "Epoch 139/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2719 - accuracy: 0.9013\n",
      "Epoch 140/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2696 - accuracy: 0.9013\n",
      "Epoch 141/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2673 - accuracy: 0.9013\n",
      "Epoch 142/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2651 - accuracy: 0.9013\n",
      "Epoch 143/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2628 - accuracy: 0.9013\n",
      "Epoch 144/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2606 - accuracy: 0.9013\n",
      "Epoch 145/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2586 - accuracy: 0.9013\n",
      "Epoch 146/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2563 - accuracy: 0.9013\n",
      "Epoch 147/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2541 - accuracy: 0.9013\n",
      "Epoch 148/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2519 - accuracy: 0.9079\n",
      "Epoch 149/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2496 - accuracy: 0.9145\n",
      "Epoch 150/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2477 - accuracy: 0.9079\n",
      "Epoch 151/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.9145\n",
      "Epoch 152/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2435 - accuracy: 0.9079\n",
      "Epoch 153/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2411 - accuracy: 0.9079\n",
      "Epoch 154/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2388 - accuracy: 0.9145\n",
      "Epoch 155/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2367 - accuracy: 0.9211\n",
      "Epoch 156/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2346 - accuracy: 0.9211\n",
      "Epoch 157/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2327 - accuracy: 0.9276\n",
      "Epoch 158/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2304 - accuracy: 0.9342\n",
      "Epoch 159/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2283 - accuracy: 0.9342\n",
      "Epoch 160/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2262 - accuracy: 0.9342\n",
      "Epoch 161/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2243 - accuracy: 0.9342\n",
      "Epoch 162/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2222 - accuracy: 0.9342\n",
      "Epoch 163/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2200 - accuracy: 0.9342\n",
      "Epoch 164/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2179 - accuracy: 0.9408\n",
      "Epoch 165/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2159 - accuracy: 0.9408\n",
      "Epoch 166/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2139 - accuracy: 0.9408\n",
      "Epoch 167/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2118 - accuracy: 0.9408\n",
      "Epoch 168/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2098 - accuracy: 0.9408\n",
      "Epoch 169/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2078 - accuracy: 0.9408\n",
      "Epoch 170/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2058 - accuracy: 0.9408\n",
      "Epoch 171/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2038 - accuracy: 0.9408\n",
      "Epoch 172/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2018 - accuracy: 0.9408\n",
      "Epoch 173/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1998 - accuracy: 0.9408\n",
      "Epoch 174/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1978 - accuracy: 0.9408\n",
      "Epoch 175/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1958 - accuracy: 0.9474\n",
      "Epoch 176/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1939 - accuracy: 0.9474\n",
      "Epoch 177/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1920 - accuracy: 0.9474\n",
      "Epoch 178/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1899 - accuracy: 0.9474\n",
      "Epoch 179/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1879 - accuracy: 0.9474\n",
      "Epoch 180/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 0.9474\n",
      "Epoch 181/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1841 - accuracy: 0.9539\n",
      "Epoch 182/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.9539\n",
      "Epoch 183/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1802 - accuracy: 0.9539\n",
      "Epoch 184/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1784 - accuracy: 0.9539\n",
      "Epoch 185/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1764 - accuracy: 0.9539\n",
      "Epoch 186/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1744 - accuracy: 0.9539\n",
      "Epoch 187/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1725 - accuracy: 0.9605\n",
      "Epoch 188/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1707 - accuracy: 0.9605\n",
      "Epoch 189/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1687 - accuracy: 0.9605\n",
      "Epoch 190/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1670 - accuracy: 0.9605\n",
      "Epoch 191/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1650 - accuracy: 0.9539\n",
      "Epoch 192/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1631 - accuracy: 0.9605\n",
      "Epoch 193/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1613 - accuracy: 0.9605\n",
      "Epoch 194/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1595 - accuracy: 0.9605\n",
      "Epoch 195/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1577 - accuracy: 0.9605\n",
      "Epoch 196/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1560 - accuracy: 0.9605\n",
      "Epoch 197/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1542 - accuracy: 0.9605\n",
      "Epoch 198/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1524 - accuracy: 0.9605\n",
      "Epoch 199/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1505 - accuracy: 0.9671\n",
      "Epoch 200/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1488 - accuracy: 0.9737\n",
      "Epoch 201/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1471 - accuracy: 0.9737\n",
      "Epoch 202/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9737\n",
      "Epoch 203/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1438 - accuracy: 0.9737\n",
      "Epoch 204/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1422 - accuracy: 0.9737\n",
      "Epoch 205/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1402 - accuracy: 0.9737\n",
      "Epoch 206/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1387 - accuracy: 0.9737\n",
      "Epoch 207/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1369 - accuracy: 0.9737\n",
      "Epoch 208/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1352 - accuracy: 0.9737\n",
      "Epoch 209/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1339 - accuracy: 0.9803\n",
      "Epoch 210/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1320 - accuracy: 0.9803\n",
      "Epoch 211/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1303 - accuracy: 0.9803\n",
      "Epoch 212/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1285 - accuracy: 0.9803\n",
      "Epoch 213/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1273 - accuracy: 0.9803\n",
      "Epoch 214/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1254 - accuracy: 0.9803\n",
      "Epoch 215/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1240 - accuracy: 0.9868\n",
      "Epoch 216/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1222 - accuracy: 0.9868\n",
      "Epoch 217/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1206 - accuracy: 0.9868\n",
      "Epoch 218/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1189 - accuracy: 0.9868\n",
      "Epoch 219/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1174 - accuracy: 0.9868\n",
      "Epoch 220/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1159 - accuracy: 0.9868\n",
      "Epoch 221/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1144 - accuracy: 0.9868\n",
      "Epoch 222/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1128 - accuracy: 0.9868\n",
      "Epoch 223/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1111 - accuracy: 0.9868\n",
      "Epoch 224/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1098 - accuracy: 0.9868\n",
      "Epoch 225/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1081 - accuracy: 0.9868\n",
      "Epoch 226/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1066 - accuracy: 0.9868\n",
      "Epoch 227/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1051 - accuracy: 0.9868\n",
      "Epoch 228/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1038 - accuracy: 0.9868\n",
      "Epoch 229/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1021 - accuracy: 0.9868\n",
      "Epoch 230/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1007 - accuracy: 0.9868\n",
      "Epoch 231/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0993 - accuracy: 0.9868\n",
      "Epoch 232/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0979 - accuracy: 0.9868\n",
      "Epoch 233/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0964 - accuracy: 0.9868\n",
      "Epoch 234/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0951 - accuracy: 0.9868\n",
      "Epoch 235/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0939 - accuracy: 0.9868\n",
      "Epoch 236/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0923 - accuracy: 0.9934\n",
      "Epoch 237/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0909 - accuracy: 0.9934\n",
      "Epoch 238/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0895 - accuracy: 0.9934\n",
      "Epoch 239/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0882 - accuracy: 0.9934\n",
      "Epoch 240/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0871 - accuracy: 0.9934\n",
      "Epoch 241/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0857 - accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0842 - accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0832 - accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0804 - accuracy: 1.0000\n",
      "Epoch 246/500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0791 - accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0778 - accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0766 - accuracy: 1.0000\n",
      "Epoch 249/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0754 - accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0740 - accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0729 - accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0706 - accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0692 - accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0615 - accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0571 - accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 1.0000\n",
      "Epoch 268/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0542 - accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0531 - accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0521 - accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0493 - accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0484 - accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0475 - accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0450 - accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0443 - accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0435 - accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0427 - accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0405 - accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0399 - accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0371 - accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0319 - accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0308 - accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0301 - accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0294 - accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0289 - accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0283 - accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0277 - accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0272 - accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0267 - accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0256 - accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0251 - accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0204 - accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0183 - accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0180 - accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0176 - accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0168 - accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 1.0000\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 413/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.7484e-04 - accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.6294e-04 - accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.1746e-04 - accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.0346e-04 - accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.6133e-04 - accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.5076e-04 - accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.2365e-04 - accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.0993e-04 - accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.7774e-04 - accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.4615e-04 - accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.2606e-04 - accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.9412e-04 - accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.8598e-04 - accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.6454e-04 - accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.3484e-04 - accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.7592e-04 - accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.7963e-04 - accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.4908e-04 - accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.2881e-04 - accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.0360e-04 - accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.8121e-04 - accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.6733e-04 - accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.7241e-04 - accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.3606e-04 - accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.2085e-04 - accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.9323e-04 - accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.9997e-04 - accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.6178e-04 - accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.5488e-04 - accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.3193e-04 - accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.2001e-04 - accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.9982e-04 - accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.9297e-04 - accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.8266e-04 - accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.6282e-04 - accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.5022e-04 - accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.3750e-04 - accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.2309e-04 - accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.2124e-04 - accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.0496e-04 - accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9767e-04 - accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.8120e-04 - accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.7565e-04 - accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.6417e-04 - accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.4738e-04 - accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.2895e-04 - accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.3222e-04 - accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1162e-04 - accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1530e-04 - accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0033e-04 - accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.9547e-05 - accuracy: 1.0000\n",
      "Epoch 493/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 8.0347e-05 - accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 8.5282e-05 - accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.6731e-05 - accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.8989e-05 - accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.9073e-05 - accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.7544e-05 - accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.7548e-05 - accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.8832e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f88604c7a60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(features, classes, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46c38512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [06:37<00:00,  1.76it/s]\n"
     ]
    }
   ],
   "source": [
    "grad_sum = 0\n",
    "for col_name in tqdm(features.columns):\n",
    "    pointFrame = features.loc[:, features.columns != col_name]\n",
    "    for i in features[col_name]:\n",
    "        pointFrame[col_name] = i*np.ones(len(features.index))\n",
    "        points = tf.Variable(pointFrame, dtype='float')\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = model(points, training=False)\n",
    "        grads = tape.gradient(pred, points)\n",
    "        grad_sum += np.abs(grads.numpy())\n",
    "saliency_order = np.argsort(-np.sum(np.abs(grad_sum), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5082fe64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>521</th>\n",
       "      <th>555</th>\n",
       "      <th>464</th>\n",
       "      <th>146</th>\n",
       "      <th>459</th>\n",
       "      <th>578</th>\n",
       "      <th>466</th>\n",
       "      <th>567</th>\n",
       "      <th>102</th>\n",
       "      <th>476</th>\n",
       "      <th>...</th>\n",
       "      <th>580</th>\n",
       "      <th>512</th>\n",
       "      <th>550</th>\n",
       "      <th>545</th>\n",
       "      <th>509</th>\n",
       "      <th>571</th>\n",
       "      <th>546</th>\n",
       "      <th>455</th>\n",
       "      <th>547</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.019545</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.156682</td>\n",
       "      <td>0.014037</td>\n",
       "      <td>-0.031571</td>\n",
       "      <td>0.004495</td>\n",
       "      <td>0.037353</td>\n",
       "      <td>-0.002092</td>\n",
       "      <td>0.034154</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>-0.006884</td>\n",
       "      <td>0.025033</td>\n",
       "      <td>0.020956</td>\n",
       "      <td>-0.016513</td>\n",
       "      <td>-0.000891</td>\n",
       "      <td>0.017661</td>\n",
       "      <td>-0.008144</td>\n",
       "      <td>0.019453</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.019545</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>-0.071990</td>\n",
       "      <td>0.009191</td>\n",
       "      <td>-0.031571</td>\n",
       "      <td>0.004495</td>\n",
       "      <td>0.278855</td>\n",
       "      <td>-0.002092</td>\n",
       "      <td>0.018739</td>\n",
       "      <td>-0.068907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>-0.006884</td>\n",
       "      <td>0.025033</td>\n",
       "      <td>0.020956</td>\n",
       "      <td>-0.016513</td>\n",
       "      <td>-0.000891</td>\n",
       "      <td>0.017661</td>\n",
       "      <td>-0.008144</td>\n",
       "      <td>0.019453</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.010090</td>\n",
       "      <td>-0.131291</td>\n",
       "      <td>0.008758</td>\n",
       "      <td>-0.031571</td>\n",
       "      <td>0.014783</td>\n",
       "      <td>0.171833</td>\n",
       "      <td>0.004874</td>\n",
       "      <td>-0.043517</td>\n",
       "      <td>-0.034020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007166</td>\n",
       "      <td>-0.019150</td>\n",
       "      <td>0.004244</td>\n",
       "      <td>0.007180</td>\n",
       "      <td>0.021233</td>\n",
       "      <td>0.008760</td>\n",
       "      <td>-0.007271</td>\n",
       "      <td>0.229704</td>\n",
       "      <td>0.012418</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.010090</td>\n",
       "      <td>-0.140440</td>\n",
       "      <td>0.066090</td>\n",
       "      <td>-0.031571</td>\n",
       "      <td>0.014783</td>\n",
       "      <td>-0.195110</td>\n",
       "      <td>0.004874</td>\n",
       "      <td>-0.021684</td>\n",
       "      <td>-0.027042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007166</td>\n",
       "      <td>-0.019150</td>\n",
       "      <td>0.004244</td>\n",
       "      <td>0.007180</td>\n",
       "      <td>0.021233</td>\n",
       "      <td>0.008760</td>\n",
       "      <td>-0.007271</td>\n",
       "      <td>-0.008144</td>\n",
       "      <td>0.012418</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.004381</td>\n",
       "      <td>-0.003327</td>\n",
       "      <td>-0.029781</td>\n",
       "      <td>-0.104275</td>\n",
       "      <td>-0.031571</td>\n",
       "      <td>0.006089</td>\n",
       "      <td>0.284429</td>\n",
       "      <td>0.002363</td>\n",
       "      <td>-0.049273</td>\n",
       "      <td>-0.013611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008576</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.029734</td>\n",
       "      <td>0.012956</td>\n",
       "      <td>-0.024416</td>\n",
       "      <td>0.011717</td>\n",
       "      <td>0.021297</td>\n",
       "      <td>-0.008144</td>\n",
       "      <td>0.018683</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.089982</td>\n",
       "      <td>0.009065</td>\n",
       "      <td>0.063551</td>\n",
       "      <td>-0.029268</td>\n",
       "      <td>-0.031571</td>\n",
       "      <td>-0.004344</td>\n",
       "      <td>0.280373</td>\n",
       "      <td>-0.014891</td>\n",
       "      <td>-0.066011</td>\n",
       "      <td>-0.059386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0.046772</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.018410</td>\n",
       "      <td>0.051588</td>\n",
       "      <td>-0.016223</td>\n",
       "      <td>0.006035</td>\n",
       "      <td>-0.008144</td>\n",
       "      <td>0.006751</td>\n",
       "      <td>-0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.019351</td>\n",
       "      <td>0.007854</td>\n",
       "      <td>-0.040653</td>\n",
       "      <td>-0.007182</td>\n",
       "      <td>0.586617</td>\n",
       "      <td>-0.001011</td>\n",
       "      <td>0.193040</td>\n",
       "      <td>0.017754</td>\n",
       "      <td>0.043483</td>\n",
       "      <td>-0.064848</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005173</td>\n",
       "      <td>0.005516</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.009247</td>\n",
       "      <td>-0.041244</td>\n",
       "      <td>0.012807</td>\n",
       "      <td>0.009186</td>\n",
       "      <td>-0.008144</td>\n",
       "      <td>0.009858</td>\n",
       "      <td>-0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.019351</td>\n",
       "      <td>0.007854</td>\n",
       "      <td>-0.026035</td>\n",
       "      <td>0.030283</td>\n",
       "      <td>-0.031571</td>\n",
       "      <td>-0.001011</td>\n",
       "      <td>-0.075700</td>\n",
       "      <td>0.017754</td>\n",
       "      <td>0.175669</td>\n",
       "      <td>-0.054389</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005173</td>\n",
       "      <td>0.005516</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.009247</td>\n",
       "      <td>-0.041244</td>\n",
       "      <td>0.012807</td>\n",
       "      <td>0.009186</td>\n",
       "      <td>-0.008144</td>\n",
       "      <td>0.009858</td>\n",
       "      <td>-0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.004470</td>\n",
       "      <td>-0.010036</td>\n",
       "      <td>-0.140440</td>\n",
       "      <td>-0.007820</td>\n",
       "      <td>-0.031571</td>\n",
       "      <td>0.011668</td>\n",
       "      <td>-0.195110</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>0.025620</td>\n",
       "      <td>-0.055482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009916</td>\n",
       "      <td>0.063362</td>\n",
       "      <td>-0.037031</td>\n",
       "      <td>-0.043478</td>\n",
       "      <td>0.039641</td>\n",
       "      <td>0.009538</td>\n",
       "      <td>-0.050214</td>\n",
       "      <td>-0.008144</td>\n",
       "      <td>-0.044736</td>\n",
       "      <td>-0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.004470</td>\n",
       "      <td>-0.010036</td>\n",
       "      <td>-0.136928</td>\n",
       "      <td>-0.029013</td>\n",
       "      <td>-0.031571</td>\n",
       "      <td>0.011668</td>\n",
       "      <td>-0.104243</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>0.017945</td>\n",
       "      <td>-0.061736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009916</td>\n",
       "      <td>0.063362</td>\n",
       "      <td>-0.037031</td>\n",
       "      <td>-0.043478</td>\n",
       "      <td>0.039641</td>\n",
       "      <td>0.009538</td>\n",
       "      <td>-0.050214</td>\n",
       "      <td>-0.008144</td>\n",
       "      <td>-0.044736</td>\n",
       "      <td>-0.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 700 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          521       555       464       146       459       578       466  \\\n",
       "0    0.019545  0.006736  0.156682  0.014037 -0.031571  0.004495  0.037353   \n",
       "1    0.019545  0.006736 -0.071990  0.009191 -0.031571  0.004495  0.278855   \n",
       "2    0.000482  0.010090 -0.131291  0.008758 -0.031571  0.014783  0.171833   \n",
       "3    0.000482  0.010090 -0.140440  0.066090 -0.031571  0.014783 -0.195110   \n",
       "4   -0.004381 -0.003327 -0.029781 -0.104275 -0.031571  0.006089  0.284429   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "147  0.089982  0.009065  0.063551 -0.029268 -0.031571 -0.004344  0.280373   \n",
       "148  0.019351  0.007854 -0.040653 -0.007182  0.586617 -0.001011  0.193040   \n",
       "149  0.019351  0.007854 -0.026035  0.030283 -0.031571 -0.001011 -0.075700   \n",
       "150  0.004470 -0.010036 -0.140440 -0.007820 -0.031571  0.011668 -0.195110   \n",
       "151  0.004470 -0.010036 -0.136928 -0.029013 -0.031571  0.011668 -0.104243   \n",
       "\n",
       "          567       102       476  ...       580       512       550  \\\n",
       "0   -0.002092  0.034154 -0.031988  ...  0.000045 -0.006884  0.025033   \n",
       "1   -0.002092  0.018739 -0.068907  ...  0.000045 -0.006884  0.025033   \n",
       "2    0.004874 -0.043517 -0.034020  ...  0.007166 -0.019150  0.004244   \n",
       "3    0.004874 -0.021684 -0.027042  ...  0.007166 -0.019150  0.004244   \n",
       "4    0.002363 -0.049273 -0.013611  ...  0.008576  0.000245  0.029734   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "147 -0.014891 -0.066011 -0.059386  ...  0.002724  0.046772  0.000484   \n",
       "148  0.017754  0.043483 -0.064848  ... -0.005173  0.005516  0.001316   \n",
       "149  0.017754  0.175669 -0.054389  ... -0.005173  0.005516  0.001316   \n",
       "150  0.001634  0.025620 -0.055482  ...  0.009916  0.063362 -0.037031   \n",
       "151  0.001634  0.017945 -0.061736  ...  0.009916  0.063362 -0.037031   \n",
       "\n",
       "          545       509       571       546       455       547       0    \n",
       "0    0.020956 -0.016513 -0.000891  0.017661 -0.008144  0.019453  0.250000  \n",
       "1    0.020956 -0.016513 -0.000891  0.017661 -0.008144  0.019453  0.250000  \n",
       "2    0.007180  0.021233  0.008760 -0.007271  0.229704  0.012418  0.250000  \n",
       "3    0.007180  0.021233  0.008760 -0.007271 -0.008144  0.012418  0.250000  \n",
       "4    0.012956 -0.024416  0.011717  0.021297 -0.008144  0.018683  0.250000  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "147  0.018410  0.051588 -0.016223  0.006035 -0.008144  0.006751 -0.083333  \n",
       "148  0.009247 -0.041244  0.012807  0.009186 -0.008144  0.009858 -0.083333  \n",
       "149  0.009247 -0.041244  0.012807  0.009186 -0.008144  0.009858 -0.083333  \n",
       "150 -0.043478  0.039641  0.009538 -0.050214 -0.008144 -0.044736 -0.083333  \n",
       "151 -0.043478  0.039641  0.009538 -0.050214 -0.008144 -0.044736 -0.083333  \n",
       "\n",
       "[152 rows x 700 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features[saliency_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74075456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_features = 100\n",
    "salient_features = features.iloc[:,saliency_order[0:num_features]]\n",
    "A = np.zeros((features.shape[0], features.shape[0]))\n",
    "for i in features.index:\n",
    "    for j in range(i):\n",
    "        A[i,j] = np.linalg.norm(salient_features.iloc[i,:] - salient_features.iloc[j,:])\n",
    "A = A + np.transpose(A)\n",
    "# p = np.median(A).astype('int')\n",
    "# print(np.max(A))\n",
    "p = 1.6\n",
    "A = (A < p)\n",
    "A = A - np.eye(A.shape[0])\n",
    "rows, cols = np.where(A==1)\n",
    "edges = zip(rows.tolist(), cols.tolist())\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(edges, node_size=1)\n",
    "color_map = np.array([])\n",
    "for node in G:\n",
    "    if (class_label[node]==0):\n",
    "        color_map = np.append(color_map, 'red')\n",
    "    elif (class_label[node]==1):\n",
    "        color_map = np.append(color_map, 'blue')\n",
    "    else:\n",
    "        color_map = np.append(color_map, 'yellow')\n",
    "nx.draw(G, node_color=color_map)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27d504bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a21a45c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141.61293299248968\n",
      "[2 1 1 2 1 2 1 1 1 2 1 2 1 2 1 2 1 2 2 1 1 1 2 1 2 2 2 1 2 1 2 1 1 1 2 2 2\n",
      " 1 2 1 2 2 2 1 2 2 2 2 1 1 2 2 2 2 1 1 2 2 2 2 2 1 2 1 2 2 2 1 2 2 2 0 2 1\n",
      " 2 2 2 1 2 1 0 1 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 1 2 1 1 0 1 2 0 1 2 1 2 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 2 1]\n",
      "     adenoma  hyperplasic  serrated\n",
      "0        1.0          0.0       0.0\n",
      "1        1.0          0.0       0.0\n",
      "2        1.0          0.0       0.0\n",
      "3        1.0          0.0       0.0\n",
      "4        1.0          0.0       0.0\n",
      "..       ...          ...       ...\n",
      "147      0.0          0.0       1.0\n",
      "148      0.0          0.0       1.0\n",
      "149      0.0          0.0       1.0\n",
      "150      0.0          0.0       1.0\n",
      "151      0.0          0.0       1.0\n",
      "\n",
      "[152 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(salient_features)\n",
    "print(kmeans.inertia_)\n",
    "# print(kmeans.cluster_centers_)\n",
    "# print(kmeans.n_iter_)\n",
    "predicted_label = kmeans.labels_\n",
    "print(predicted_label)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "19f946f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6578947368421053\n"
     ]
    }
   ],
   "source": [
    "compared_classes = np.array([])\n",
    "for i in classes.iterrows():\n",
    "    if i[1]['adenoma']==1:\n",
    "        compared_classes = np.append(compared_classes, 2)\n",
    "    elif i[1]['hyperplasic']==1:\n",
    "        compared_classes = np.append(compared_classes, 1)\n",
    "    else:\n",
    "        compared_classes = np.append(compared_classes, 0)\n",
    "print(np.count_nonzero(compared_classes!=predicted_label)/len(predicted_label))\n",
    "# print(i[1]['adenoma'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "mlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
