{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6ef3116e",
      "metadata": {
        "id": "6ef3116e"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from IPython.utils import io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import InputLayer\n",
        "from tensorflow.keras.layers import Activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b2a82fc2",
      "metadata": {
        "id": "b2a82fc2"
      },
      "outputs": [],
      "source": [
        "features = pd.read_csv('gastrointestinal_colonoscopy_lesions_dataset.csv')\n",
        "features = features.T\n",
        "class_label = pd.Series(features.index)\n",
        "features.index = range(features.shape[0])\n",
        "classes = np.zeros((features.shape[0], 3))\n",
        "for i in range(classes.shape[0]):\n",
        "    if 'adenoma' in class_label[i]:\n",
        "        classes[i,0] = 1.0\n",
        "        class_label[i] = 0\n",
        "    elif 'serrated' in class_label[i]:\n",
        "        classes[i,2] = 1.0\n",
        "        class_label[i] = 2\n",
        "    else:\n",
        "        classes[i,1] = 1.0\n",
        "        class_label[i] = 1\n",
        "classes = {'adenoma': classes[:,0], 'hyperplasic': classes[:,1], 'serrated': classes[:,2]}\n",
        "classes = pd.DataFrame(classes)\n",
        "class_label = class_label.astype('int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9d3a520d",
      "metadata": {
        "id": "9d3a520d",
        "outputId": "44713866-a583-4fa6-bbff-d5434472fa05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 789
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0     1         2         3         4         5         6    \\\n",
              "0    0.250000 -0.25  0.048325 -0.005553 -0.056058 -0.084224 -0.037834   \n",
              "1    0.250000  0.25 -0.001203  0.367137 -0.084265 -0.100569  0.018451   \n",
              "2    0.250000  0.25 -0.233810  0.046065  0.024136  0.032700 -0.031101   \n",
              "3    0.250000 -0.25 -0.182565  0.057049 -0.031463 -0.025114 -0.050518   \n",
              "4    0.250000  0.25 -0.107936 -0.094438  0.092679  0.038768  0.186656   \n",
              "..        ...   ...       ...       ...       ...       ...       ...   \n",
              "147 -0.083333  0.25  0.040649 -0.066683 -0.185786 -0.250955 -0.163660   \n",
              "148 -0.083333  0.25 -0.153445  0.092191 -0.010435 -0.057762 -0.097339   \n",
              "149 -0.083333 -0.25  0.144594  0.231284 -0.043448 -0.041229 -0.173962   \n",
              "150 -0.083333 -0.25 -0.169496 -0.098815 -0.207792 -0.250433 -0.221289   \n",
              "151 -0.083333  0.25 -0.159845  0.127796  0.027929  0.123740 -0.062721   \n",
              "\n",
              "          7         8         9    ...       690       691       692  \\\n",
              "0   -0.031987 -0.101462 -0.050684  ...  0.397177  0.392793  0.388256   \n",
              "1    0.046227 -0.101911 -0.038210  ...  0.397177  0.392793  0.388256   \n",
              "2   -0.036372 -0.169688 -0.154002  ...  0.060715  0.057743  0.055493   \n",
              "3   -0.035422 -0.067798 -0.052955  ...  0.060715  0.057743  0.055493   \n",
              "4    0.125008  0.095410  0.078630  ... -0.054256 -0.053808 -0.052869   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "147 -0.173238 -0.232896 -0.223542  ... -0.054095 -0.053643 -0.052701   \n",
              "148 -0.111005 -0.120050  0.000883  ... -0.043740 -0.044039 -0.043146   \n",
              "149 -0.202734 -0.153664 -0.000519  ... -0.043740 -0.044039 -0.043146   \n",
              "150 -0.226000  0.073333  0.138157  ... -0.053643 -0.053247 -0.052332   \n",
              "151 -0.072166  0.041411  0.038973  ... -0.053643 -0.053247 -0.052332   \n",
              "\n",
              "          693       694       695       696       697       698       699  \n",
              "0    0.383761  0.384351  0.383117  0.379185  0.365162  0.365579  0.375950  \n",
              "1    0.383761  0.384351  0.383117  0.379185  0.365162  0.365579  0.375950  \n",
              "2    0.056890  0.052044  0.053244  0.052057  0.045743  0.046962  0.047065  \n",
              "3    0.056890  0.052044  0.053244  0.052057  0.045743  0.046962  0.047065  \n",
              "4   -0.052718 -0.051934 -0.051097 -0.050394 -0.050345 -0.049870 -0.049726  \n",
              "..        ...       ...       ...       ...       ...       ...       ...  \n",
              "147 -0.052581 -0.051796 -0.050957 -0.050288 -0.050236 -0.049758 -0.049611  \n",
              "148 -0.043641 -0.042803 -0.042638 -0.042785 -0.042676 -0.042227 -0.042307  \n",
              "149 -0.043641 -0.042803 -0.042638 -0.042785 -0.042676 -0.042227 -0.042307  \n",
              "150 -0.052204 -0.051450 -0.050608 -0.049938 -0.049907 -0.049461 -0.049344  \n",
              "151 -0.052204 -0.051450 -0.050608 -0.049938 -0.049907 -0.049461 -0.049344  \n",
              "\n",
              "[152 rows x 700 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ca00f6e-0250-461e-ba29-eacc87ca1de2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>690</th>\n",
              "      <th>691</th>\n",
              "      <th>692</th>\n",
              "      <th>693</th>\n",
              "      <th>694</th>\n",
              "      <th>695</th>\n",
              "      <th>696</th>\n",
              "      <th>697</th>\n",
              "      <th>698</th>\n",
              "      <th>699</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>0.048325</td>\n",
              "      <td>-0.005553</td>\n",
              "      <td>-0.056058</td>\n",
              "      <td>-0.084224</td>\n",
              "      <td>-0.037834</td>\n",
              "      <td>-0.031987</td>\n",
              "      <td>-0.101462</td>\n",
              "      <td>-0.050684</td>\n",
              "      <td>...</td>\n",
              "      <td>0.397177</td>\n",
              "      <td>0.392793</td>\n",
              "      <td>0.388256</td>\n",
              "      <td>0.383761</td>\n",
              "      <td>0.384351</td>\n",
              "      <td>0.383117</td>\n",
              "      <td>0.379185</td>\n",
              "      <td>0.365162</td>\n",
              "      <td>0.365579</td>\n",
              "      <td>0.375950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.001203</td>\n",
              "      <td>0.367137</td>\n",
              "      <td>-0.084265</td>\n",
              "      <td>-0.100569</td>\n",
              "      <td>0.018451</td>\n",
              "      <td>0.046227</td>\n",
              "      <td>-0.101911</td>\n",
              "      <td>-0.038210</td>\n",
              "      <td>...</td>\n",
              "      <td>0.397177</td>\n",
              "      <td>0.392793</td>\n",
              "      <td>0.388256</td>\n",
              "      <td>0.383761</td>\n",
              "      <td>0.384351</td>\n",
              "      <td>0.383117</td>\n",
              "      <td>0.379185</td>\n",
              "      <td>0.365162</td>\n",
              "      <td>0.365579</td>\n",
              "      <td>0.375950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.233810</td>\n",
              "      <td>0.046065</td>\n",
              "      <td>0.024136</td>\n",
              "      <td>0.032700</td>\n",
              "      <td>-0.031101</td>\n",
              "      <td>-0.036372</td>\n",
              "      <td>-0.169688</td>\n",
              "      <td>-0.154002</td>\n",
              "      <td>...</td>\n",
              "      <td>0.060715</td>\n",
              "      <td>0.057743</td>\n",
              "      <td>0.055493</td>\n",
              "      <td>0.056890</td>\n",
              "      <td>0.052044</td>\n",
              "      <td>0.053244</td>\n",
              "      <td>0.052057</td>\n",
              "      <td>0.045743</td>\n",
              "      <td>0.046962</td>\n",
              "      <td>0.047065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-0.182565</td>\n",
              "      <td>0.057049</td>\n",
              "      <td>-0.031463</td>\n",
              "      <td>-0.025114</td>\n",
              "      <td>-0.050518</td>\n",
              "      <td>-0.035422</td>\n",
              "      <td>-0.067798</td>\n",
              "      <td>-0.052955</td>\n",
              "      <td>...</td>\n",
              "      <td>0.060715</td>\n",
              "      <td>0.057743</td>\n",
              "      <td>0.055493</td>\n",
              "      <td>0.056890</td>\n",
              "      <td>0.052044</td>\n",
              "      <td>0.053244</td>\n",
              "      <td>0.052057</td>\n",
              "      <td>0.045743</td>\n",
              "      <td>0.046962</td>\n",
              "      <td>0.047065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.107936</td>\n",
              "      <td>-0.094438</td>\n",
              "      <td>0.092679</td>\n",
              "      <td>0.038768</td>\n",
              "      <td>0.186656</td>\n",
              "      <td>0.125008</td>\n",
              "      <td>0.095410</td>\n",
              "      <td>0.078630</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.054256</td>\n",
              "      <td>-0.053808</td>\n",
              "      <td>-0.052869</td>\n",
              "      <td>-0.052718</td>\n",
              "      <td>-0.051934</td>\n",
              "      <td>-0.051097</td>\n",
              "      <td>-0.050394</td>\n",
              "      <td>-0.050345</td>\n",
              "      <td>-0.049870</td>\n",
              "      <td>-0.049726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>-0.083333</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.040649</td>\n",
              "      <td>-0.066683</td>\n",
              "      <td>-0.185786</td>\n",
              "      <td>-0.250955</td>\n",
              "      <td>-0.163660</td>\n",
              "      <td>-0.173238</td>\n",
              "      <td>-0.232896</td>\n",
              "      <td>-0.223542</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.054095</td>\n",
              "      <td>-0.053643</td>\n",
              "      <td>-0.052701</td>\n",
              "      <td>-0.052581</td>\n",
              "      <td>-0.051796</td>\n",
              "      <td>-0.050957</td>\n",
              "      <td>-0.050288</td>\n",
              "      <td>-0.050236</td>\n",
              "      <td>-0.049758</td>\n",
              "      <td>-0.049611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>-0.083333</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.153445</td>\n",
              "      <td>0.092191</td>\n",
              "      <td>-0.010435</td>\n",
              "      <td>-0.057762</td>\n",
              "      <td>-0.097339</td>\n",
              "      <td>-0.111005</td>\n",
              "      <td>-0.120050</td>\n",
              "      <td>0.000883</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.043740</td>\n",
              "      <td>-0.044039</td>\n",
              "      <td>-0.043146</td>\n",
              "      <td>-0.043641</td>\n",
              "      <td>-0.042803</td>\n",
              "      <td>-0.042638</td>\n",
              "      <td>-0.042785</td>\n",
              "      <td>-0.042676</td>\n",
              "      <td>-0.042227</td>\n",
              "      <td>-0.042307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>-0.083333</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>0.144594</td>\n",
              "      <td>0.231284</td>\n",
              "      <td>-0.043448</td>\n",
              "      <td>-0.041229</td>\n",
              "      <td>-0.173962</td>\n",
              "      <td>-0.202734</td>\n",
              "      <td>-0.153664</td>\n",
              "      <td>-0.000519</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.043740</td>\n",
              "      <td>-0.044039</td>\n",
              "      <td>-0.043146</td>\n",
              "      <td>-0.043641</td>\n",
              "      <td>-0.042803</td>\n",
              "      <td>-0.042638</td>\n",
              "      <td>-0.042785</td>\n",
              "      <td>-0.042676</td>\n",
              "      <td>-0.042227</td>\n",
              "      <td>-0.042307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>-0.083333</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-0.169496</td>\n",
              "      <td>-0.098815</td>\n",
              "      <td>-0.207792</td>\n",
              "      <td>-0.250433</td>\n",
              "      <td>-0.221289</td>\n",
              "      <td>-0.226000</td>\n",
              "      <td>0.073333</td>\n",
              "      <td>0.138157</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.053643</td>\n",
              "      <td>-0.053247</td>\n",
              "      <td>-0.052332</td>\n",
              "      <td>-0.052204</td>\n",
              "      <td>-0.051450</td>\n",
              "      <td>-0.050608</td>\n",
              "      <td>-0.049938</td>\n",
              "      <td>-0.049907</td>\n",
              "      <td>-0.049461</td>\n",
              "      <td>-0.049344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>-0.083333</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.159845</td>\n",
              "      <td>0.127796</td>\n",
              "      <td>0.027929</td>\n",
              "      <td>0.123740</td>\n",
              "      <td>-0.062721</td>\n",
              "      <td>-0.072166</td>\n",
              "      <td>0.041411</td>\n",
              "      <td>0.038973</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.053643</td>\n",
              "      <td>-0.053247</td>\n",
              "      <td>-0.052332</td>\n",
              "      <td>-0.052204</td>\n",
              "      <td>-0.051450</td>\n",
              "      <td>-0.050608</td>\n",
              "      <td>-0.049938</td>\n",
              "      <td>-0.049907</td>\n",
              "      <td>-0.049461</td>\n",
              "      <td>-0.049344</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>152 rows Ã— 700 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ca00f6e-0250-461e-ba29-eacc87ca1de2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0ca00f6e-0250-461e-ba29-eacc87ca1de2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0ca00f6e-0250-461e-ba29-eacc87ca1de2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Total number of columns (700) exceeds max_columns (20) limiting to first (20) columns.\n",
            "Error: Runtime no longer has a reference to this dataframe, please re-run this cell and try again.\n",
            "Error: Runtime no longer has a reference to this dataframe, please re-run this cell and try again.\n",
            "Error: Runtime no longer has a reference to this dataframe, please re-run this cell and try again.\n",
            "Error: Runtime no longer has a reference to this dataframe, please re-run this cell and try again.\n"
          ]
        }
      ],
      "source": [
        "for col in features.columns:\n",
        "    if features[col].abs().max()==0:\n",
        "        continue\n",
        "    features[col] = (features[col] - features[col].mean())/features[col].abs().max()\n",
        "features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "bb3de32e",
      "metadata": {
        "id": "bb3de32e",
        "outputId": "3db1372b-ca3e-4744-c16f-65746aac572a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 7)                 4907      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,965\n",
            "Trainable params: 4,965\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    \n",
        "    InputLayer(input_shape=(features.shape[1])),\n",
        "    \n",
        "    Dense(7, activation='sigmoid'),\n",
        "    \n",
        "    Dense(5, activation='sigmoid'),\n",
        "    \n",
        "    Dense(3, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='Adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy']\n",
        "             )\n",
        "model.summary()\n",
        "model.save_weights('model_weights/initial_weights_colonoscopy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "406c8d25",
      "metadata": {
        "id": "406c8d25",
        "outputId": "66c76038-9904-420d-b2b3-dedeb6f26628",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 168ms/step - loss: 0.0430 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0611 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1060 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2627 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0892 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5454 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3347 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0985 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0744 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0382 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.3309 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0468 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0467 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0498 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0474 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0391 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0941 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0372 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0366 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0511 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1138 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6198 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0422 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0527 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0458 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0562 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0450 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0678 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0480 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1654 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0409 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0408 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3386 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1089 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0420 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0378 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0412 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1428 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0377 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0376 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2824 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0424 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0438 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0682 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0417 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0357 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0519 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0507 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0567 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0463 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0578 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0405 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.9112 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2019 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.3694 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2101 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0362 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0426 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0784 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0391 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0368 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0448 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2184 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0911 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0392 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2125 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0561 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0588 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2013 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0392 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0367 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7154 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6848 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0700 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.0240 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0540 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0403 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0466 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0419 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6577 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0601 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2652 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0665 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0708 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0682 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0871 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0796 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2598 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1522 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0655 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.9332 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4336 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1332 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1548 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.2573 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0777 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0585 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0661 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0685 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0561 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0597 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0687 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0590 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0645 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0693 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0612 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0654 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0771 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1302 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0643 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0620 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0623 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0733 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1298 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0543 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0653 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.4594 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0609 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0671 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0727 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0637 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0608 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.7192 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1973 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.4107 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2525 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6226 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.9000 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2217 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.4720 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2018 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1987 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.1962 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.9836 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5854 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2099 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.3272 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3016 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1883 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1915 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4046 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.3283 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.8488 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3644 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.2536 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.3089 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2623 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2025 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.6311 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2168 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.3220 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5994 - accuracy: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "acc = 0\n",
        "j = 0\n",
        "for train_index, test_index in LeaveOneOut().split(features):\n",
        "    x_train, x_test = features.iloc[train_index,:], features.iloc[test_index,:]\n",
        "    y_train, y_test = classes.iloc[train_index,:], classes.iloc[test_index,:]\n",
        "    model.load_weights('model_weights/initial_weights_colonoscopy')\n",
        "    with io.capture_output() as captured:\n",
        "        model.fit(x_train, y_train, epochs=500)\n",
        "    acc += model.evaluate(x_test, y_test)[1]\n",
        "    j+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fe3a4412",
      "metadata": {
        "id": "fe3a4412",
        "outputId": "71091327-04ec-4748-f687-57842fa392b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.868421052631579\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy: ', acc/j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4978bff8",
      "metadata": {
        "id": "4978bff8",
        "outputId": "a28d5744-72c0-4562-95b9-d108b4124c98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0856 - accuracy: 0.9934\n",
            "Epoch 2/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0851 - accuracy: 0.9934\n",
            "Epoch 3/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0846 - accuracy: 0.9934\n",
            "Epoch 4/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0842 - accuracy: 0.9934\n",
            "Epoch 5/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0836 - accuracy: 0.9934\n",
            "Epoch 6/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0833 - accuracy: 1.0000\n",
            "Epoch 7/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0829 - accuracy: 1.0000\n",
            "Epoch 8/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0825 - accuracy: 1.0000\n",
            "Epoch 9/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0821 - accuracy: 1.0000\n",
            "Epoch 10/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0817 - accuracy: 1.0000\n",
            "Epoch 11/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0814 - accuracy: 1.0000\n",
            "Epoch 12/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0810 - accuracy: 1.0000\n",
            "Epoch 13/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0807 - accuracy: 1.0000\n",
            "Epoch 14/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0804 - accuracy: 1.0000\n",
            "Epoch 15/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0800 - accuracy: 1.0000\n",
            "Epoch 16/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0797 - accuracy: 1.0000\n",
            "Epoch 17/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0793 - accuracy: 1.0000\n",
            "Epoch 18/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0790 - accuracy: 1.0000\n",
            "Epoch 19/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0787 - accuracy: 1.0000\n",
            "Epoch 20/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0784 - accuracy: 1.0000\n",
            "Epoch 21/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0781 - accuracy: 1.0000\n",
            "Epoch 22/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0777 - accuracy: 1.0000\n",
            "Epoch 23/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0775 - accuracy: 1.0000\n",
            "Epoch 24/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0771 - accuracy: 1.0000\n",
            "Epoch 25/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0768 - accuracy: 1.0000\n",
            "Epoch 26/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0766 - accuracy: 1.0000\n",
            "Epoch 27/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0762 - accuracy: 1.0000\n",
            "Epoch 28/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0759 - accuracy: 1.0000\n",
            "Epoch 29/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0756 - accuracy: 1.0000\n",
            "Epoch 30/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0753 - accuracy: 1.0000\n",
            "Epoch 31/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0750 - accuracy: 1.0000\n",
            "Epoch 32/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0747 - accuracy: 1.0000\n",
            "Epoch 33/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0744 - accuracy: 1.0000\n",
            "Epoch 34/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0741 - accuracy: 1.0000\n",
            "Epoch 35/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0738 - accuracy: 1.0000\n",
            "Epoch 36/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0736 - accuracy: 1.0000\n",
            "Epoch 37/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0733 - accuracy: 1.0000\n",
            "Epoch 38/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0730 - accuracy: 1.0000\n",
            "Epoch 39/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0727 - accuracy: 1.0000\n",
            "Epoch 40/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0724 - accuracy: 1.0000\n",
            "Epoch 41/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 1.0000\n",
            "Epoch 42/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0719 - accuracy: 1.0000\n",
            "Epoch 43/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0716 - accuracy: 1.0000\n",
            "Epoch 44/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 1.0000\n",
            "Epoch 45/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 1.0000\n",
            "Epoch 46/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0708 - accuracy: 1.0000\n",
            "Epoch 47/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0705 - accuracy: 1.0000\n",
            "Epoch 48/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0703 - accuracy: 1.0000\n",
            "Epoch 49/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0700 - accuracy: 1.0000\n",
            "Epoch 50/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 1.0000\n",
            "Epoch 51/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 1.0000\n",
            "Epoch 52/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0692 - accuracy: 1.0000\n",
            "Epoch 53/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 1.0000\n",
            "Epoch 54/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 1.0000\n",
            "Epoch 55/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 1.0000\n",
            "Epoch 56/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 1.0000\n",
            "Epoch 57/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 1.0000\n",
            "Epoch 58/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 1.0000\n",
            "Epoch 59/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0674 - accuracy: 1.0000\n",
            "Epoch 60/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 1.0000\n",
            "Epoch 61/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 1.0000\n",
            "Epoch 62/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 1.0000\n",
            "Epoch 63/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 1.0000\n",
            "Epoch 64/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 1.0000\n",
            "Epoch 65/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 1.0000\n",
            "Epoch 66/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 1.0000\n",
            "Epoch 67/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 1.0000\n",
            "Epoch 68/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 1.0000\n",
            "Epoch 69/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 1.0000\n",
            "Epoch 70/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 1.0000\n",
            "Epoch 71/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 1.0000\n",
            "Epoch 72/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 1.0000\n",
            "Epoch 73/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 1.0000\n",
            "Epoch 74/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 1.0000\n",
            "Epoch 75/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 1.0000\n",
            "Epoch 76/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 1.0000\n",
            "Epoch 77/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 1.0000\n",
            "Epoch 78/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 1.0000\n",
            "Epoch 79/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 1.0000\n",
            "Epoch 80/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 1.0000\n",
            "Epoch 81/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 1.0000\n",
            "Epoch 82/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 1.0000\n",
            "Epoch 83/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 1.0000\n",
            "Epoch 84/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 1.0000\n",
            "Epoch 85/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 1.0000\n",
            "Epoch 86/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 1.0000\n",
            "Epoch 87/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 1.0000\n",
            "Epoch 88/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 1.0000\n",
            "Epoch 89/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 1.0000\n",
            "Epoch 90/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 1.0000\n",
            "Epoch 91/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 1.0000\n",
            "Epoch 92/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 1.0000\n",
            "Epoch 93/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 1.0000\n",
            "Epoch 94/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 1.0000\n",
            "Epoch 95/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 1.0000\n",
            "Epoch 96/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0589 - accuracy: 1.0000\n",
            "Epoch 97/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0587 - accuracy: 1.0000\n",
            "Epoch 98/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0585 - accuracy: 1.0000\n",
            "Epoch 99/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0583 - accuracy: 1.0000\n",
            "Epoch 100/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 1.0000\n",
            "Epoch 101/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 1.0000\n",
            "Epoch 102/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 1.0000\n",
            "Epoch 103/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 1.0000\n",
            "Epoch 104/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0573 - accuracy: 1.0000\n",
            "Epoch 105/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0571 - accuracy: 1.0000\n",
            "Epoch 106/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 1.0000\n",
            "Epoch 107/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0567 - accuracy: 1.0000\n",
            "Epoch 108/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0565 - accuracy: 1.0000\n",
            "Epoch 109/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0563 - accuracy: 1.0000\n",
            "Epoch 110/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0561 - accuracy: 1.0000\n",
            "Epoch 111/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 1.0000\n",
            "Epoch 112/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0557 - accuracy: 1.0000\n",
            "Epoch 113/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0555 - accuracy: 1.0000\n",
            "Epoch 114/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0553 - accuracy: 1.0000\n",
            "Epoch 115/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 1.0000\n",
            "Epoch 116/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0549 - accuracy: 1.0000\n",
            "Epoch 117/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 1.0000\n",
            "Epoch 118/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0545 - accuracy: 1.0000\n",
            "Epoch 119/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 1.0000\n",
            "Epoch 120/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0541 - accuracy: 1.0000\n",
            "Epoch 121/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 1.0000\n",
            "Epoch 122/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 1.0000\n",
            "Epoch 123/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 1.0000\n",
            "Epoch 124/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0534 - accuracy: 1.0000\n",
            "Epoch 125/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 1.0000\n",
            "Epoch 126/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 1.0000\n",
            "Epoch 127/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0528 - accuracy: 1.0000\n",
            "Epoch 128/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0527 - accuracy: 1.0000\n",
            "Epoch 129/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0525 - accuracy: 1.0000\n",
            "Epoch 130/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0523 - accuracy: 1.0000\n",
            "Epoch 131/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 1.0000\n",
            "Epoch 132/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0519 - accuracy: 1.0000\n",
            "Epoch 133/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 1.0000\n",
            "Epoch 134/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0516 - accuracy: 1.0000\n",
            "Epoch 135/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0514 - accuracy: 1.0000\n",
            "Epoch 136/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0512 - accuracy: 1.0000\n",
            "Epoch 137/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0511 - accuracy: 1.0000\n",
            "Epoch 138/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 1.0000\n",
            "Epoch 139/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 1.0000\n",
            "Epoch 140/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0505 - accuracy: 1.0000\n",
            "Epoch 141/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0504 - accuracy: 1.0000\n",
            "Epoch 142/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 1.0000\n",
            "Epoch 143/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 1.0000\n",
            "Epoch 144/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0498 - accuracy: 1.0000\n",
            "Epoch 145/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0497 - accuracy: 1.0000\n",
            "Epoch 146/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0495 - accuracy: 1.0000\n",
            "Epoch 147/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 1.0000\n",
            "Epoch 148/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0492 - accuracy: 1.0000\n",
            "Epoch 149/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 1.0000\n",
            "Epoch 150/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0488 - accuracy: 1.0000\n",
            "Epoch 151/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0487 - accuracy: 1.0000\n",
            "Epoch 152/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0485 - accuracy: 1.0000\n",
            "Epoch 153/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 1.0000\n",
            "Epoch 154/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 1.0000\n",
            "Epoch 155/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0480 - accuracy: 1.0000\n",
            "Epoch 156/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0479 - accuracy: 1.0000\n",
            "Epoch 157/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 1.0000\n",
            "Epoch 158/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0476 - accuracy: 1.0000\n",
            "Epoch 159/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0474 - accuracy: 1.0000\n",
            "Epoch 160/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 1.0000\n",
            "Epoch 161/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 1.0000\n",
            "Epoch 162/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 1.0000\n",
            "Epoch 163/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 1.0000\n",
            "Epoch 164/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0466 - accuracy: 1.0000\n",
            "Epoch 165/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 1.0000\n",
            "Epoch 166/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 1.0000\n",
            "Epoch 167/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0462 - accuracy: 1.0000\n",
            "Epoch 168/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0460 - accuracy: 1.0000\n",
            "Epoch 169/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0458 - accuracy: 1.0000\n",
            "Epoch 170/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0457 - accuracy: 1.0000\n",
            "Epoch 171/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0455 - accuracy: 1.0000\n",
            "Epoch 172/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0454 - accuracy: 1.0000\n",
            "Epoch 173/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0452 - accuracy: 1.0000\n",
            "Epoch 174/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0451 - accuracy: 1.0000\n",
            "Epoch 175/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0449 - accuracy: 1.0000\n",
            "Epoch 176/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0448 - accuracy: 1.0000\n",
            "Epoch 177/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0446 - accuracy: 1.0000\n",
            "Epoch 178/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0445 - accuracy: 1.0000\n",
            "Epoch 179/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0444 - accuracy: 1.0000\n",
            "Epoch 180/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0442 - accuracy: 1.0000\n",
            "Epoch 181/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 1.0000\n",
            "Epoch 182/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0439 - accuracy: 1.0000\n",
            "Epoch 183/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0438 - accuracy: 1.0000\n",
            "Epoch 184/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0436 - accuracy: 1.0000\n",
            "Epoch 185/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0435 - accuracy: 1.0000\n",
            "Epoch 186/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0434 - accuracy: 1.0000\n",
            "Epoch 187/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0432 - accuracy: 1.0000\n",
            "Epoch 188/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0431 - accuracy: 1.0000\n",
            "Epoch 189/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 1.0000\n",
            "Epoch 190/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0428 - accuracy: 1.0000\n",
            "Epoch 191/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 1.0000\n",
            "Epoch 192/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0425 - accuracy: 1.0000\n",
            "Epoch 193/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 1.0000\n",
            "Epoch 194/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0422 - accuracy: 1.0000\n",
            "Epoch 195/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0421 - accuracy: 1.0000\n",
            "Epoch 196/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0420 - accuracy: 1.0000\n",
            "Epoch 197/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0418 - accuracy: 1.0000\n",
            "Epoch 198/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0417 - accuracy: 1.0000\n",
            "Epoch 199/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0416 - accuracy: 1.0000\n",
            "Epoch 200/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0414 - accuracy: 1.0000\n",
            "Epoch 201/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0413 - accuracy: 1.0000\n",
            "Epoch 202/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 1.0000\n",
            "Epoch 203/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0410 - accuracy: 1.0000\n",
            "Epoch 204/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 1.0000\n",
            "Epoch 205/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0408 - accuracy: 1.0000\n",
            "Epoch 206/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 1.0000\n",
            "Epoch 207/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0405 - accuracy: 1.0000\n",
            "Epoch 208/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 1.0000\n",
            "Epoch 209/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0403 - accuracy: 1.0000\n",
            "Epoch 210/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0401 - accuracy: 1.0000\n",
            "Epoch 211/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 1.0000\n",
            "Epoch 212/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0399 - accuracy: 1.0000\n",
            "Epoch 213/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0398 - accuracy: 1.0000\n",
            "Epoch 214/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0396 - accuracy: 1.0000\n",
            "Epoch 215/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 1.0000\n",
            "Epoch 216/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0394 - accuracy: 1.0000\n",
            "Epoch 217/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0393 - accuracy: 1.0000\n",
            "Epoch 218/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0391 - accuracy: 1.0000\n",
            "Epoch 219/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 1.0000\n",
            "Epoch 220/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0389 - accuracy: 1.0000\n",
            "Epoch 221/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 1.0000\n",
            "Epoch 222/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 1.0000\n",
            "Epoch 223/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0385 - accuracy: 1.0000\n",
            "Epoch 224/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0384 - accuracy: 1.0000\n",
            "Epoch 225/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 1.0000\n",
            "Epoch 226/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0381 - accuracy: 1.0000\n",
            "Epoch 227/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0380 - accuracy: 1.0000\n",
            "Epoch 228/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0379 - accuracy: 1.0000\n",
            "Epoch 229/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 1.0000\n",
            "Epoch 230/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0377 - accuracy: 1.0000\n",
            "Epoch 231/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0375 - accuracy: 1.0000\n",
            "Epoch 232/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0374 - accuracy: 1.0000\n",
            "Epoch 233/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0373 - accuracy: 1.0000\n",
            "Epoch 234/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0372 - accuracy: 1.0000\n",
            "Epoch 235/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0371 - accuracy: 1.0000\n",
            "Epoch 236/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0370 - accuracy: 1.0000\n",
            "Epoch 237/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0369 - accuracy: 1.0000\n",
            "Epoch 238/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0367 - accuracy: 1.0000\n",
            "Epoch 239/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0366 - accuracy: 1.0000\n",
            "Epoch 240/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0365 - accuracy: 1.0000\n",
            "Epoch 241/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0364 - accuracy: 1.0000\n",
            "Epoch 242/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0363 - accuracy: 1.0000\n",
            "Epoch 243/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0362 - accuracy: 1.0000\n",
            "Epoch 244/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0361 - accuracy: 1.0000\n",
            "Epoch 245/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0359 - accuracy: 1.0000\n",
            "Epoch 246/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0358 - accuracy: 1.0000\n",
            "Epoch 247/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0357 - accuracy: 1.0000\n",
            "Epoch 248/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0356 - accuracy: 1.0000\n",
            "Epoch 249/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 1.0000\n",
            "Epoch 250/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0354 - accuracy: 1.0000\n",
            "Epoch 251/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 1.0000\n",
            "Epoch 252/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0352 - accuracy: 1.0000\n",
            "Epoch 253/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0351 - accuracy: 1.0000\n",
            "Epoch 254/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0350 - accuracy: 1.0000\n",
            "Epoch 255/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0349 - accuracy: 1.0000\n",
            "Epoch 256/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0348 - accuracy: 1.0000\n",
            "Epoch 257/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0346 - accuracy: 1.0000\n",
            "Epoch 258/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0345 - accuracy: 1.0000\n",
            "Epoch 259/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0344 - accuracy: 1.0000\n",
            "Epoch 260/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0343 - accuracy: 1.0000\n",
            "Epoch 261/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0342 - accuracy: 1.0000\n",
            "Epoch 262/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0341 - accuracy: 1.0000\n",
            "Epoch 263/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0340 - accuracy: 1.0000\n",
            "Epoch 264/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 1.0000\n",
            "Epoch 265/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0338 - accuracy: 1.0000\n",
            "Epoch 266/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0337 - accuracy: 1.0000\n",
            "Epoch 267/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0336 - accuracy: 1.0000\n",
            "Epoch 268/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0335 - accuracy: 1.0000\n",
            "Epoch 269/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0334 - accuracy: 1.0000\n",
            "Epoch 270/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0333 - accuracy: 1.0000\n",
            "Epoch 271/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0332 - accuracy: 1.0000\n",
            "Epoch 272/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0331 - accuracy: 1.0000\n",
            "Epoch 273/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0330 - accuracy: 1.0000\n",
            "Epoch 274/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0329 - accuracy: 1.0000\n",
            "Epoch 275/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0328 - accuracy: 1.0000\n",
            "Epoch 276/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0327 - accuracy: 1.0000\n",
            "Epoch 277/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0326 - accuracy: 1.0000\n",
            "Epoch 278/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0325 - accuracy: 1.0000\n",
            "Epoch 279/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0324 - accuracy: 1.0000\n",
            "Epoch 280/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0323 - accuracy: 1.0000\n",
            "Epoch 281/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0322 - accuracy: 1.0000\n",
            "Epoch 282/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0321 - accuracy: 1.0000\n",
            "Epoch 283/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0320 - accuracy: 1.0000\n",
            "Epoch 284/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0319 - accuracy: 1.0000\n",
            "Epoch 285/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0318 - accuracy: 1.0000\n",
            "Epoch 286/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0317 - accuracy: 1.0000\n",
            "Epoch 287/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0316 - accuracy: 1.0000\n",
            "Epoch 288/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0315 - accuracy: 1.0000\n",
            "Epoch 289/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0315 - accuracy: 1.0000\n",
            "Epoch 290/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0314 - accuracy: 1.0000\n",
            "Epoch 291/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0313 - accuracy: 1.0000\n",
            "Epoch 292/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0312 - accuracy: 1.0000\n",
            "Epoch 293/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0311 - accuracy: 1.0000\n",
            "Epoch 294/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0310 - accuracy: 1.0000\n",
            "Epoch 295/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0309 - accuracy: 1.0000\n",
            "Epoch 296/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0308 - accuracy: 1.0000\n",
            "Epoch 297/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0307 - accuracy: 1.0000\n",
            "Epoch 298/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0306 - accuracy: 1.0000\n",
            "Epoch 299/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0305 - accuracy: 1.0000\n",
            "Epoch 300/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0304 - accuracy: 1.0000\n",
            "Epoch 301/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0303 - accuracy: 1.0000\n",
            "Epoch 302/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0303 - accuracy: 1.0000\n",
            "Epoch 303/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0302 - accuracy: 1.0000\n",
            "Epoch 304/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0301 - accuracy: 1.0000\n",
            "Epoch 305/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 1.0000\n",
            "Epoch 306/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0299 - accuracy: 1.0000\n",
            "Epoch 307/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0298 - accuracy: 1.0000\n",
            "Epoch 308/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0297 - accuracy: 1.0000\n",
            "Epoch 309/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 1.0000\n",
            "Epoch 310/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0296 - accuracy: 1.0000\n",
            "Epoch 311/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0295 - accuracy: 1.0000\n",
            "Epoch 312/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0294 - accuracy: 1.0000\n",
            "Epoch 313/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0293 - accuracy: 1.0000\n",
            "Epoch 314/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0292 - accuracy: 1.0000\n",
            "Epoch 315/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0291 - accuracy: 1.0000\n",
            "Epoch 316/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0290 - accuracy: 1.0000\n",
            "Epoch 317/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 1.0000\n",
            "Epoch 318/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 1.0000\n",
            "Epoch 319/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0288 - accuracy: 1.0000\n",
            "Epoch 320/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - accuracy: 1.0000\n",
            "Epoch 321/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0286 - accuracy: 1.0000\n",
            "Epoch 322/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0285 - accuracy: 1.0000\n",
            "Epoch 323/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0284 - accuracy: 1.0000\n",
            "Epoch 324/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0284 - accuracy: 1.0000\n",
            "Epoch 325/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0283 - accuracy: 1.0000\n",
            "Epoch 326/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0282 - accuracy: 1.0000\n",
            "Epoch 327/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0281 - accuracy: 1.0000\n",
            "Epoch 328/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0280 - accuracy: 1.0000\n",
            "Epoch 329/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0279 - accuracy: 1.0000\n",
            "Epoch 330/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0279 - accuracy: 1.0000\n",
            "Epoch 331/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0278 - accuracy: 1.0000\n",
            "Epoch 332/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - accuracy: 1.0000\n",
            "Epoch 333/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0276 - accuracy: 1.0000\n",
            "Epoch 334/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0275 - accuracy: 1.0000\n",
            "Epoch 335/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0275 - accuracy: 1.0000\n",
            "Epoch 336/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0274 - accuracy: 1.0000\n",
            "Epoch 337/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 1.0000\n",
            "Epoch 338/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0272 - accuracy: 1.0000\n",
            "Epoch 339/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0272 - accuracy: 1.0000\n",
            "Epoch 340/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0271 - accuracy: 1.0000\n",
            "Epoch 341/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0270 - accuracy: 1.0000\n",
            "Epoch 342/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0269 - accuracy: 1.0000\n",
            "Epoch 343/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0268 - accuracy: 1.0000\n",
            "Epoch 344/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0268 - accuracy: 1.0000\n",
            "Epoch 345/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0267 - accuracy: 1.0000\n",
            "Epoch 346/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0266 - accuracy: 1.0000\n",
            "Epoch 347/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0265 - accuracy: 1.0000\n",
            "Epoch 348/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0265 - accuracy: 1.0000\n",
            "Epoch 349/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0264 - accuracy: 1.0000\n",
            "Epoch 350/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0263 - accuracy: 1.0000\n",
            "Epoch 351/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0262 - accuracy: 1.0000\n",
            "Epoch 352/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0262 - accuracy: 1.0000\n",
            "Epoch 353/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0261 - accuracy: 1.0000\n",
            "Epoch 354/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0260 - accuracy: 1.0000\n",
            "Epoch 355/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0259 - accuracy: 1.0000\n",
            "Epoch 356/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0259 - accuracy: 1.0000\n",
            "Epoch 357/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0258 - accuracy: 1.0000\n",
            "Epoch 358/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0257 - accuracy: 1.0000\n",
            "Epoch 359/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0256 - accuracy: 1.0000\n",
            "Epoch 360/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0256 - accuracy: 1.0000\n",
            "Epoch 361/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 1.0000\n",
            "Epoch 362/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0254 - accuracy: 1.0000\n",
            "Epoch 363/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - accuracy: 1.0000\n",
            "Epoch 364/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 1.0000\n",
            "Epoch 365/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 1.0000\n",
            "Epoch 366/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0251 - accuracy: 1.0000\n",
            "Epoch 367/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0251 - accuracy: 1.0000\n",
            "Epoch 368/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0250 - accuracy: 1.0000\n",
            "Epoch 369/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0249 - accuracy: 1.0000\n",
            "Epoch 370/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0248 - accuracy: 1.0000\n",
            "Epoch 371/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0248 - accuracy: 1.0000\n",
            "Epoch 372/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0247 - accuracy: 1.0000\n",
            "Epoch 373/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0246 - accuracy: 1.0000\n",
            "Epoch 374/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0246 - accuracy: 1.0000\n",
            "Epoch 375/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0245 - accuracy: 1.0000\n",
            "Epoch 376/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0244 - accuracy: 1.0000\n",
            "Epoch 377/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0244 - accuracy: 1.0000\n",
            "Epoch 378/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 1.0000\n",
            "Epoch 379/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0242 - accuracy: 1.0000\n",
            "Epoch 380/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 1.0000\n",
            "Epoch 381/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 1.0000\n",
            "Epoch 382/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0240 - accuracy: 1.0000\n",
            "Epoch 383/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0239 - accuracy: 1.0000\n",
            "Epoch 384/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0239 - accuracy: 1.0000\n",
            "Epoch 385/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0238 - accuracy: 1.0000\n",
            "Epoch 386/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0237 - accuracy: 1.0000\n",
            "Epoch 387/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0237 - accuracy: 1.0000\n",
            "Epoch 388/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0236 - accuracy: 1.0000\n",
            "Epoch 389/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0235 - accuracy: 1.0000\n",
            "Epoch 390/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0235 - accuracy: 1.0000\n",
            "Epoch 391/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0234 - accuracy: 1.0000\n",
            "Epoch 392/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0233 - accuracy: 1.0000\n",
            "Epoch 393/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 1.0000\n",
            "Epoch 394/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0232 - accuracy: 1.0000\n",
            "Epoch 395/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0231 - accuracy: 1.0000\n",
            "Epoch 396/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0231 - accuracy: 1.0000\n",
            "Epoch 397/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0230 - accuracy: 1.0000\n",
            "Epoch 398/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0230 - accuracy: 1.0000\n",
            "Epoch 399/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0229 - accuracy: 1.0000\n",
            "Epoch 400/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0228 - accuracy: 1.0000\n",
            "Epoch 401/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0228 - accuracy: 1.0000\n",
            "Epoch 402/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0227 - accuracy: 1.0000\n",
            "Epoch 403/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0226 - accuracy: 1.0000\n",
            "Epoch 404/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0226 - accuracy: 1.0000\n",
            "Epoch 405/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0225 - accuracy: 1.0000\n",
            "Epoch 406/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0224 - accuracy: 1.0000\n",
            "Epoch 407/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0224 - accuracy: 1.0000\n",
            "Epoch 408/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0223 - accuracy: 1.0000\n",
            "Epoch 409/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0223 - accuracy: 1.0000\n",
            "Epoch 410/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0222 - accuracy: 1.0000\n",
            "Epoch 411/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0221 - accuracy: 1.0000\n",
            "Epoch 412/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0221 - accuracy: 1.0000\n",
            "Epoch 413/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0220 - accuracy: 1.0000\n",
            "Epoch 414/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0220 - accuracy: 1.0000\n",
            "Epoch 415/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0219 - accuracy: 1.0000\n",
            "Epoch 416/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 1.0000\n",
            "Epoch 417/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0218 - accuracy: 1.0000\n",
            "Epoch 418/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0217 - accuracy: 1.0000\n",
            "Epoch 419/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0216 - accuracy: 1.0000\n",
            "Epoch 420/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0216 - accuracy: 1.0000\n",
            "Epoch 421/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0215 - accuracy: 1.0000\n",
            "Epoch 422/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0215 - accuracy: 1.0000\n",
            "Epoch 423/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0214 - accuracy: 1.0000\n",
            "Epoch 424/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 1.0000\n",
            "Epoch 425/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 1.0000\n",
            "Epoch 426/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 1.0000\n",
            "Epoch 427/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0212 - accuracy: 1.0000\n",
            "Epoch 428/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0211 - accuracy: 1.0000\n",
            "Epoch 429/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 1.0000\n",
            "Epoch 430/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 1.0000\n",
            "Epoch 431/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 1.0000\n",
            "Epoch 432/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0209 - accuracy: 1.0000\n",
            "Epoch 433/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 1.0000\n",
            "Epoch 434/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 1.0000\n",
            "Epoch 435/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0207 - accuracy: 1.0000\n",
            "Epoch 436/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0206 - accuracy: 1.0000\n",
            "Epoch 437/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0206 - accuracy: 1.0000\n",
            "Epoch 438/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0205 - accuracy: 1.0000\n",
            "Epoch 439/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0205 - accuracy: 1.0000\n",
            "Epoch 440/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0204 - accuracy: 1.0000\n",
            "Epoch 441/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0204 - accuracy: 1.0000\n",
            "Epoch 442/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0203 - accuracy: 1.0000\n",
            "Epoch 443/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0203 - accuracy: 1.0000\n",
            "Epoch 444/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0202 - accuracy: 1.0000\n",
            "Epoch 445/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 1.0000\n",
            "Epoch 446/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 1.0000\n",
            "Epoch 447/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 1.0000\n",
            "Epoch 448/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 1.0000\n",
            "Epoch 449/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0199 - accuracy: 1.0000\n",
            "Epoch 450/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0199 - accuracy: 1.0000\n",
            "Epoch 451/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 1.0000\n",
            "Epoch 452/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0198 - accuracy: 1.0000\n",
            "Epoch 453/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0197 - accuracy: 1.0000\n",
            "Epoch 454/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 1.0000\n",
            "Epoch 455/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 1.0000\n",
            "Epoch 456/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 1.0000\n",
            "Epoch 457/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 1.0000\n",
            "Epoch 458/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 1.0000\n",
            "Epoch 459/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0194 - accuracy: 1.0000\n",
            "Epoch 460/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0193 - accuracy: 1.0000\n",
            "Epoch 461/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0193 - accuracy: 1.0000\n",
            "Epoch 462/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0192 - accuracy: 1.0000\n",
            "Epoch 463/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0192 - accuracy: 1.0000\n",
            "Epoch 464/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0191 - accuracy: 1.0000\n",
            "Epoch 465/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0191 - accuracy: 1.0000\n",
            "Epoch 466/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0190 - accuracy: 1.0000\n",
            "Epoch 467/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0190 - accuracy: 1.0000\n",
            "Epoch 468/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 1.0000\n",
            "Epoch 469/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 1.0000\n",
            "Epoch 470/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 1.0000\n",
            "Epoch 471/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 1.0000\n",
            "Epoch 472/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 1.0000\n",
            "Epoch 473/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 1.0000\n",
            "Epoch 474/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0186 - accuracy: 1.0000\n",
            "Epoch 475/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 1.0000\n",
            "Epoch 476/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 1.0000\n",
            "Epoch 477/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 1.0000\n",
            "Epoch 478/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 1.0000\n",
            "Epoch 479/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 1.0000\n",
            "Epoch 480/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 1.0000\n",
            "Epoch 481/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0182 - accuracy: 1.0000\n",
            "Epoch 482/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0182 - accuracy: 1.0000\n",
            "Epoch 483/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0182 - accuracy: 1.0000\n",
            "Epoch 484/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 1.0000\n",
            "Epoch 485/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0181 - accuracy: 1.0000\n",
            "Epoch 486/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 1.0000\n",
            "Epoch 487/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 1.0000\n",
            "Epoch 488/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0179 - accuracy: 1.0000\n",
            "Epoch 489/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 1.0000\n",
            "Epoch 490/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 1.0000\n",
            "Epoch 491/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 1.0000\n",
            "Epoch 492/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 1.0000\n",
            "Epoch 493/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 1.0000\n",
            "Epoch 494/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0176 - accuracy: 1.0000\n",
            "Epoch 495/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 1.0000\n",
            "Epoch 496/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0175 - accuracy: 1.0000\n",
            "Epoch 497/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0175 - accuracy: 1.0000\n",
            "Epoch 498/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 1.0000\n",
            "Epoch 499/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0174 - accuracy: 1.0000\n",
            "Epoch 500/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0173 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fea81ec2090>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "model.fit(features, classes, epochs=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "46c38512",
      "metadata": {
        "id": "46c38512",
        "outputId": "45977369-81bf-47bd-877f-d219134f7d6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 700/700 [08:35<00:00,  1.36it/s]\n"
          ]
        }
      ],
      "source": [
        "grad_sum = 0\n",
        "for col_name in tqdm(features.columns):\n",
        "    pointFrame = features.loc[:, features.columns != col_name]\n",
        "    for i in features[col_name]:\n",
        "        pointFrame[col_name] = i*np.ones(len(features.index))\n",
        "        points = tf.Variable(pointFrame, dtype='float')\n",
        "        with tf.GradientTape() as tape:\n",
        "            pred = model(points, training=False)\n",
        "        grads = tape.gradient(pred, points)\n",
        "        grad_sum += np.abs(grads.numpy())\n",
        "saliency_order = np.argsort(-np.sum(np.abs(grad_sum), 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5082fe64",
      "metadata": {
        "id": "5082fe64",
        "outputId": "406e2d0c-3915-4da0-c3e8-62f74db3d0ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The features arranged in order of saliency are: \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         547       555       146       464       546       545  \\\n",
              "0    0.250000  0.019453  0.006736  0.014037  0.156682  0.017661  0.020956   \n",
              "1    0.250000  0.019453  0.006736  0.009191 -0.071990  0.017661  0.020956   \n",
              "2    0.250000  0.012418  0.010090  0.008758 -0.131291 -0.007271  0.007180   \n",
              "3    0.250000  0.012418  0.010090  0.066090 -0.140440 -0.007271  0.007180   \n",
              "4    0.250000  0.018683 -0.003327 -0.104275 -0.029781  0.021297  0.012956   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "147 -0.083333  0.006751  0.009065 -0.029268  0.063551  0.006035  0.018410   \n",
              "148 -0.083333  0.009858  0.007854 -0.007182 -0.040653  0.009186  0.009247   \n",
              "149 -0.083333  0.009858  0.007854  0.030283 -0.026035  0.009186  0.009247   \n",
              "150 -0.083333 -0.044736 -0.010036 -0.007820 -0.140440 -0.050214 -0.043478   \n",
              "151 -0.083333 -0.044736 -0.010036 -0.029013 -0.136928 -0.050214 -0.043478   \n",
              "\n",
              "          455       549       581  ...  291  391  182  325  261  404  394  \\\n",
              "0   -0.008144  0.013944 -0.000948  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "1   -0.008144  0.013944 -0.000948  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2    0.229704  0.016346  0.004249  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "3   -0.008144  0.016346  0.004249  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "4   -0.008144  0.017094  0.005566  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "..        ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "147 -0.008144 -0.003144 -0.002889  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "148 -0.008144  0.007949  0.001962  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "149 -0.008144  0.007949  0.001962  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "150 -0.008144 -0.039516  0.010348  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "151 -0.008144 -0.039516  0.010348  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "\n",
              "     274  322  366  \n",
              "0    0.0  0.0  0.0  \n",
              "1    0.0  0.0  0.0  \n",
              "2    0.0  0.0  0.0  \n",
              "3    0.0  0.0  0.0  \n",
              "4    0.0  0.0  0.0  \n",
              "..   ...  ...  ...  \n",
              "147  0.0  0.0  0.0  \n",
              "148  0.0  0.0  0.0  \n",
              "149  0.0  0.0  0.0  \n",
              "150  0.0  0.0  0.0  \n",
              "151  0.0  0.0  0.0  \n",
              "\n",
              "[152 rows x 700 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-33942750-1b83-4d88-b2b2-6cec03937f2f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>547</th>\n",
              "      <th>555</th>\n",
              "      <th>146</th>\n",
              "      <th>464</th>\n",
              "      <th>546</th>\n",
              "      <th>545</th>\n",
              "      <th>455</th>\n",
              "      <th>549</th>\n",
              "      <th>581</th>\n",
              "      <th>...</th>\n",
              "      <th>291</th>\n",
              "      <th>391</th>\n",
              "      <th>182</th>\n",
              "      <th>325</th>\n",
              "      <th>261</th>\n",
              "      <th>404</th>\n",
              "      <th>394</th>\n",
              "      <th>274</th>\n",
              "      <th>322</th>\n",
              "      <th>366</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.019453</td>\n",
              "      <td>0.006736</td>\n",
              "      <td>0.014037</td>\n",
              "      <td>0.156682</td>\n",
              "      <td>0.017661</td>\n",
              "      <td>0.020956</td>\n",
              "      <td>-0.008144</td>\n",
              "      <td>0.013944</td>\n",
              "      <td>-0.000948</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.019453</td>\n",
              "      <td>0.006736</td>\n",
              "      <td>0.009191</td>\n",
              "      <td>-0.071990</td>\n",
              "      <td>0.017661</td>\n",
              "      <td>0.020956</td>\n",
              "      <td>-0.008144</td>\n",
              "      <td>0.013944</td>\n",
              "      <td>-0.000948</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.012418</td>\n",
              "      <td>0.010090</td>\n",
              "      <td>0.008758</td>\n",
              "      <td>-0.131291</td>\n",
              "      <td>-0.007271</td>\n",
              "      <td>0.007180</td>\n",
              "      <td>0.229704</td>\n",
              "      <td>0.016346</td>\n",
              "      <td>0.004249</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.012418</td>\n",
              "      <td>0.010090</td>\n",
              "      <td>0.066090</td>\n",
              "      <td>-0.140440</td>\n",
              "      <td>-0.007271</td>\n",
              "      <td>0.007180</td>\n",
              "      <td>-0.008144</td>\n",
              "      <td>0.016346</td>\n",
              "      <td>0.004249</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.018683</td>\n",
              "      <td>-0.003327</td>\n",
              "      <td>-0.104275</td>\n",
              "      <td>-0.029781</td>\n",
              "      <td>0.021297</td>\n",
              "      <td>0.012956</td>\n",
              "      <td>-0.008144</td>\n",
              "      <td>0.017094</td>\n",
              "      <td>0.005566</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>-0.083333</td>\n",
              "      <td>0.006751</td>\n",
              "      <td>0.009065</td>\n",
              "      <td>-0.029268</td>\n",
              "      <td>0.063551</td>\n",
              "      <td>0.006035</td>\n",
              "      <td>0.018410</td>\n",
              "      <td>-0.008144</td>\n",
              "      <td>-0.003144</td>\n",
              "      <td>-0.002889</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>-0.083333</td>\n",
              "      <td>0.009858</td>\n",
              "      <td>0.007854</td>\n",
              "      <td>-0.007182</td>\n",
              "      <td>-0.040653</td>\n",
              "      <td>0.009186</td>\n",
              "      <td>0.009247</td>\n",
              "      <td>-0.008144</td>\n",
              "      <td>0.007949</td>\n",
              "      <td>0.001962</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>-0.083333</td>\n",
              "      <td>0.009858</td>\n",
              "      <td>0.007854</td>\n",
              "      <td>0.030283</td>\n",
              "      <td>-0.026035</td>\n",
              "      <td>0.009186</td>\n",
              "      <td>0.009247</td>\n",
              "      <td>-0.008144</td>\n",
              "      <td>0.007949</td>\n",
              "      <td>0.001962</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>-0.083333</td>\n",
              "      <td>-0.044736</td>\n",
              "      <td>-0.010036</td>\n",
              "      <td>-0.007820</td>\n",
              "      <td>-0.140440</td>\n",
              "      <td>-0.050214</td>\n",
              "      <td>-0.043478</td>\n",
              "      <td>-0.008144</td>\n",
              "      <td>-0.039516</td>\n",
              "      <td>0.010348</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>-0.083333</td>\n",
              "      <td>-0.044736</td>\n",
              "      <td>-0.010036</td>\n",
              "      <td>-0.029013</td>\n",
              "      <td>-0.136928</td>\n",
              "      <td>-0.050214</td>\n",
              "      <td>-0.043478</td>\n",
              "      <td>-0.008144</td>\n",
              "      <td>-0.039516</td>\n",
              "      <td>0.010348</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>152 rows Ã— 700 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33942750-1b83-4d88-b2b2-6cec03937f2f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-33942750-1b83-4d88-b2b2-6cec03937f2f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-33942750-1b83-4d88-b2b2-6cec03937f2f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "print('The features arranged in order of saliency are: \\n')\n",
        "features[saliency_order]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "74075456",
      "metadata": {
        "id": "74075456",
        "outputId": "d0da0e2a-4af9-4552-d7be-74ac4ee169fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "num_features = 100\n",
        "salient_features = features.iloc[:,saliency_order[0:num_features]]\n",
        "A = np.zeros((features.shape[0], features.shape[0]))\n",
        "for i in features.index:\n",
        "    for j in range(i):\n",
        "        A[i,j] = np.linalg.norm(salient_features.iloc[i,:] - salient_features.iloc[j,:])\n",
        "A = A + np.transpose(A)\n",
        "p = 1.3\n",
        "A = (A < p)\n",
        "A = A - np.eye(A.shape[0])\n",
        "rows, cols = np.where(A==1)\n",
        "edges = zip(rows.tolist(), cols.tolist())\n",
        "G = nx.Graph()\n",
        "G.add_edges_from(edges, node_size=1)\n",
        "color_map = np.array([])\n",
        "for node in G:\n",
        "    if (class_label[node]==0):\n",
        "        color_map = np.append(color_map, 'red')\n",
        "    elif (class_label[node]==1):\n",
        "        color_map = np.append(color_map, 'blue')\n",
        "    else:\n",
        "        color_map = np.append(color_map, 'yellow')\n",
        "nx.draw(G, node_color=color_map)\n",
        "plt.plot()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nx.is_connected(G) # tells whether or not the graph is connected\n",
        "nx.number_connected_components(G) # number of different connected components\n",
        "nx.density(G) # this tells how close the graph is to being fully connected\n",
        "# nx.clustering(G) # gives the clustering value of each vertex\n",
        "nx.average_clustering(G) # clustering value for the whole graph\n",
        "nx.transitivity(G) # 3* number of triangles in G/ number of connected triads in G"
      ],
      "metadata": {
        "id": "CZQuhjgE2J34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54328162-8f31-4914-8585-16b81e99fd56"
      },
      "id": "CZQuhjgE2J34",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7817564178204491"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "04de62bc",
      "metadata": {
        "id": "04de62bc",
        "outputId": "a0b4499c-2aac-47f3-f7cd-e092ca45edc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "giant_component = G.subgraph(max(nx.connected_components(G), key=len))\n",
        "color_map_GC = np.array([])\n",
        "for node in G:\n",
        "    if node in giant_component:\n",
        "        color_map_GC = np.append(color_map_GC, 'blue')\n",
        "    else:\n",
        "        color_map_GC = np.append(color_map_GC, 'red')\n",
        "nx.draw(G, node_color=color_map_GC)\n",
        "plt.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "1cf69a78",
      "metadata": {
        "id": "1cf69a78",
        "outputId": "013b24d5-5a37-4b9f-e1eb-227ac52807c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eccentricity of giant component: {0: 4, 1: 4, 2: 4, 4: 4, 5: 4, 6: 4, 7: 4, 8: 4, 9: 4, 10: 4, 11: 4, 12: 4, 13: 4, 14: 4, 15: 4, 16: 4, 17: 4, 18: 4, 20: 4, 21: 4, 22: 4, 23: 4, 24: 4, 25: 4, 26: 4, 27: 4, 28: 4, 29: 4, 30: 4, 31: 4, 32: 4, 33: 4, 34: 4, 35: 4, 36: 4, 37: 4, 38: 4, 39: 4, 43: 4, 46: 4, 47: 4, 50: 4, 51: 4, 53: 4, 54: 4, 55: 4, 56: 4, 57: 4, 58: 4, 59: 4, 60: 5, 61: 4, 62: 4, 63: 4, 64: 4, 65: 4, 66: 4, 67: 4, 72: 4, 76: 4, 77: 4, 78: 4, 81: 4, 89: 4, 92: 4, 102: 4, 116: 4, 122: 4, 123: 4, 124: 4, 125: 3, 126: 4, 127: 4, 128: 3, 132: 4, 136: 3, 137: 4, 138: 4, 139: 4, 140: 4, 141: 4, 142: 4, 143: 4, 144: 4, 145: 4, 146: 4, 147: 4, 148: 4, 149: 4, 151: 4, 75: 4, 129: 4, 3: 4, 41: 4, 42: 4, 52: 4, 90: 4, 96: 4, 97: 4, 113: 4, 150: 4, 40: 5, 74: 4, 69: 4, 133: 4, 68: 4, 87: 4, 99: 4, 100: 4, 73: 4, 101: 4, 19: 5, 88: 4, 115: 4, 80: 4, 91: 4, 95: 4, 121: 4, 82: 4, 83: 4, 108: 4, 109: 4, 118: 4, 131: 5, 49: 5, 86: 5, 48: 6, 105: 4, 98: 4, 120: 4, 70: 5, 71: 5, 119: 4, 130: 5, 106: 4, 103: 4, 110: 4, 111: 5, 84: 5, 85: 4, 112: 4, 114: 4, 117: 4, 93: 4, 104: 5, 134: 5, 135: 6}\n",
            "Diameter of giant component: 6\n",
            "Radius of giant component: 3\n",
            "Degree centrality: \n",
            "{0: 0.6013513513513514, 1: 0.5540540540540541, 2: 0.5743243243243243, 4: 0.5608108108108109, 5: 0.6891891891891893, 6: 0.6013513513513514, 7: 0.37162162162162166, 8: 0.6013513513513514, 9: 0.6959459459459459, 10: 0.722972972972973, 11: 0.7297297297297298, 12: 0.6216216216216217, 13: 0.5945945945945946, 14: 0.6824324324324325, 15: 0.7027027027027027, 16: 0.5472972972972974, 17: 0.5202702702702703, 18: 0.6081081081081081, 20: 0.5675675675675675, 21: 0.5945945945945946, 22: 0.6891891891891893, 23: 0.668918918918919, 24: 0.6621621621621622, 25: 0.6216216216216217, 26: 0.44594594594594594, 27: 0.6148648648648649, 28: 0.6081081081081081, 29: 0.6554054054054055, 30: 0.6891891891891893, 31: 0.5743243243243243, 32: 0.472972972972973, 33: 0.5540540540540541, 34: 0.6891891891891893, 35: 0.6418918918918919, 36: 0.5878378378378378, 37: 0.6486486486486487, 38: 0.6283783783783784, 39: 0.6013513513513514, 43: 0.6891891891891893, 46: 0.4256756756756757, 47: 0.6486486486486487, 50: 0.6418918918918919, 51: 0.6621621621621622, 53: 0.5675675675675675, 54: 0.6148648648648649, 55: 0.5067567567567568, 56: 0.5472972972972974, 57: 0.75, 58: 0.7162162162162162, 59: 0.6891891891891893, 60: 0.0945945945945946, 61: 0.5945945945945946, 62: 0.6081081081081081, 63: 0.45270270270270274, 64: 0.6486486486486487, 65: 0.6554054054054055, 66: 0.6824324324324325, 67: 0.5405405405405406, 72: 0.35135135135135137, 76: 0.7297297297297298, 77: 0.49324324324324326, 78: 0.6621621621621622, 81: 0.32432432432432434, 89: 0.6283783783783784, 92: 0.2702702702702703, 102: 0.26351351351351354, 116: 0.7770270270270271, 122: 0.27702702702702703, 123: 0.3310810810810811, 124: 0.7635135135135136, 125: 0.6216216216216217, 126: 0.5135135135135136, 127: 0.40540540540540543, 128: 0.75, 132: 0.45270270270270274, 136: 0.75, 137: 0.6959459459459459, 138: 0.5, 139: 0.5540540540540541, 140: 0.6486486486486487, 141: 0.6013513513513514, 142: 0.6959459459459459, 143: 0.6418918918918919, 144: 0.5270270270270271, 145: 0.3581081081081081, 146: 0.4256756756756757, 147: 0.41216216216216217, 148: 0.5472972972972974, 149: 0.5472972972972974, 151: 0.7094594594594595, 75: 0.44594594594594594, 129: 0.6081081081081081, 3: 0.47972972972972977, 41: 0.4864864864864865, 42: 0.43243243243243246, 52: 0.45270270270270274, 90: 0.32432432432432434, 96: 0.27702702702702703, 97: 0.5540540540540541, 113: 0.2972972972972973, 150: 0.5067567567567568, 40: 0.04054054054054054, 74: 0.38513513513513514, 69: 0.3310810810810811, 133: 0.24324324324324326, 68: 0.24324324324324326, 87: 0.3581081081081081, 99: 0.22972972972972974, 100: 0.4864864864864865, 73: 0.14864864864864866, 101: 0.22297297297297297, 19: 0.013513513513513514, 88: 0.10810810810810811, 115: 0.1891891891891892, 80: 0.12162162162162163, 91: 0.26351351351351354, 95: 0.3783783783783784, 121: 0.27702702702702703, 82: 0.2972972972972973, 83: 0.22972972972972974, 108: 0.13513513513513514, 109: 0.14189189189189189, 118: 0.19594594594594594, 131: 0.02027027027027027, 49: 0.013513513513513514, 86: 0.02027027027027027, 44: 0.006756756756756757, 45: 0.006756756756756757, 48: 0.006756756756756757, 105: 0.12162162162162163, 98: 0.08783783783783784, 120: 0.08108108108108109, 70: 0.013513513513513514, 71: 0.013513513513513514, 119: 0.14189189189189189, 130: 0.02027027027027027, 106: 0.06756756756756757, 103: 0.08783783783783784, 110: 0.14189189189189189, 111: 0.02027027027027027, 84: 0.0472972972972973, 85: 0.14189189189189189, 112: 0.11486486486486487, 114: 0.06756756756756757, 117: 0.05405405405405406, 93: 0.04054054054054054, 104: 0.04054054054054054, 134: 0.02027027027027027, 135: 0.006756756756756757}\n",
            "Maximum degree centrality: 151\n",
            "Degree histogram: [0, 4, 4, 5, 0, 0, 3, 1, 1, 0, 2, 0, 1, 2, 1, 0, 1, 1, 2, 0, 1, 4, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 2, 0, 2, 0, 0, 2, 1, 3, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 1, 2, 0, 1, 1, 1, 0, 0, 1, 1, 0, 2, 1, 0, 2, 3, 0, 0, 1, 1, 2, 1, 1, 2, 1, 1, 1, 0, 1, 4, 4, 1, 2, 2, 0, 1, 3, 5, 4, 2, 3, 2, 0, 3, 4, 2, 3, 1, 0, 2, 6, 3, 1, 1, 1, 1, 2, 0, 0, 3, 0, 1, 0, 1]\n",
            "Eigenvector centrality: \n",
            "{0: 0.10399529416073074, 1: 0.10027316969032603, 2: 0.10253307501054917, 4: 0.09969713093491674, 5: 0.11532900734072528, 6: 0.10433385602884915, 7: 0.06767772503255239, 8: 0.10575548654327538, 9: 0.11466672381765028, 10: 0.11612528582807861, 11: 0.11800201767929241, 12: 0.10802881426238929, 13: 0.10399292511775063, 14: 0.11459043971822387, 15: 0.11486326987759532, 16: 0.09930919008467745, 17: 0.09431976699603643, 18: 0.10612928450934155, 20: 0.10184898826594342, 21: 0.10529718049196427, 22: 0.11474097933254991, 23: 0.11277830599064713, 24: 0.11241413747507417, 25: 0.10715762194232367, 26: 0.08062053083019567, 27: 0.10471800405181701, 28: 0.10613077956132302, 29: 0.11112501915177837, 30: 0.1148989681812942, 31: 0.10072712068606095, 32: 0.0834057050883352, 33: 0.09755655656881716, 34: 0.11487162152349703, 35: 0.10989023573017151, 36: 0.09972196145190113, 37: 0.10952954670582986, 38: 0.10877353863470927, 39: 0.10569361162346487, 43: 0.11560247549653115, 46: 0.07834885531548658, 47: 0.10870615595811071, 50: 0.10921254140039756, 51: 0.11117827575574181, 53: 0.10057807066750833, 54: 0.10630342792468202, 55: 0.09279787001302518, 56: 0.09515764808521346, 57: 0.11848655269728077, 58: 0.11624454561897267, 59: 0.11441117793576099, 60: 0.018280430809858774, 61: 0.10449857118542169, 62: 0.10611283433146633, 63: 0.0811180155924144, 64: 0.10767394730497212, 65: 0.10928007424903001, 66: 0.11413744152904995, 67: 0.09665788655798313, 72: 0.06182875167404042, 76: 0.11570365734286557, 77: 0.08745675565754496, 78: 0.11264520828104745, 81: 0.047798125929504096, 89: 0.09336479436402813, 92: 0.038559990438606556, 102: 0.03585674240314164, 116: 0.11100056731077457, 122: 0.04894223282212536, 123: 0.06025377565213004, 124: 0.1180872004958688, 125: 0.10453536307528098, 126: 0.09012643239829624, 127: 0.06694709110370872, 128: 0.11581720704979799, 132: 0.07802441372820272, 136: 0.11585886490983836, 137: 0.11413199990070272, 138: 0.08935769421986327, 139: 0.0980660614244185, 140: 0.1103130069064543, 141: 0.1047943255582579, 142: 0.11502944626535949, 143: 0.1100228000328621, 144: 0.09005576339650072, 145: 0.06541362637961708, 146: 0.07404677074588623, 147: 0.07330547931580855, 148: 0.09841119735253767, 149: 0.08690440859061616, 151: 0.11566474462166135, 75: 0.08167502663292694, 129: 0.09375114199170446, 3: 0.08637704602060992, 41: 0.08822293582138041, 42: 0.07513582477374972, 52: 0.08172712640467861, 90: 0.05462196366692229, 96: 0.038569504133270455, 97: 0.07863177941225051, 113: 0.043739725010209424, 150: 0.08821800804767393, 40: 0.006885366942661831, 74: 0.060991420190171994, 69: 0.0576125388182513, 133: 0.04380505270281019, 68: 0.038321441169479734, 87: 0.056600090842569506, 99: 0.03290819382933515, 100: 0.06531705198454713, 73: 0.02596141064417814, 101: 0.03243240105383022, 19: 0.001770334814807857, 88: 0.013664697353984038, 115: 0.019758444780924513, 80: 0.013464092043009798, 91: 0.03424640608262293, 95: 0.04979950415565141, 121: 0.032713375793797725, 82: 0.033048627902030586, 83: 0.028151738004295337, 108: 0.018559584263717455, 109: 0.014177881217620331, 118: 0.01875496932425954, 131: 0.003304742076471983, 49: 0.001160870467636078, 86: 0.0021720046887323528, 44: 8.931200468454124e-15, 45: 8.931200468454124e-15, 48: 1.3811236135515798e-05, 105: 0.01083032209365568, 98: 0.005438435666031729, 120: 0.007457053339087851, 70: 0.0004614453478114976, 71: 0.0004614453478114976, 119: 0.011280170840668265, 130: 0.0026476398526563533, 106: 0.006143056553466146, 103: 0.007768270401089526, 110: 0.012594170853420171, 111: 0.0018300721627577054, 84: 0.003376017660087617, 85: 0.013447222992055776, 112: 0.008651194273276335, 114: 0.0067715836623502635, 117: 0.006058198227622341, 93: 0.0039006820222605245, 104: 0.001254854489051036, 134: 0.00016768823263539365, 135: 1.9965297605278267e-06}\n",
            "Maximum eigenvector centrality: 151\n",
            "Closeness centrality: \n",
            "{0: 0.6825925451517869, 1: 0.6637190185577282, 2: 0.6698931489629164, 4: 0.6637190185577282, 5: 0.7386001386001386, 6: 0.6858429858429859, 7: 0.5715358215358216, 8: 0.6858429858429859, 9: 0.7424073558094176, 10: 0.7540682043299844, 11: 0.7661012075905693, 12: 0.6924376299376299, 13: 0.6858429858429859, 14: 0.7348317705460563, 15: 0.7501407657657657, 16: 0.6576576576576576, 17: 0.6401201201201201, 18: 0.6891245312297943, 20: 0.6637190185577282, 21: 0.6793727689954104, 22: 0.7386001386001386, 23: 0.7274092274092274, 24: 0.7165523732687912, 25: 0.6991603253739176, 26: 0.6102840128263858, 27: 0.6924376299376299, 28: 0.6891245312297943, 29: 0.7201351351351352, 30: 0.7386001386001386, 31: 0.6698931489629164, 32: 0.6208061509785647, 33: 0.6606744359037937, 34: 0.7348317705460563, 35: 0.7060148383677796, 36: 0.6761832254790001, 37: 0.7094927439755027, 38: 0.6991603253739176, 39: 0.6891245312297943, 43: 0.7386001386001386, 46: 0.6026235440461383, 47: 0.7094927439755027, 50: 0.7025708635464732, 51: 0.7274092274092274, 53: 0.6606744359037937, 54: 0.6924376299376299, 55: 0.6372877302080842, 56: 0.6637190185577282, 57: 0.7785244704163624, 58: 0.7580369843527738, 59: 0.7424073558094176, 60: 0.4676202176202176, 61: 0.6825925451517869, 62: 0.6957827392610002, 63: 0.6155001155001155, 64: 0.713005084292213, 65: 0.7201351351351352, 66: 0.7348317705460563, 67: 0.6546683046683047, 72: 0.5715358215358216, 76: 0.7661012075905693, 77: 0.6262044653349002, 78: 0.7237539046584273, 81: 0.5648118706942236, 89: 0.6991603253739176, 92: 0.5434982151963285, 102: 0.5455569205569205, 116: 0.7743388549840162, 122: 0.5497214772023933, 123: 0.5670355394764843, 124: 0.7870329345739182, 125: 0.7060148383677796, 126: 0.6458611077445159, 127: 0.5927038149260372, 128: 0.7785244704163624, 132: 0.6102840128263858, 136: 0.7870329345739182, 137: 0.7386001386001386, 138: 0.6344802952732468, 139: 0.6546683046683047, 140: 0.7094927439755027, 141: 0.6793727689954104, 142: 0.7386001386001386, 143: 0.7094927439755027, 144: 0.6517060046471811, 145: 0.5784217952892652, 146: 0.6102840128263858, 147: 0.6001126126126126, 148: 0.6606744359037937, 149: 0.6517060046471811, 151: 0.7462540260467722, 75: 0.6077089747975825, 129: 0.6891245312297943, 3: 0.6181417468971118, 41: 0.6234936234936236, 42: 0.6128809660724555, 52: 0.6155001155001155, 90: 0.5604164475759806, 96: 0.553950103950104, 97: 0.6667917917917918, 113: 0.5648118706942236, 150: 0.6344802952732468, 40: 0.44728890381064296, 74: 0.5902747009304387, 69: 0.5738128566813826, 133: 0.5374142799515934, 68: 0.5394270675169551, 87: 0.5738128566813826, 99: 0.5354164573495428, 100: 0.6344802952732468, 73: 0.5035910035910036, 101: 0.5295111287758346, 19: 0.3861314397507427, 88: 0.49664492078285183, 115: 0.5199531661625525, 80: 0.5018363311046239, 91: 0.5518276897587242, 95: 0.5927038149260372, 121: 0.5604164475759806, 82: 0.5582442908024303, 83: 0.5334334334334334, 108: 0.49664492078285183, 109: 0.5035910035910036, 118: 0.5334334334334334, 131: 0.4351269698701723, 49: 0.398966833869881, 86: 0.4236089030206677, 44: 0.006756756756756757, 45: 0.006756756756756757, 48: 0.2846383933340455, 105: 0.5071374191092501, 98: 0.4849394849394849, 120: 0.4865777940102265, 70: 0.35043072269349645, 71: 0.35043072269349645, 119: 0.5162259033226776, 130: 0.4236089030206677, 106: 0.4849394849394849, 103: 0.4898878470307042, 110: 0.5071374191092501, 111: 0.40570993528740007, 84: 0.43644553644553646, 85: 0.5125516976050783, 112: 0.5018363311046239, 114: 0.4769106855199571, 117: 0.4753367228614753, 93: 0.47377311522048365, 104: 0.38509900274606157, 134: 0.3396863844977052, 135: 0.2531230703462689}\n",
            "Maximum closeness centrality: 151\n",
            "Betweeness centrality: \n",
            "{0: 0.0023004922452970486, 1: 0.0006537554284696073, 2: 0.0011034246534354008, 4: 0.0010054853928578536, 5: 0.00412770793598677, 6: 0.0021135744800236424, 7: 0.005433480382531329, 8: 0.0015869005970440356, 9: 0.006891001293093433, 10: 0.007629820469501194, 11: 0.006703083488959788, 12: 0.0022340069586780894, 13: 0.0024197281666064646, 14: 0.004255583240563602, 15: 0.006525396810234843, 16: 0.0005637570245037261, 17: 0.0005010920241150709, 18: 0.0018795625132305635, 20: 0.0008183788782490483, 21: 0.001200606759810871, 22: 0.005033359994569737, 23: 0.004581077068187853, 24: 0.0030876018578900118, 25: 0.0026743457740578823, 26: 0.0007479531449538119, 27: 0.003331594670341743, 28: 0.0024119406004288624, 29: 0.0037939794076632502, 30: 0.005049330828835528, 31: 0.005748128502036099, 32: 0.001111545699450604, 33: 0.027380613612171416, 34: 0.004387588102838487, 35: 0.002823724361368913, 36: 0.0031315139105470837, 37: 0.003387182774100518, 38: 0.0022489000325390564, 39: 0.0016316165994503095, 43: 0.0040025424027929, 46: 0.0003597018762264663, 47: 0.0038410396240908355, 50: 0.0028247044867789387, 51: 0.005403532192914609, 53: 0.001275407409279247, 54: 0.002591342920313469, 55: 0.00040301832295348817, 56: 0.004336031308140074, 57: 0.010254697987840547, 58: 0.007559939827720554, 59: 0.004917394587087796, 60: 0.0, 61: 0.0017890191147257868, 62: 0.0023198542842302067, 63: 0.008245750125307327, 64: 0.004596100485322315, 65: 0.0049675936554332886, 66: 0.0069087560590269294, 67: 0.002327389158813224, 72: 0.0030076483705393825, 76: 0.014617845378828079, 77: 0.008330329777973607, 78: 0.005383191193639232, 81: 0.006865024603358517, 89: 0.0166047797750648, 92: 0.0016986639939539883, 102: 0.002669279808204736, 116: 0.03289136742957452, 122: 0.0007990635643705802, 123: 0.00010215608813350234, 124: 0.0169245160939783, 125: 0.007678796094562118, 126: 0.004571275316318827, 127: 0.007554749347856976, 128: 0.02777334384340161, 132: 0.001666266170552605, 136: 0.021929957385008404, 137: 0.005407777907806258, 138: 0.0012219553834003517, 139: 0.0014243959961792564, 140: 0.003932628572089701, 141: 0.002004495318418667, 142: 0.00454863635575722, 143: 0.002891508933170324, 144: 0.0030961868907698844, 145: 0.00041454960615574897, 146: 0.0013883287723026993, 147: 0.0004679372700336988, 148: 0.0012047360866014496, 149: 0.01316674600866672, 151: 0.006869463562494926, 75: 0.0006601458479726832, 129: 0.02516220221908902, 3: 0.0018292288519113542, 41: 0.0005034502813020982, 42: 0.0071840716461991925, 52: 0.0036635365268511294, 90: 0.0006541738259755341, 96: 0.0031592877787669483, 97: 0.016167583995603398, 113: 0.0035791699398097943, 150: 0.0022345358307923643, 40: 0.0, 74: 0.0038061486053728934, 69: 0.0012130807498063497, 133: 0.0004032244085184057, 68: 0.027098750963420074, 87: 0.0017438527292578648, 99: 0.0012590882406951101, 100: 0.013838520128398151, 73: 2.6006141308760355e-05, 101: 0.001034478349525078, 19: 0.0, 88: 0.0013485690425833563, 115: 0.001743698254887756, 80: 0.00028224129097214896, 91: 0.0034857031844703597, 95: 0.016795119300673022, 121: 0.00423951018501092, 82: 0.007104662689048363, 83: 0.0027511619031226108, 108: 0.0018184801681169966, 109: 0.0012224767120454815, 118: 0.004933514127894677, 131: 2.1289335423477146e-06, 49: 0.013329656186799044, 86: 0.0, 44: 0.0, 45: 0.0, 48: 0.0, 105: 0.0016538286776102747, 98: 0.009980510706919283, 120: 0.00016510429905752593, 70: 0.0, 71: 0.0, 119: 0.0026534403426248156, 130: 0.0, 106: 0.0005580650174359076, 103: 0.00012284017797513518, 110: 0.0009215374593712354, 111: 0.0, 84: 0.00011797118260885597, 85: 0.001371219215779674, 112: 0.017595429895131867, 114: 2.8493906044926463e-05, 117: 4.5964331678617394e-06, 93: 1.0214295928581643e-05, 104: 4.6839842758210104e-05, 134: 0.013329656186799042, 135: 0.0}\n",
            "Maximum betweeness centrality: 151\n"
          ]
        }
      ],
      "source": [
        "print(f'Eccentricity of giant component: {nx.eccentricity(giant_component)}') # largest possible shortest path distance between a vertex and all other vertices\n",
        "print(f'Diameter of giant component: {nx.diameter(giant_component)}') # maximum shortest distance between a pair of vertices in G, it is the largest possible eccentricity value of a vertex\n",
        "print(f'Radius of giant component: {nx.radius(giant_component)}') #  minimum eccentricity value of a vertex\n",
        "\n",
        "print(f'Degree centrality: \\n{nx.degree_centrality(G)}') # number of edges incident upon a vertex\n",
        "print(f'Maximum degree centrality: {max(nx.degree_centrality(G))}')\n",
        "print(f'Degree histogram: {nx.degree_histogram(G)}')\n",
        "\n",
        "# below gives us the different centrality measures for the vertices of the graphs\n",
        "print(f'Eigenvector centrality: \\n{nx.eigenvector_centrality(G)}')\n",
        "print(f'Maximum eigenvector centrality: {max(nx.eigenvector_centrality(G))}')\n",
        "print(f'Closeness centrality: \\n{nx.closeness_centrality(G)}')\n",
        "print(f'Maximum closeness centrality: {max(nx.closeness_centrality(G))}')\n",
        "print(f'Betweeness centrality: \\n{nx.betweenness_centrality(G)}')\n",
        "print(f'Maximum betweeness centrality: {max(nx.betweenness_centrality(G))}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "a21a45c5",
      "metadata": {
        "id": "a21a45c5",
        "outputId": "253ba25f-aadb-4aa9-8663-76f0f877bb5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***KMEANS for 3 clusters***\n",
            "Number of Iterations:  7\n",
            "Cluster Centers:  [[ 1.38888889e-01 -2.00401437e-02 -1.72608889e-02 -5.03328904e-03\n",
            "   1.82368400e-02 -1.89933817e-02 -1.89708224e-02 -8.14373591e-03\n",
            "  -1.95993787e-02  1.60832899e-02 -1.62825961e-01  4.21324344e-03\n",
            "  -3.15710220e-02 -1.61973382e-03 -2.35679472e-02 -2.59257662e-03\n",
            "   7.88215285e-03 -2.51576706e-02  1.27651587e-02 -4.35455305e-03\n",
            "   8.46946364e-02 -3.83832946e-02 -1.34866726e-02 -2.12096910e-02\n",
            "   5.96966873e-02  1.15021269e-01 -4.02382102e-02  3.67013488e-02\n",
            "  -1.69982631e-02  2.33057241e-02  1.01653679e-01 -1.75302355e-02\n",
            "   6.36539239e-02  9.00936049e-02  2.65141030e-03 -1.38758305e-02\n",
            "  -6.91362454e-03 -9.26836411e-02 -2.07387588e-02 -3.26810531e-02\n",
            "  -7.26592878e-02 -1.74832040e-01 -2.14162078e-01 -1.57683639e-01\n",
            "  -2.74505264e-02  7.35844657e-03 -2.13465867e-02 -1.35039620e-01\n",
            "  -2.56053950e-02  3.65670993e-03 -1.51412096e-01  1.31433527e-01\n",
            "   2.86271820e-02 -1.67245359e-03 -2.25154316e-02  2.37684017e-02\n",
            "  -6.33080720e-02  1.63338768e-01  1.10643646e-01 -1.77321688e-02\n",
            "   1.62212528e-01  8.83294914e-03 -3.92385497e-02  1.97430537e-02\n",
            "   5.22415685e-03 -7.53450841e-02  1.14498206e-01  9.24199430e-02\n",
            "   1.35762266e-02 -2.62089955e-02 -2.98352125e-02 -5.21721453e-02\n",
            "   1.33230203e-01 -1.66277447e-01 -1.60461077e-01  4.33691243e-02\n",
            "  -3.91058450e-02 -8.07145968e-02 -1.35299982e-01 -4.04464921e-02\n",
            "  -1.00111701e-02  1.35430666e-01  1.39493650e-02 -1.37479165e-02\n",
            "  -1.27021749e-02 -2.30624595e-01 -5.26648584e-02 -5.75753728e-02\n",
            "   1.22514440e-01  1.59244969e-02 -1.75154846e-02 -3.30465768e-02\n",
            "  -3.18455122e-02  1.43019187e-01  1.50123961e-01 -1.24879755e-01\n",
            "   4.71096153e-02 -1.27853835e-02  4.18836289e-02  7.48673459e-02]\n",
            " [-3.87037037e-01 -1.23890040e-02 -6.46824385e-03  1.62434544e-02\n",
            "   5.52323780e-02 -1.09646473e-02 -1.21029405e-02 -8.14373591e-03\n",
            "  -9.44658583e-03 -9.86885167e-04 -5.49013465e-04 -5.47752368e-03\n",
            "  -2.20364605e-02 -5.05702287e-03 -8.45120006e-03 -3.14728285e-02\n",
            "  -1.08235013e-04 -5.60738236e-03 -5.74363592e-04 -1.62104193e-02\n",
            "  -3.15503460e-03 -1.40785753e-02 -2.76803872e-02 -1.08556567e-02\n",
            "   3.32485020e-02 -4.56712812e-02 -7.55083427e-02 -1.46792426e-02\n",
            "  -1.21450322e-02 -6.47322758e-02 -4.84599437e-02 -9.65569528e-03\n",
            "   8.87892973e-02  7.05650502e-02 -5.26740419e-03 -5.90061009e-03\n",
            "  -1.97463719e-02 -2.49817229e-02 -1.20591404e-02  7.67666120e-03\n",
            "  -1.14388976e-01  1.01517934e-02 -5.45452107e-02  4.13872605e-03\n",
            "   4.49754871e-02  9.61734111e-02 -8.49338931e-03 -1.00002446e-01\n",
            "   4.50020427e-02  2.78781060e-02  4.59953941e-04  6.34499311e-02\n",
            "   1.55985769e-02  7.84595629e-02 -9.89158220e-03 -3.31528826e-02\n",
            "  -1.17836674e-02 -6.54451195e-02  5.63684817e-02  4.44716081e-02\n",
            "  -5.57720305e-02 -2.17101766e-03 -1.77829317e-02  6.07674376e-03\n",
            "  -2.31038221e-03 -3.27215257e-02  6.17308582e-02 -6.20791010e-02\n",
            "  -6.05362596e-02  2.69849920e-02  2.42126381e-03  1.30756532e-01\n",
            "   1.24200676e-02 -1.23964165e-04 -1.13338416e-01  2.48237136e-02\n",
            "  -1.09035807e-02 -7.23517592e-03 -1.64217088e-03  2.84688772e-02\n",
            "  -1.76366324e-02 -1.19327197e-02  2.35010087e-04 -6.92469783e-03\n",
            "  -7.94099599e-03  1.53946779e-02  2.85938183e-02 -1.28906567e-01\n",
            "  -3.68446070e-02  4.36187680e-03 -2.72813503e-02 -1.07108873e-02\n",
            "  -2.03728030e-03  7.34963913e-02 -6.80978971e-04 -5.68490866e-03\n",
            "  -1.01867392e-02 -7.19508483e-03  1.87425661e-02 -5.88851324e-02]\n",
            " [ 1.65789474e-01  8.39986214e-03  5.24422779e-03 -7.05848401e-03\n",
            "  -2.84663062e-02  7.59294430e-03  8.12928622e-03  4.88624155e-03\n",
            "   6.95040954e-03 -1.56410154e-03  2.08275489e-02  2.06241731e-03\n",
            "   1.44262420e-02  2.60002984e-03  6.98020389e-03  1.52356653e-02\n",
            "  -9.44371144e-04  5.83393951e-03 -1.34037413e-03  8.22866846e-03\n",
            "  -9.20377979e-03  1.15172150e-02  1.48153421e-02  7.82127204e-03\n",
            "  -2.32899246e-02  7.10476238e-03  4.08498310e-02  2.31736561e-03\n",
            "   7.90005903e-03  2.77187760e-02  1.01142455e-02  6.78809593e-03\n",
            "  -5.00985839e-02 -4.48057949e-02  2.16017121e-03  4.54776232e-03\n",
            "   1.02268445e-02  2.35408550e-02  8.33185712e-03  4.91819819e-04\n",
            "   6.33622669e-02  1.72753029e-02  5.28892571e-02  1.79574842e-02\n",
            "  -1.78367432e-02 -4.64853143e-02  6.71959536e-03  6.44272158e-02\n",
            "  -1.80823914e-02 -1.36673189e-02  1.89078655e-02 -4.66573602e-02\n",
            "  -1.10048647e-02 -3.69537988e-02  7.52954082e-03  1.27016726e-02\n",
            "   1.35785463e-02  1.03680544e-02 -4.06768992e-02 -1.88256457e-02\n",
            "   5.92832665e-03 -8.73641594e-05  1.33799424e-02 -5.37231699e-03\n",
            "   4.34498076e-04  2.50169438e-02 -4.37038641e-02  1.77317919e-02\n",
            "   2.69601786e-02 -9.47175467e-03  2.62174398e-03 -5.53471388e-02\n",
            "  -2.27122682e-02  2.10621869e-02  7.39553858e-02 -1.72368064e-02\n",
            "   1.01045397e-02  1.36227166e-02  1.78683944e-02 -8.37622703e-03\n",
            "   9.61876314e-03 -1.14546905e-02 -1.87334562e-03  5.01669895e-03\n",
            "   5.36600966e-03  2.18393119e-02 -6.89203706e-03  6.83336842e-02\n",
            "   1.97720038e-03 -4.07766757e-03  1.51352272e-02  9.24788263e-03\n",
            "   4.98761852e-03 -5.28796617e-02 -1.86404576e-02  1.84671363e-02\n",
            "  -1.12539072e-03  5.02319388e-03 -1.41686213e-02  1.84360295e-02]]\n",
            "Inertia:  129.10172501533197\n"
          ]
        }
      ],
      "source": [
        "kmeans = KMeans(n_clusters=3)\n",
        "kmeans.fit(salient_features)\n",
        "print('***KMEANS for 3 clusters***')\n",
        "print('Number of Iterations: ', kmeans.n_iter_)\n",
        "print('Cluster Centers: ', kmeans.cluster_centers_)\n",
        "print('Inertia: ', kmeans.inertia_) # SSE\n",
        "predicted_label = kmeans.labels_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "19f946f0",
      "metadata": {
        "id": "19f946f0",
        "outputId": "9db6dd0f-2426-4f4e-bc5f-5d3fc5be2f19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KMeans accuracy for 3 classes:  0.7697368421052632\n"
          ]
        }
      ],
      "source": [
        "compared_classes = np.array([])\n",
        "for i in classes.iterrows():\n",
        "    if i[1]['adenoma']==1:\n",
        "        compared_classes = np.append(compared_classes, 2)\n",
        "    elif i[1]['hyperplasic']==1:\n",
        "        compared_classes = np.append(compared_classes, 1)\n",
        "    else:\n",
        "        compared_classes = np.append(compared_classes, 0)\n",
        "print('KMeans accuracy for 3 classes: ', np.count_nonzero(compared_classes==predicted_label)/len(predicted_label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "d5069e44",
      "metadata": {
        "id": "d5069e44",
        "outputId": "2f514b2d-4860-40ee-b0b1-184b38e4fa57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***KMEANS for 2 clusters***\n",
            "Number of Iterations:  6\n",
            "Cluster Centers:  [[ 1.71146953e-01  8.31561889e-03  5.07989477e-03 -6.50461932e-03\n",
            "  -3.07950831e-02  7.46112803e-03  7.84496021e-03  5.16645612e-03\n",
            "   6.97391247e-03 -1.50729272e-03  1.96626853e-02  2.45732251e-03\n",
            "   1.54154304e-02  2.60164351e-03  7.21372855e-03  1.51746395e-02\n",
            "  -1.18132244e-03  6.50043810e-03 -1.31329659e-03  9.08122931e-03\n",
            "  -8.81942600e-03  1.08002731e-02  1.47121275e-02  7.59645047e-03\n",
            "  -2.41408323e-02  4.96117100e-03  4.16400575e-02  1.47456863e-02\n",
            "   7.71250137e-03  3.03747461e-02  1.47182692e-02  6.19741571e-03\n",
            "  -5.43718222e-02 -5.30362443e-02  2.37835161e-03  4.24471363e-03\n",
            "   1.07808560e-02  2.33027633e-02  8.07875188e-03  1.26322325e-03\n",
            "   6.63375032e-02  1.62359862e-02  5.46211405e-02  1.70047404e-02\n",
            "  -1.72746753e-02 -5.03438819e-02  6.67727034e-03  6.35103656e-02\n",
            "  -1.75696006e-02 -1.39792976e-02  1.76823956e-02 -4.66745074e-02\n",
            "  -1.00817523e-02 -3.87035500e-02  7.20187029e-03  1.27684277e-02\n",
            "   1.32948467e-02  1.30035149e-02 -4.15444563e-02 -1.89366217e-02\n",
            "   3.79668278e-03 -8.65976427e-05  1.93826074e-02 -5.34220905e-03\n",
            "   6.18206003e-04  2.49281494e-02 -4.59400586e-02  2.22011642e-02\n",
            "   3.03121356e-02 -9.63824221e-03  2.42666714e-03 -5.51639073e-02\n",
            "  -2.59345541e-02  1.94223814e-02  7.19983600e-02 -1.69841593e-02\n",
            "   9.82998444e-03  1.26699012e-02  1.73278536e-02 -8.97940623e-03\n",
            "   8.10506174e-03 -1.43161940e-02 -1.83526465e-03  5.00909120e-03\n",
            "   5.48278085e-03  1.88622348e-02 -7.24286524e-03  6.99620600e-02\n",
            "   4.85505146e-03 -4.02946424e-03  1.54431940e-02  8.77426499e-03\n",
            "   4.83120613e-03 -5.48163122e-02 -2.05585840e-02  1.76937698e-02\n",
            "  -3.95964166e-03  5.04615004e-03 -1.74632622e-02  1.95725841e-02]\n",
            " [-2.69774011e-01 -1.31076704e-02 -8.00729176e-03  1.02530440e-02\n",
            "   4.85414022e-02 -1.17607611e-02 -1.23657847e-02 -8.14373591e-03\n",
            "  -1.09927773e-02  2.37590208e-03 -3.09937243e-02 -3.87340667e-03\n",
            "  -2.42988988e-02 -4.10089571e-03 -1.13707925e-02 -2.39193470e-02\n",
            "   1.86208453e-03 -1.02464533e-02  2.07011158e-03 -1.43144801e-02\n",
            "   1.39018071e-02 -1.70241592e-02 -2.31903026e-02 -1.19740660e-02\n",
            "   3.80524983e-02 -7.82015089e-03 -6.56360229e-02 -2.32432005e-02\n",
            "  -1.21569937e-02 -4.78788370e-02 -2.31999837e-02 -9.76880781e-03\n",
            "   8.57047367e-02  8.35995037e-02 -3.74892711e-03 -6.69081979e-03\n",
            "  -1.69935527e-02 -3.67314743e-02 -1.27343038e-02 -1.99118241e-03\n",
            "  -1.04565895e-01 -2.55923172e-02 -8.60977300e-02 -2.68040824e-02\n",
            "   2.72295729e-02  7.93556105e-02 -1.05251888e-02 -1.00109559e-01\n",
            "   2.76944552e-02  2.20351640e-02 -2.78722506e-02  7.35716812e-02\n",
            "   1.58915756e-02  6.10072907e-02 -1.13521006e-02 -2.01265046e-02\n",
            "  -2.09562838e-02 -2.04970658e-02  6.54853294e-02  2.98492511e-02\n",
            "  -5.98460166e-03  1.36501369e-04 -3.05522455e-02  8.42077020e-03\n",
            "  -9.74460310e-04 -3.92935236e-02  7.24139907e-02 -3.49950554e-02\n",
            "  -4.77801459e-02  1.51924835e-02 -3.82508549e-03  8.69532776e-02\n",
            "   4.08798904e-02 -3.06149401e-02 -1.13488940e-01  2.67716409e-02\n",
            "  -1.54947212e-02 -1.99712003e-02 -2.73133964e-02  1.41539793e-02\n",
            "  -1.27757753e-02  2.25662041e-02  2.89287479e-03 -7.89568613e-03\n",
            "  -8.64234948e-03 -2.97319972e-02  1.14167198e-02 -1.10279179e-01\n",
            "  -7.65287773e-03  6.35152839e-03 -2.43426618e-02 -1.38306211e-02\n",
            "  -7.61529101e-03  8.64053735e-02  3.24059036e-02 -2.78901795e-02\n",
            "   6.24146906e-03 -7.95410091e-03  2.75268370e-02 -3.08517004e-02]]\n",
            "Inertia:  138.07645958174118\n"
          ]
        }
      ],
      "source": [
        "kmeans = KMeans(n_clusters=2)\n",
        "kmeans.fit(salient_features)\n",
        "print('***KMEANS for 2 clusters***')\n",
        "print('Number of Iterations: ', kmeans.n_iter_)\n",
        "print('Cluster Centers: ', kmeans.cluster_centers_)\n",
        "print('Inertia: ', kmeans.inertia_) # SSE\n",
        "predicted_label = kmeans.labels_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "4bd2148b",
      "metadata": {
        "id": "4bd2148b",
        "outputId": "908b11b8-1458-4b6b-9a5f-82e5f884e488",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KMeans accuracy for 2 classes:  0.8881578947368421\n"
          ]
        }
      ],
      "source": [
        "compared_classes = np.array([])\n",
        "for i in classes.iterrows():\n",
        "    if i[1]['adenoma']==1:\n",
        "        compared_classes = np.append(compared_classes, 0)\n",
        "    elif i[1]['hyperplasic']==1:\n",
        "        compared_classes = np.append(compared_classes, 1)\n",
        "    else:\n",
        "        compared_classes = np.append(compared_classes, 0)\n",
        "print('KMeans accuracy for 2 classes: ', np.count_nonzero(compared_classes==predicted_label)/len(predicted_label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "2c92d9eb",
      "metadata": {
        "id": "2c92d9eb",
        "outputId": "8a08a7ef-3594-4a8e-d56f-31bd9a56a886",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "color_map_cluster = np.array([])\n",
        "for node in G:\n",
        "    if (predicted_label[node]==0):\n",
        "        color_map_cluster = np.append(color_map_cluster, 'red')\n",
        "    elif (predicted_label[node]==1):\n",
        "        color_map_cluster = np.append(color_map_cluster, 'blue')\n",
        "    else:\n",
        "        color_map_cluster = np.append(color_map_cluster, 'yellow')\n",
        "nx.draw(G, node_color=color_map_cluster)\n",
        "plt.plot()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "MLPColonoscopy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}