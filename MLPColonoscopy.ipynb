{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "6ef3116e",
      "metadata": {
        "id": "6ef3116e"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from IPython.utils import io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import InputLayer\n",
        "from tensorflow.keras.layers import Activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "b2a82fc2",
      "metadata": {
        "id": "b2a82fc2"
      },
      "outputs": [],
      "source": [
        "features = pd.read_csv('gastrointestinal_colonoscopy_lesions_dataset.csv')\n",
        "features = features.T\n",
        "class_label = pd.Series(features.index)\n",
        "features.index = range(features.shape[0])\n",
        "classes = np.zeros((features.shape[0], 3))\n",
        "for i in range(classes.shape[0]):\n",
        "    if 'adenoma' in class_label[i]:\n",
        "        classes[i,0] = 1.0\n",
        "        class_label[i] = 0\n",
        "    elif 'serrated' in class_label[i]:\n",
        "        classes[i,2] = 1.0\n",
        "        class_label[i] = 2\n",
        "    else:\n",
        "        classes[i,1] = 1.0\n",
        "        class_label[i] = 1\n",
        "classes = {'adenoma': classes[:,0], 'hyperplasic': classes[:,1], 'serrated': classes[:,2]}\n",
        "classes = pd.DataFrame(classes)\n",
        "class_label = class_label.astype('int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "9d3a520d",
      "metadata": {
        "id": "9d3a520d",
        "outputId": "5b510f79-c4ad-403d-fbdf-9c8112630a41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0     1         2         3         4         5         6    \\\n",
              "0    0.250000 -0.25  0.048325 -0.005553 -0.056058 -0.084224 -0.037834   \n",
              "1    0.250000  0.25 -0.001203  0.367137 -0.084265 -0.100569  0.018451   \n",
              "2    0.250000  0.25 -0.233810  0.046065  0.024136  0.032700 -0.031101   \n",
              "3    0.250000 -0.25 -0.182565  0.057049 -0.031463 -0.025114 -0.050518   \n",
              "4    0.250000  0.25 -0.107936 -0.094438  0.092679  0.038768  0.186656   \n",
              "..        ...   ...       ...       ...       ...       ...       ...   \n",
              "147 -0.083333  0.25  0.040649 -0.066683 -0.185786 -0.250955 -0.163660   \n",
              "148 -0.083333  0.25 -0.153445  0.092191 -0.010435 -0.057762 -0.097339   \n",
              "149 -0.083333 -0.25  0.144594  0.231284 -0.043448 -0.041229 -0.173962   \n",
              "150 -0.083333 -0.25 -0.169496 -0.098815 -0.207792 -0.250433 -0.221289   \n",
              "151 -0.083333  0.25 -0.159845  0.127796  0.027929  0.123740 -0.062721   \n",
              "\n",
              "          7         8         9    ...       690       691       692  \\\n",
              "0   -0.031987 -0.101462 -0.050684  ...  0.397177  0.392793  0.388256   \n",
              "1    0.046227 -0.101911 -0.038210  ...  0.397177  0.392793  0.388256   \n",
              "2   -0.036372 -0.169688 -0.154002  ...  0.060715  0.057743  0.055493   \n",
              "3   -0.035422 -0.067798 -0.052955  ...  0.060715  0.057743  0.055493   \n",
              "4    0.125008  0.095410  0.078630  ... -0.054256 -0.053808 -0.052869   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "147 -0.173238 -0.232896 -0.223542  ... -0.054095 -0.053643 -0.052701   \n",
              "148 -0.111005 -0.120050  0.000883  ... -0.043740 -0.044039 -0.043146   \n",
              "149 -0.202734 -0.153664 -0.000519  ... -0.043740 -0.044039 -0.043146   \n",
              "150 -0.226000  0.073333  0.138157  ... -0.053643 -0.053247 -0.052332   \n",
              "151 -0.072166  0.041411  0.038973  ... -0.053643 -0.053247 -0.052332   \n",
              "\n",
              "          693       694       695       696       697       698       699  \n",
              "0    0.383761  0.384351  0.383117  0.379185  0.365162  0.365579  0.375950  \n",
              "1    0.383761  0.384351  0.383117  0.379185  0.365162  0.365579  0.375950  \n",
              "2    0.056890  0.052044  0.053244  0.052057  0.045743  0.046962  0.047065  \n",
              "3    0.056890  0.052044  0.053244  0.052057  0.045743  0.046962  0.047065  \n",
              "4   -0.052718 -0.051934 -0.051097 -0.050394 -0.050345 -0.049870 -0.049726  \n",
              "..        ...       ...       ...       ...       ...       ...       ...  \n",
              "147 -0.052581 -0.051796 -0.050957 -0.050288 -0.050236 -0.049758 -0.049611  \n",
              "148 -0.043641 -0.042803 -0.042638 -0.042785 -0.042676 -0.042227 -0.042307  \n",
              "149 -0.043641 -0.042803 -0.042638 -0.042785 -0.042676 -0.042227 -0.042307  \n",
              "150 -0.052204 -0.051450 -0.050608 -0.049938 -0.049907 -0.049461 -0.049344  \n",
              "151 -0.052204 -0.051450 -0.050608 -0.049938 -0.049907 -0.049461 -0.049344  \n",
              "\n",
              "[152 rows x 700 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1236dc47-a8cb-4833-812e-ac84d84c0501\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>690</th>\n",
              "      <th>691</th>\n",
              "      <th>692</th>\n",
              "      <th>693</th>\n",
              "      <th>694</th>\n",
              "      <th>695</th>\n",
              "      <th>696</th>\n",
              "      <th>697</th>\n",
              "      <th>698</th>\n",
              "      <th>699</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>0.048325</td>\n",
              "      <td>-0.005553</td>\n",
              "      <td>-0.056058</td>\n",
              "      <td>-0.084224</td>\n",
              "      <td>-0.037834</td>\n",
              "      <td>-0.031987</td>\n",
              "      <td>-0.101462</td>\n",
              "      <td>-0.050684</td>\n",
              "      <td>...</td>\n",
              "      <td>0.397177</td>\n",
              "      <td>0.392793</td>\n",
              "      <td>0.388256</td>\n",
              "      <td>0.383761</td>\n",
              "      <td>0.384351</td>\n",
              "      <td>0.383117</td>\n",
              "      <td>0.379185</td>\n",
              "      <td>0.365162</td>\n",
              "      <td>0.365579</td>\n",
              "      <td>0.375950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.001203</td>\n",
              "      <td>0.367137</td>\n",
              "      <td>-0.084265</td>\n",
              "      <td>-0.100569</td>\n",
              "      <td>0.018451</td>\n",
              "      <td>0.046227</td>\n",
              "      <td>-0.101911</td>\n",
              "      <td>-0.038210</td>\n",
              "      <td>...</td>\n",
              "      <td>0.397177</td>\n",
              "      <td>0.392793</td>\n",
              "      <td>0.388256</td>\n",
              "      <td>0.383761</td>\n",
              "      <td>0.384351</td>\n",
              "      <td>0.383117</td>\n",
              "      <td>0.379185</td>\n",
              "      <td>0.365162</td>\n",
              "      <td>0.365579</td>\n",
              "      <td>0.375950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.233810</td>\n",
              "      <td>0.046065</td>\n",
              "      <td>0.024136</td>\n",
              "      <td>0.032700</td>\n",
              "      <td>-0.031101</td>\n",
              "      <td>-0.036372</td>\n",
              "      <td>-0.169688</td>\n",
              "      <td>-0.154002</td>\n",
              "      <td>...</td>\n",
              "      <td>0.060715</td>\n",
              "      <td>0.057743</td>\n",
              "      <td>0.055493</td>\n",
              "      <td>0.056890</td>\n",
              "      <td>0.052044</td>\n",
              "      <td>0.053244</td>\n",
              "      <td>0.052057</td>\n",
              "      <td>0.045743</td>\n",
              "      <td>0.046962</td>\n",
              "      <td>0.047065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-0.182565</td>\n",
              "      <td>0.057049</td>\n",
              "      <td>-0.031463</td>\n",
              "      <td>-0.025114</td>\n",
              "      <td>-0.050518</td>\n",
              "      <td>-0.035422</td>\n",
              "      <td>-0.067798</td>\n",
              "      <td>-0.052955</td>\n",
              "      <td>...</td>\n",
              "      <td>0.060715</td>\n",
              "      <td>0.057743</td>\n",
              "      <td>0.055493</td>\n",
              "      <td>0.056890</td>\n",
              "      <td>0.052044</td>\n",
              "      <td>0.053244</td>\n",
              "      <td>0.052057</td>\n",
              "      <td>0.045743</td>\n",
              "      <td>0.046962</td>\n",
              "      <td>0.047065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.107936</td>\n",
              "      <td>-0.094438</td>\n",
              "      <td>0.092679</td>\n",
              "      <td>0.038768</td>\n",
              "      <td>0.186656</td>\n",
              "      <td>0.125008</td>\n",
              "      <td>0.095410</td>\n",
              "      <td>0.078630</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.054256</td>\n",
              "      <td>-0.053808</td>\n",
              "      <td>-0.052869</td>\n",
              "      <td>-0.052718</td>\n",
              "      <td>-0.051934</td>\n",
              "      <td>-0.051097</td>\n",
              "      <td>-0.050394</td>\n",
              "      <td>-0.050345</td>\n",
              "      <td>-0.049870</td>\n",
              "      <td>-0.049726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>-0.083333</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.040649</td>\n",
              "      <td>-0.066683</td>\n",
              "      <td>-0.185786</td>\n",
              "      <td>-0.250955</td>\n",
              "      <td>-0.163660</td>\n",
              "      <td>-0.173238</td>\n",
              "      <td>-0.232896</td>\n",
              "      <td>-0.223542</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.054095</td>\n",
              "      <td>-0.053643</td>\n",
              "      <td>-0.052701</td>\n",
              "      <td>-0.052581</td>\n",
              "      <td>-0.051796</td>\n",
              "      <td>-0.050957</td>\n",
              "      <td>-0.050288</td>\n",
              "      <td>-0.050236</td>\n",
              "      <td>-0.049758</td>\n",
              "      <td>-0.049611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>-0.083333</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.153445</td>\n",
              "      <td>0.092191</td>\n",
              "      <td>-0.010435</td>\n",
              "      <td>-0.057762</td>\n",
              "      <td>-0.097339</td>\n",
              "      <td>-0.111005</td>\n",
              "      <td>-0.120050</td>\n",
              "      <td>0.000883</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.043740</td>\n",
              "      <td>-0.044039</td>\n",
              "      <td>-0.043146</td>\n",
              "      <td>-0.043641</td>\n",
              "      <td>-0.042803</td>\n",
              "      <td>-0.042638</td>\n",
              "      <td>-0.042785</td>\n",
              "      <td>-0.042676</td>\n",
              "      <td>-0.042227</td>\n",
              "      <td>-0.042307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>-0.083333</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>0.144594</td>\n",
              "      <td>0.231284</td>\n",
              "      <td>-0.043448</td>\n",
              "      <td>-0.041229</td>\n",
              "      <td>-0.173962</td>\n",
              "      <td>-0.202734</td>\n",
              "      <td>-0.153664</td>\n",
              "      <td>-0.000519</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.043740</td>\n",
              "      <td>-0.044039</td>\n",
              "      <td>-0.043146</td>\n",
              "      <td>-0.043641</td>\n",
              "      <td>-0.042803</td>\n",
              "      <td>-0.042638</td>\n",
              "      <td>-0.042785</td>\n",
              "      <td>-0.042676</td>\n",
              "      <td>-0.042227</td>\n",
              "      <td>-0.042307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>-0.083333</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-0.169496</td>\n",
              "      <td>-0.098815</td>\n",
              "      <td>-0.207792</td>\n",
              "      <td>-0.250433</td>\n",
              "      <td>-0.221289</td>\n",
              "      <td>-0.226000</td>\n",
              "      <td>0.073333</td>\n",
              "      <td>0.138157</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.053643</td>\n",
              "      <td>-0.053247</td>\n",
              "      <td>-0.052332</td>\n",
              "      <td>-0.052204</td>\n",
              "      <td>-0.051450</td>\n",
              "      <td>-0.050608</td>\n",
              "      <td>-0.049938</td>\n",
              "      <td>-0.049907</td>\n",
              "      <td>-0.049461</td>\n",
              "      <td>-0.049344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>-0.083333</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.159845</td>\n",
              "      <td>0.127796</td>\n",
              "      <td>0.027929</td>\n",
              "      <td>0.123740</td>\n",
              "      <td>-0.062721</td>\n",
              "      <td>-0.072166</td>\n",
              "      <td>0.041411</td>\n",
              "      <td>0.038973</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.053643</td>\n",
              "      <td>-0.053247</td>\n",
              "      <td>-0.052332</td>\n",
              "      <td>-0.052204</td>\n",
              "      <td>-0.051450</td>\n",
              "      <td>-0.050608</td>\n",
              "      <td>-0.049938</td>\n",
              "      <td>-0.049907</td>\n",
              "      <td>-0.049461</td>\n",
              "      <td>-0.049344</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>152 rows Ã— 700 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1236dc47-a8cb-4833-812e-ac84d84c0501')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1236dc47-a8cb-4833-812e-ac84d84c0501 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1236dc47-a8cb-4833-812e-ac84d84c0501');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "for col in features.columns:\n",
        "    if features[col].abs().max()==0:\n",
        "        continue\n",
        "    features[col] = (features[col] - features[col].mean())/features[col].abs().max()\n",
        "features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "bb3de32e",
      "metadata": {
        "id": "bb3de32e",
        "outputId": "1034eb4a-f027-49b8-a2aa-15c5c5261b95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 7)                 4907      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,965\n",
            "Trainable params: 4,965\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    \n",
        "    InputLayer(input_shape=(features.shape[1])),\n",
        "    \n",
        "    Dense(7, activation='sigmoid'),\n",
        "    \n",
        "    Dense(5, activation='sigmoid'),\n",
        "    \n",
        "    Dense(3, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='Adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy']\n",
        "             )\n",
        "model.summary()\n",
        "model.save_weights('model_weights/initial_weights_colonoscopy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "406c8d25",
      "metadata": {
        "id": "406c8d25",
        "outputId": "7be88874-578e-4554-a5fa-1acde877ca4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0911 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0851 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1568 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2771 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1658 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4631 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2059 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1440 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1091 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0543 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4023 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0695 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0778 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0694 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0675 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0572 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1468 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0551 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0526 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0667 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2780 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6688 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0629 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0687 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0711 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1259 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0760 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0854 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0693 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1815 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0604 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0598 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.3005 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1589 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0584 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0538 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0685 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1899 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0557 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0557 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2537 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0803 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0617 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0988 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0590 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0534 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1071 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0732 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0674 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0552 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0750 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0570 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6467 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1736 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2647 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1186 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0547 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0616 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1596 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0586 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0554 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0606 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1950 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1001 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0657 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3600 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0781 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0840 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3365 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0626 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0560 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6929 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4754 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1461 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.4354 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0778 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0629 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0762 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0592 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6792 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0431 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1121 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0416 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0441 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0546 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0583 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0829 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2057 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1484 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0547 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.4306 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6158 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1125 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2185 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.1216 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0822 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0431 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0486 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0416 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0421 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0414 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0574 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0535 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0421 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0418 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0424 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0416 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0436 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1756 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0430 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0432 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0506 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0480 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1810 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0417 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0684 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5235 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0499 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0485 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0535 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0585 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0556 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.9933 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2731 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6935 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3306 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4957 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.9511 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3565 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.5070 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.3370 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2709 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.6176 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.8058 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.9363 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3027 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4412 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3621 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2779 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2803 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5222 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5654 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.9032 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4053 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.1095 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5297 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3953 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2875 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.5292 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3206 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5517 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7307 - accuracy: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "acc = 0\n",
        "j = 0\n",
        "for train_index, test_index in LeaveOneOut().split(features):\n",
        "    x_train, x_test = features.iloc[train_index,:], features.iloc[test_index,:]\n",
        "    y_train, y_test = classes.iloc[train_index,:], classes.iloc[test_index,:]\n",
        "    model.load_weights('model_weights/initial_weights_colonoscopy')\n",
        "    with io.capture_output() as captured:\n",
        "        model.fit(x_train, y_train, epochs=500)\n",
        "    acc += model.evaluate(x_test, y_test)[1]\n",
        "    j+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "fe3a4412",
      "metadata": {
        "id": "fe3a4412",
        "outputId": "b44ef05d-9ea5-4320-b50b-21fd9d5bcd18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.8421052631578947\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy: ', acc/j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "4978bff8",
      "metadata": {
        "id": "4978bff8",
        "outputId": "c6f66ebb-71dc-4423-c4ba-25174f0935e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1121 - accuracy: 0.9934\n",
            "Epoch 2/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1114 - accuracy: 0.9934\n",
            "Epoch 3/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1105 - accuracy: 0.9934\n",
            "Epoch 4/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1097 - accuracy: 0.9934\n",
            "Epoch 5/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1090 - accuracy: 0.9934\n",
            "Epoch 6/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1082 - accuracy: 0.9934\n",
            "Epoch 7/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1075 - accuracy: 0.9934\n",
            "Epoch 8/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1067 - accuracy: 0.9934\n",
            "Epoch 9/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1061 - accuracy: 0.9934\n",
            "Epoch 10/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1054 - accuracy: 0.9934\n",
            "Epoch 11/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1047 - accuracy: 0.9934\n",
            "Epoch 12/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1040 - accuracy: 0.9934\n",
            "Epoch 13/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1033 - accuracy: 0.9934\n",
            "Epoch 14/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1026 - accuracy: 0.9934\n",
            "Epoch 15/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1020 - accuracy: 0.9934\n",
            "Epoch 16/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1013 - accuracy: 0.9934\n",
            "Epoch 17/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1006 - accuracy: 0.9934\n",
            "Epoch 18/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1001 - accuracy: 0.9934\n",
            "Epoch 19/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0994 - accuracy: 1.0000\n",
            "Epoch 20/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0988 - accuracy: 1.0000\n",
            "Epoch 21/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0982 - accuracy: 1.0000\n",
            "Epoch 22/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0976 - accuracy: 1.0000\n",
            "Epoch 23/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0970 - accuracy: 1.0000\n",
            "Epoch 24/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0964 - accuracy: 1.0000\n",
            "Epoch 25/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0958 - accuracy: 1.0000\n",
            "Epoch 26/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0952 - accuracy: 1.0000\n",
            "Epoch 27/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0946 - accuracy: 1.0000\n",
            "Epoch 28/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0940 - accuracy: 1.0000\n",
            "Epoch 29/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0935 - accuracy: 1.0000\n",
            "Epoch 30/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0929 - accuracy: 1.0000\n",
            "Epoch 31/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0924 - accuracy: 1.0000\n",
            "Epoch 32/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0918 - accuracy: 1.0000\n",
            "Epoch 33/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0913 - accuracy: 1.0000\n",
            "Epoch 34/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0907 - accuracy: 1.0000\n",
            "Epoch 35/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0902 - accuracy: 1.0000\n",
            "Epoch 36/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0897 - accuracy: 1.0000\n",
            "Epoch 37/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0891 - accuracy: 1.0000\n",
            "Epoch 38/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0886 - accuracy: 1.0000\n",
            "Epoch 39/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0881 - accuracy: 1.0000\n",
            "Epoch 40/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0876 - accuracy: 1.0000\n",
            "Epoch 41/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0871 - accuracy: 1.0000\n",
            "Epoch 42/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0866 - accuracy: 1.0000\n",
            "Epoch 43/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0860 - accuracy: 1.0000\n",
            "Epoch 44/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0856 - accuracy: 1.0000\n",
            "Epoch 45/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0851 - accuracy: 1.0000\n",
            "Epoch 46/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0846 - accuracy: 1.0000\n",
            "Epoch 47/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0841 - accuracy: 1.0000\n",
            "Epoch 48/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0837 - accuracy: 1.0000\n",
            "Epoch 49/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0832 - accuracy: 1.0000\n",
            "Epoch 50/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0827 - accuracy: 1.0000\n",
            "Epoch 51/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0822 - accuracy: 1.0000\n",
            "Epoch 52/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 1.0000\n",
            "Epoch 53/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 1.0000\n",
            "Epoch 54/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0808 - accuracy: 1.0000\n",
            "Epoch 55/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0804 - accuracy: 1.0000\n",
            "Epoch 56/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0800 - accuracy: 1.0000\n",
            "Epoch 57/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0795 - accuracy: 1.0000\n",
            "Epoch 58/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0791 - accuracy: 1.0000\n",
            "Epoch 59/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0787 - accuracy: 1.0000\n",
            "Epoch 60/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0782 - accuracy: 1.0000\n",
            "Epoch 61/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0778 - accuracy: 1.0000\n",
            "Epoch 62/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0774 - accuracy: 1.0000\n",
            "Epoch 63/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0769 - accuracy: 1.0000\n",
            "Epoch 64/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0765 - accuracy: 1.0000\n",
            "Epoch 65/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0761 - accuracy: 1.0000\n",
            "Epoch 66/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0757 - accuracy: 1.0000\n",
            "Epoch 67/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0753 - accuracy: 1.0000\n",
            "Epoch 68/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0749 - accuracy: 1.0000\n",
            "Epoch 69/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0745 - accuracy: 1.0000\n",
            "Epoch 70/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0741 - accuracy: 1.0000\n",
            "Epoch 71/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0737 - accuracy: 1.0000\n",
            "Epoch 72/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0733 - accuracy: 1.0000\n",
            "Epoch 73/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0729 - accuracy: 1.0000\n",
            "Epoch 74/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0726 - accuracy: 1.0000\n",
            "Epoch 75/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 1.0000\n",
            "Epoch 76/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0718 - accuracy: 1.0000\n",
            "Epoch 77/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 1.0000\n",
            "Epoch 78/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 1.0000\n",
            "Epoch 79/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 1.0000\n",
            "Epoch 80/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 1.0000\n",
            "Epoch 81/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 1.0000\n",
            "Epoch 82/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 1.0000\n",
            "Epoch 83/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0692 - accuracy: 1.0000\n",
            "Epoch 84/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 1.0000\n",
            "Epoch 85/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 1.0000\n",
            "Epoch 86/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 1.0000\n",
            "Epoch 87/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 1.0000\n",
            "Epoch 88/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 1.0000\n",
            "Epoch 89/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 1.0000\n",
            "Epoch 90/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 1.0000\n",
            "Epoch 91/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 1.0000\n",
            "Epoch 92/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 1.0000\n",
            "Epoch 93/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 1.0000\n",
            "Epoch 94/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 1.0000\n",
            "Epoch 95/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 1.0000\n",
            "Epoch 96/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 1.0000\n",
            "Epoch 97/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 1.0000\n",
            "Epoch 98/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 1.0000\n",
            "Epoch 99/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 1.0000\n",
            "Epoch 100/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 1.0000\n",
            "Epoch 101/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 1.0000\n",
            "Epoch 102/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 1.0000\n",
            "Epoch 103/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 1.0000\n",
            "Epoch 104/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 1.0000\n",
            "Epoch 105/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 1.0000\n",
            "Epoch 106/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 1.0000\n",
            "Epoch 107/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 1.0000\n",
            "Epoch 108/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 1.0000\n",
            "Epoch 109/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 1.0000\n",
            "Epoch 110/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0606 - accuracy: 1.0000\n",
            "Epoch 111/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 1.0000\n",
            "Epoch 112/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 1.0000\n",
            "Epoch 113/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 1.0000\n",
            "Epoch 114/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 1.0000\n",
            "Epoch 115/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 1.0000\n",
            "Epoch 116/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 1.0000\n",
            "Epoch 117/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 1.0000\n",
            "Epoch 118/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 1.0000\n",
            "Epoch 119/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 1.0000\n",
            "Epoch 120/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 1.0000\n",
            "Epoch 121/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 1.0000\n",
            "Epoch 122/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 1.0000\n",
            "Epoch 123/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 1.0000\n",
            "Epoch 124/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 1.0000\n",
            "Epoch 125/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 1.0000\n",
            "Epoch 126/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 1.0000\n",
            "Epoch 127/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 1.0000\n",
            "Epoch 128/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0558 - accuracy: 1.0000\n",
            "Epoch 129/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 1.0000\n",
            "Epoch 130/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 1.0000\n",
            "Epoch 131/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 1.0000\n",
            "Epoch 132/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 1.0000\n",
            "Epoch 133/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 1.0000\n",
            "Epoch 134/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 1.0000\n",
            "Epoch 135/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 1.0000\n",
            "Epoch 136/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 1.0000\n",
            "Epoch 137/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0536 - accuracy: 1.0000\n",
            "Epoch 138/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0533 - accuracy: 1.0000\n",
            "Epoch 139/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 1.0000\n",
            "Epoch 140/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 1.0000\n",
            "Epoch 141/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 1.0000\n",
            "Epoch 142/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 1.0000\n",
            "Epoch 143/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 1.0000\n",
            "Epoch 144/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 1.0000\n",
            "Epoch 145/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 1.0000\n",
            "Epoch 146/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0515 - accuracy: 1.0000\n",
            "Epoch 147/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0513 - accuracy: 1.0000\n",
            "Epoch 148/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 1.0000\n",
            "Epoch 149/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 1.0000\n",
            "Epoch 150/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 1.0000\n",
            "Epoch 151/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0504 - accuracy: 1.0000\n",
            "Epoch 152/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 1.0000\n",
            "Epoch 153/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 1.0000\n",
            "Epoch 154/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 1.0000\n",
            "Epoch 155/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 1.0000\n",
            "Epoch 156/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 1.0000\n",
            "Epoch 157/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0491 - accuracy: 1.0000\n",
            "Epoch 158/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 1.0000\n",
            "Epoch 159/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 1.0000\n",
            "Epoch 160/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 1.0000\n",
            "Epoch 161/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 1.0000\n",
            "Epoch 162/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 1.0000\n",
            "Epoch 163/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 1.0000\n",
            "Epoch 164/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0477 - accuracy: 1.0000\n",
            "Epoch 165/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 1.0000\n",
            "Epoch 166/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 1.0000\n",
            "Epoch 167/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 1.0000\n",
            "Epoch 168/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 1.0000\n",
            "Epoch 169/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 1.0000\n",
            "Epoch 170/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 1.0000\n",
            "Epoch 171/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 1.0000\n",
            "Epoch 172/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0461 - accuracy: 1.0000\n",
            "Epoch 173/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0459 - accuracy: 1.0000\n",
            "Epoch 174/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 1.0000\n",
            "Epoch 175/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 1.0000\n",
            "Epoch 176/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 1.0000\n",
            "Epoch 177/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0452 - accuracy: 1.0000\n",
            "Epoch 178/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0450 - accuracy: 1.0000\n",
            "Epoch 179/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0448 - accuracy: 1.0000\n",
            "Epoch 180/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0446 - accuracy: 1.0000\n",
            "Epoch 181/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 1.0000\n",
            "Epoch 182/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 1.0000\n",
            "Epoch 183/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 1.0000\n",
            "Epoch 184/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 1.0000\n",
            "Epoch 185/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 1.0000\n",
            "Epoch 186/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 1.0000\n",
            "Epoch 187/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0434 - accuracy: 1.0000\n",
            "Epoch 188/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 1.0000\n",
            "Epoch 189/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0431 - accuracy: 1.0000\n",
            "Epoch 190/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 1.0000\n",
            "Epoch 191/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 1.0000\n",
            "Epoch 192/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0425 - accuracy: 1.0000\n",
            "Epoch 193/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0424 - accuracy: 1.0000\n",
            "Epoch 194/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0422 - accuracy: 1.0000\n",
            "Epoch 195/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 1.0000\n",
            "Epoch 196/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0419 - accuracy: 1.0000\n",
            "Epoch 197/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0417 - accuracy: 1.0000\n",
            "Epoch 198/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 1.0000\n",
            "Epoch 199/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 1.0000\n",
            "Epoch 200/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 1.0000\n",
            "Epoch 201/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0411 - accuracy: 1.0000\n",
            "Epoch 202/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 1.0000\n",
            "Epoch 203/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0407 - accuracy: 1.0000\n",
            "Epoch 204/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0406 - accuracy: 1.0000\n",
            "Epoch 205/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 1.0000\n",
            "Epoch 206/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 1.0000\n",
            "Epoch 207/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 1.0000\n",
            "Epoch 208/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 1.0000\n",
            "Epoch 209/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 1.0000\n",
            "Epoch 210/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0396 - accuracy: 1.0000\n",
            "Epoch 211/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 1.0000\n",
            "Epoch 212/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 1.0000\n",
            "Epoch 213/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0392 - accuracy: 1.0000\n",
            "Epoch 214/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 1.0000\n",
            "Epoch 215/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 1.0000\n",
            "Epoch 216/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 1.0000\n",
            "Epoch 217/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 1.0000\n",
            "Epoch 218/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0385 - accuracy: 1.0000\n",
            "Epoch 219/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 1.0000\n",
            "Epoch 220/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0382 - accuracy: 1.0000\n",
            "Epoch 221/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0380 - accuracy: 1.0000\n",
            "Epoch 222/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 1.0000\n",
            "Epoch 223/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 1.0000\n",
            "Epoch 224/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 1.0000\n",
            "Epoch 225/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0375 - accuracy: 1.0000\n",
            "Epoch 226/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0373 - accuracy: 1.0000\n",
            "Epoch 227/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 1.0000\n",
            "Epoch 228/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0370 - accuracy: 1.0000\n",
            "Epoch 229/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0369 - accuracy: 1.0000\n",
            "Epoch 230/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 1.0000\n",
            "Epoch 231/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0366 - accuracy: 1.0000\n",
            "Epoch 232/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 1.0000\n",
            "Epoch 233/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - accuracy: 1.0000\n",
            "Epoch 234/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 1.0000\n",
            "Epoch 235/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0361 - accuracy: 1.0000\n",
            "Epoch 236/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0359 - accuracy: 1.0000\n",
            "Epoch 237/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0358 - accuracy: 1.0000\n",
            "Epoch 238/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0357 - accuracy: 1.0000\n",
            "Epoch 239/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0356 - accuracy: 1.0000\n",
            "Epoch 240/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 1.0000\n",
            "Epoch 241/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 1.0000\n",
            "Epoch 242/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - accuracy: 1.0000\n",
            "Epoch 243/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 1.0000\n",
            "Epoch 244/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0349 - accuracy: 1.0000\n",
            "Epoch 245/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0348 - accuracy: 1.0000\n",
            "Epoch 246/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 1.0000\n",
            "Epoch 247/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 1.0000\n",
            "Epoch 248/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 1.0000\n",
            "Epoch 249/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 1.0000\n",
            "Epoch 250/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - accuracy: 1.0000\n",
            "Epoch 251/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0340 - accuracy: 1.0000\n",
            "Epoch 252/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 1.0000\n",
            "Epoch 253/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0338 - accuracy: 1.0000\n",
            "Epoch 254/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0337 - accuracy: 1.0000\n",
            "Epoch 255/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0335 - accuracy: 1.0000\n",
            "Epoch 256/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - accuracy: 1.0000\n",
            "Epoch 257/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0333 - accuracy: 1.0000\n",
            "Epoch 258/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 1.0000\n",
            "Epoch 259/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0331 - accuracy: 1.0000\n",
            "Epoch 260/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0329 - accuracy: 1.0000\n",
            "Epoch 261/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0328 - accuracy: 1.0000\n",
            "Epoch 262/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0327 - accuracy: 1.0000\n",
            "Epoch 263/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0326 - accuracy: 1.0000\n",
            "Epoch 264/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 1.0000\n",
            "Epoch 265/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0324 - accuracy: 1.0000\n",
            "Epoch 266/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0322 - accuracy: 1.0000\n",
            "Epoch 267/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0321 - accuracy: 1.0000\n",
            "Epoch 268/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0320 - accuracy: 1.0000\n",
            "Epoch 269/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0319 - accuracy: 1.0000\n",
            "Epoch 270/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0318 - accuracy: 1.0000\n",
            "Epoch 271/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0317 - accuracy: 1.0000\n",
            "Epoch 272/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0316 - accuracy: 1.0000\n",
            "Epoch 273/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0315 - accuracy: 1.0000\n",
            "Epoch 274/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 1.0000\n",
            "Epoch 275/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0313 - accuracy: 1.0000\n",
            "Epoch 276/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0311 - accuracy: 1.0000\n",
            "Epoch 277/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0310 - accuracy: 1.0000\n",
            "Epoch 278/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0309 - accuracy: 1.0000\n",
            "Epoch 279/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0308 - accuracy: 1.0000\n",
            "Epoch 280/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0307 - accuracy: 1.0000\n",
            "Epoch 281/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0306 - accuracy: 1.0000\n",
            "Epoch 282/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0305 - accuracy: 1.0000\n",
            "Epoch 283/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0304 - accuracy: 1.0000\n",
            "Epoch 284/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0303 - accuracy: 1.0000\n",
            "Epoch 285/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0302 - accuracy: 1.0000\n",
            "Epoch 286/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0301 - accuracy: 1.0000\n",
            "Epoch 287/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0300 - accuracy: 1.0000\n",
            "Epoch 288/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0299 - accuracy: 1.0000\n",
            "Epoch 289/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 1.0000\n",
            "Epoch 290/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 1.0000\n",
            "Epoch 291/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0296 - accuracy: 1.0000\n",
            "Epoch 292/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0295 - accuracy: 1.0000\n",
            "Epoch 293/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0294 - accuracy: 1.0000\n",
            "Epoch 294/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0293 - accuracy: 1.0000\n",
            "Epoch 295/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0292 - accuracy: 1.0000\n",
            "Epoch 296/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0291 - accuracy: 1.0000\n",
            "Epoch 297/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0290 - accuracy: 1.0000\n",
            "Epoch 298/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 1.0000\n",
            "Epoch 299/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0288 - accuracy: 1.0000\n",
            "Epoch 300/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - accuracy: 1.0000\n",
            "Epoch 301/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0286 - accuracy: 1.0000\n",
            "Epoch 302/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - accuracy: 1.0000\n",
            "Epoch 303/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0284 - accuracy: 1.0000\n",
            "Epoch 304/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0283 - accuracy: 1.0000\n",
            "Epoch 305/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0282 - accuracy: 1.0000\n",
            "Epoch 306/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0281 - accuracy: 1.0000\n",
            "Epoch 307/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0280 - accuracy: 1.0000\n",
            "Epoch 308/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0279 - accuracy: 1.0000\n",
            "Epoch 309/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 1.0000\n",
            "Epoch 310/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0277 - accuracy: 1.0000\n",
            "Epoch 311/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0276 - accuracy: 1.0000\n",
            "Epoch 312/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0276 - accuracy: 1.0000\n",
            "Epoch 313/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0275 - accuracy: 1.0000\n",
            "Epoch 314/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0274 - accuracy: 1.0000\n",
            "Epoch 315/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 1.0000\n",
            "Epoch 316/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0272 - accuracy: 1.0000\n",
            "Epoch 317/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0271 - accuracy: 1.0000\n",
            "Epoch 318/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0270 - accuracy: 1.0000\n",
            "Epoch 319/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0269 - accuracy: 1.0000\n",
            "Epoch 320/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0268 - accuracy: 1.0000\n",
            "Epoch 321/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0267 - accuracy: 1.0000\n",
            "Epoch 322/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0267 - accuracy: 1.0000\n",
            "Epoch 323/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0266 - accuracy: 1.0000\n",
            "Epoch 324/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0265 - accuracy: 1.0000\n",
            "Epoch 325/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0264 - accuracy: 1.0000\n",
            "Epoch 326/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - accuracy: 1.0000\n",
            "Epoch 327/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0262 - accuracy: 1.0000\n",
            "Epoch 328/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0261 - accuracy: 1.0000\n",
            "Epoch 329/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0261 - accuracy: 1.0000\n",
            "Epoch 330/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0260 - accuracy: 1.0000\n",
            "Epoch 331/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0259 - accuracy: 1.0000\n",
            "Epoch 332/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0258 - accuracy: 1.0000\n",
            "Epoch 333/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0257 - accuracy: 1.0000\n",
            "Epoch 334/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 1.0000\n",
            "Epoch 335/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 1.0000\n",
            "Epoch 336/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 1.0000\n",
            "Epoch 337/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0254 - accuracy: 1.0000\n",
            "Epoch 338/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0253 - accuracy: 1.0000\n",
            "Epoch 339/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 1.0000\n",
            "Epoch 340/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0251 - accuracy: 1.0000\n",
            "Epoch 341/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0251 - accuracy: 1.0000\n",
            "Epoch 342/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 1.0000\n",
            "Epoch 343/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 1.0000\n",
            "Epoch 344/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0248 - accuracy: 1.0000\n",
            "Epoch 345/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0247 - accuracy: 1.0000\n",
            "Epoch 346/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0247 - accuracy: 1.0000\n",
            "Epoch 347/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0246 - accuracy: 1.0000\n",
            "Epoch 348/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0245 - accuracy: 1.0000\n",
            "Epoch 349/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0244 - accuracy: 1.0000\n",
            "Epoch 350/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 1.0000\n",
            "Epoch 351/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 1.0000\n",
            "Epoch 352/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0242 - accuracy: 1.0000\n",
            "Epoch 353/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 1.0000\n",
            "Epoch 354/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0240 - accuracy: 1.0000\n",
            "Epoch 355/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0240 - accuracy: 1.0000\n",
            "Epoch 356/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0239 - accuracy: 1.0000\n",
            "Epoch 357/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0238 - accuracy: 1.0000\n",
            "Epoch 358/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0237 - accuracy: 1.0000\n",
            "Epoch 359/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0237 - accuracy: 1.0000\n",
            "Epoch 360/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 1.0000\n",
            "Epoch 361/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0235 - accuracy: 1.0000\n",
            "Epoch 362/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0234 - accuracy: 1.0000\n",
            "Epoch 363/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0234 - accuracy: 1.0000\n",
            "Epoch 364/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 1.0000\n",
            "Epoch 365/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - accuracy: 1.0000\n",
            "Epoch 366/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 1.0000\n",
            "Epoch 367/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 1.0000\n",
            "Epoch 368/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 1.0000\n",
            "Epoch 369/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0229 - accuracy: 1.0000\n",
            "Epoch 370/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0229 - accuracy: 1.0000\n",
            "Epoch 371/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0228 - accuracy: 1.0000\n",
            "Epoch 372/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0227 - accuracy: 1.0000\n",
            "Epoch 373/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0226 - accuracy: 1.0000\n",
            "Epoch 374/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0226 - accuracy: 1.0000\n",
            "Epoch 375/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0225 - accuracy: 1.0000\n",
            "Epoch 376/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 1.0000\n",
            "Epoch 377/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 1.0000\n",
            "Epoch 378/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 1.0000\n",
            "Epoch 379/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 1.0000\n",
            "Epoch 380/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 1.0000\n",
            "Epoch 381/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 1.0000\n",
            "Epoch 382/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 1.0000\n",
            "Epoch 383/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 1.0000\n",
            "Epoch 384/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0219 - accuracy: 1.0000\n",
            "Epoch 385/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 1.0000\n",
            "Epoch 386/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 1.0000\n",
            "Epoch 387/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 1.0000\n",
            "Epoch 388/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 1.0000\n",
            "Epoch 389/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 1.0000\n",
            "Epoch 390/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 1.0000\n",
            "Epoch 391/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 1.0000\n",
            "Epoch 392/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 1.0000\n",
            "Epoch 393/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 1.0000\n",
            "Epoch 394/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 1.0000\n",
            "Epoch 395/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 1.0000\n",
            "Epoch 396/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 1.0000\n",
            "Epoch 397/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 1.0000\n",
            "Epoch 398/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 1.0000\n",
            "Epoch 399/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 1.0000\n",
            "Epoch 400/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 1.0000\n",
            "Epoch 401/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 1.0000\n",
            "Epoch 402/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 1.0000\n",
            "Epoch 403/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 1.0000\n",
            "Epoch 404/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0206 - accuracy: 1.0000\n",
            "Epoch 405/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0205 - accuracy: 1.0000\n",
            "Epoch 406/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 1.0000\n",
            "Epoch 407/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 1.0000\n",
            "Epoch 408/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 1.0000\n",
            "Epoch 409/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 1.0000\n",
            "Epoch 410/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 1.0000\n",
            "Epoch 411/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 1.0000\n",
            "Epoch 412/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 1.0000\n",
            "Epoch 413/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0200 - accuracy: 1.0000\n",
            "Epoch 414/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 1.0000\n",
            "Epoch 415/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 1.0000\n",
            "Epoch 416/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 1.0000\n",
            "Epoch 417/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 1.0000\n",
            "Epoch 418/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0197 - accuracy: 1.0000\n",
            "Epoch 419/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0197 - accuracy: 1.0000\n",
            "Epoch 420/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 1.0000\n",
            "Epoch 421/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 1.0000\n",
            "Epoch 422/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 1.0000\n",
            "Epoch 423/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 1.0000\n",
            "Epoch 424/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 1.0000\n",
            "Epoch 425/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0193 - accuracy: 1.0000\n",
            "Epoch 426/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 1.0000\n",
            "Epoch 427/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - accuracy: 1.0000\n",
            "Epoch 428/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0192 - accuracy: 1.0000\n",
            "Epoch 429/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 1.0000\n",
            "Epoch 430/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 1.0000\n",
            "Epoch 431/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 1.0000\n",
            "Epoch 432/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 1.0000\n",
            "Epoch 433/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 1.0000\n",
            "Epoch 434/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 1.0000\n",
            "Epoch 435/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 1.0000\n",
            "Epoch 436/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0187 - accuracy: 1.0000\n",
            "Epoch 437/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0187 - accuracy: 1.0000\n",
            "Epoch 438/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 1.0000\n",
            "Epoch 439/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 1.0000\n",
            "Epoch 440/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 1.0000\n",
            "Epoch 441/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 1.0000\n",
            "Epoch 442/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 1.0000\n",
            "Epoch 443/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 1.0000\n",
            "Epoch 444/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 1.0000\n",
            "Epoch 445/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 1.0000\n",
            "Epoch 446/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 1.0000\n",
            "Epoch 447/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 1.0000\n",
            "Epoch 448/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 1.0000\n",
            "Epoch 449/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 1.0000\n",
            "Epoch 450/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 1.0000\n",
            "Epoch 451/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 1.0000\n",
            "Epoch 452/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 1.0000\n",
            "Epoch 453/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 1.0000\n",
            "Epoch 454/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 1.0000\n",
            "Epoch 455/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 1.0000\n",
            "Epoch 456/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 1.0000\n",
            "Epoch 457/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 1.0000\n",
            "Epoch 458/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 1.0000\n",
            "Epoch 459/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0175 - accuracy: 1.0000\n",
            "Epoch 460/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 1.0000\n",
            "Epoch 461/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 1.0000\n",
            "Epoch 462/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0173 - accuracy: 1.0000\n",
            "Epoch 463/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0173 - accuracy: 1.0000\n",
            "Epoch 464/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 1.0000\n",
            "Epoch 465/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0172 - accuracy: 1.0000\n",
            "Epoch 466/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 1.0000\n",
            "Epoch 467/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 1.0000\n",
            "Epoch 468/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 1.0000\n",
            "Epoch 469/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 1.0000\n",
            "Epoch 470/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 1.0000\n",
            "Epoch 471/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 1.0000\n",
            "Epoch 472/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 1.0000\n",
            "Epoch 473/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 1.0000\n",
            "Epoch 474/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 1.0000\n",
            "Epoch 475/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 1.0000\n",
            "Epoch 476/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 1.0000\n",
            "Epoch 477/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 1.0000\n",
            "Epoch 478/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 1.0000\n",
            "Epoch 479/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 1.0000\n",
            "Epoch 480/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 1.0000\n",
            "Epoch 481/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 1.0000\n",
            "Epoch 482/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 1.0000\n",
            "Epoch 483/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 1.0000\n",
            "Epoch 484/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 1.0000\n",
            "Epoch 485/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 1.0000\n",
            "Epoch 486/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 1.0000\n",
            "Epoch 487/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 1.0000\n",
            "Epoch 488/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 1.0000\n",
            "Epoch 489/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 1.0000\n",
            "Epoch 490/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 1.0000\n",
            "Epoch 491/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 1.0000\n",
            "Epoch 492/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 1.0000\n",
            "Epoch 493/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 1.0000\n",
            "Epoch 494/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 1.0000\n",
            "Epoch 495/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 1.0000\n",
            "Epoch 496/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 1.0000\n",
            "Epoch 497/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 1.0000\n",
            "Epoch 498/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 1.0000\n",
            "Epoch 499/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 1.0000\n",
            "Epoch 500/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fea80991750>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "model.fit(features, classes, epochs=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "46c38512",
      "metadata": {
        "id": "46c38512",
        "outputId": "84d0c201-6816-4c52-8119-96d1b11471a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 700/700 [06:34<00:00,  1.78it/s]\n"
          ]
        }
      ],
      "source": [
        "grad_sum = 0\n",
        "for col_name in tqdm(features.columns):\n",
        "    pointFrame = features.loc[:, features.columns != col_name]\n",
        "    for i in features[col_name]:\n",
        "        pointFrame[col_name] = i*np.ones(len(features.index))\n",
        "        points = tf.Variable(pointFrame, dtype='float')\n",
        "        with tf.GradientTape() as tape:\n",
        "            pred = model(points, training=False)\n",
        "        grads = tape.gradient(pred, points)\n",
        "        grad_sum += np.abs(grads.numpy())\n",
        "saliency_order = np.argsort(-np.sum(np.abs(grad_sum), 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "5082fe64",
      "metadata": {
        "id": "5082fe64",
        "outputId": "b7dad1d9-2a0b-41e9-ffdd-b314c77f0539",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The features arranged in order of saliency are: \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         547       464       455       146       545       549  \\\n",
              "0    0.250000  0.019453  0.156682 -0.008144  0.014037  0.020956  0.013944   \n",
              "1    0.250000  0.019453 -0.071990 -0.008144  0.009191  0.020956  0.013944   \n",
              "2    0.250000  0.012418 -0.131291  0.229704  0.008758  0.007180  0.016346   \n",
              "3    0.250000  0.012418 -0.140440 -0.008144  0.066090  0.007180  0.016346   \n",
              "4    0.250000  0.018683 -0.029781 -0.008144 -0.104275  0.012956  0.017094   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "147 -0.083333  0.006751  0.063551 -0.008144 -0.029268  0.018410 -0.003144   \n",
              "148 -0.083333  0.009858 -0.040653 -0.008144 -0.007182  0.009247  0.007949   \n",
              "149 -0.083333  0.009858 -0.026035 -0.008144  0.030283  0.009247  0.007949   \n",
              "150 -0.083333 -0.044736 -0.140440 -0.008144 -0.007820 -0.043478 -0.039516   \n",
              "151 -0.083333 -0.044736 -0.136928 -0.008144 -0.029013 -0.043478 -0.039516   \n",
              "\n",
              "          546       571       521  ...  208  172  452  176  244  454  321  \\\n",
              "0    0.017661 -0.000891  0.019545  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "1    0.017661 -0.000891  0.019545  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2   -0.007271  0.008760  0.000482  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "3   -0.007271  0.008760  0.000482  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "4    0.021297  0.011717 -0.004381  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "..        ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "147  0.006035 -0.016223  0.089982  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "148  0.009186  0.012807  0.019351  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "149  0.009186  0.012807  0.019351  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "150 -0.050214  0.009538  0.004470  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "151 -0.050214  0.009538  0.004470  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "\n",
              "     220  390  409  \n",
              "0    0.0  0.0  0.0  \n",
              "1    0.0  0.0  0.0  \n",
              "2    0.0  0.0  0.0  \n",
              "3    0.0  0.0  0.0  \n",
              "4    0.0  0.0  0.0  \n",
              "..   ...  ...  ...  \n",
              "147  0.0  0.0  0.0  \n",
              "148  0.0  0.0  0.0  \n",
              "149  0.0  0.0  0.0  \n",
              "150  0.0  0.0  0.0  \n",
              "151  0.0  0.0  0.0  \n",
              "\n",
              "[152 rows x 700 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2086c03f-3395-427a-9f71-72646cbaf648\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>547</th>\n",
              "      <th>464</th>\n",
              "      <th>455</th>\n",
              "      <th>146</th>\n",
              "      <th>545</th>\n",
              "      <th>549</th>\n",
              "      <th>546</th>\n",
              "      <th>571</th>\n",
              "      <th>521</th>\n",
              "      <th>...</th>\n",
              "      <th>208</th>\n",
              "      <th>172</th>\n",
              "      <th>452</th>\n",
              "      <th>176</th>\n",
              "      <th>244</th>\n",
              "      <th>454</th>\n",
              "      <th>321</th>\n",
              "      <th>220</th>\n",
              "      <th>390</th>\n",
              "      <th>409</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.019453</td>\n",
              "      <td>0.156682</td>\n",
              "      <td>-0.008144</td>\n",
              "      <td>0.014037</td>\n",
              "      <td>0.020956</td>\n",
              "      <td>0.013944</td>\n",
              "      <td>0.017661</td>\n",
              "      <td>-0.000891</td>\n",
              "      <td>0.019545</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.019453</td>\n",
              "      <td>-0.071990</td>\n",
              "      <td>-0.008144</td>\n",
              "      <td>0.009191</td>\n",
              "      <td>0.020956</td>\n",
              "      <td>0.013944</td>\n",
              "      <td>0.017661</td>\n",
              "      <td>-0.000891</td>\n",
              "      <td>0.019545</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.012418</td>\n",
              "      <td>-0.131291</td>\n",
              "      <td>0.229704</td>\n",
              "      <td>0.008758</td>\n",
              "      <td>0.007180</td>\n",
              "      <td>0.016346</td>\n",
              "      <td>-0.007271</td>\n",
              "      <td>0.008760</td>\n",
              "      <td>0.000482</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.012418</td>\n",
              "      <td>-0.140440</td>\n",
              "      <td>-0.008144</td>\n",
              "      <td>0.066090</td>\n",
              "      <td>0.007180</td>\n",
              "      <td>0.016346</td>\n",
              "      <td>-0.007271</td>\n",
              "      <td>0.008760</td>\n",
              "      <td>0.000482</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.018683</td>\n",
              "      <td>-0.029781</td>\n",
              "      <td>-0.008144</td>\n",
              "      <td>-0.104275</td>\n",
              "      <td>0.012956</td>\n",
              "      <td>0.017094</td>\n",
              "      <td>0.021297</td>\n",
              "      <td>0.011717</td>\n",
              "      <td>-0.004381</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>-0.083333</td>\n",
              "      <td>0.006751</td>\n",
              "      <td>0.063551</td>\n",
              "      <td>-0.008144</td>\n",
              "      <td>-0.029268</td>\n",
              "      <td>0.018410</td>\n",
              "      <td>-0.003144</td>\n",
              "      <td>0.006035</td>\n",
              "      <td>-0.016223</td>\n",
              "      <td>0.089982</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>-0.083333</td>\n",
              "      <td>0.009858</td>\n",
              "      <td>-0.040653</td>\n",
              "      <td>-0.008144</td>\n",
              "      <td>-0.007182</td>\n",
              "      <td>0.009247</td>\n",
              "      <td>0.007949</td>\n",
              "      <td>0.009186</td>\n",
              "      <td>0.012807</td>\n",
              "      <td>0.019351</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>-0.083333</td>\n",
              "      <td>0.009858</td>\n",
              "      <td>-0.026035</td>\n",
              "      <td>-0.008144</td>\n",
              "      <td>0.030283</td>\n",
              "      <td>0.009247</td>\n",
              "      <td>0.007949</td>\n",
              "      <td>0.009186</td>\n",
              "      <td>0.012807</td>\n",
              "      <td>0.019351</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>-0.083333</td>\n",
              "      <td>-0.044736</td>\n",
              "      <td>-0.140440</td>\n",
              "      <td>-0.008144</td>\n",
              "      <td>-0.007820</td>\n",
              "      <td>-0.043478</td>\n",
              "      <td>-0.039516</td>\n",
              "      <td>-0.050214</td>\n",
              "      <td>0.009538</td>\n",
              "      <td>0.004470</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>-0.083333</td>\n",
              "      <td>-0.044736</td>\n",
              "      <td>-0.136928</td>\n",
              "      <td>-0.008144</td>\n",
              "      <td>-0.029013</td>\n",
              "      <td>-0.043478</td>\n",
              "      <td>-0.039516</td>\n",
              "      <td>-0.050214</td>\n",
              "      <td>0.009538</td>\n",
              "      <td>0.004470</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>152 rows Ã— 700 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2086c03f-3395-427a-9f71-72646cbaf648')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2086c03f-3395-427a-9f71-72646cbaf648 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2086c03f-3395-427a-9f71-72646cbaf648');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "print('The features arranged in order of saliency are: \\n')\n",
        "features[saliency_order]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "74075456",
      "metadata": {
        "id": "74075456",
        "outputId": "b0b04eb0-4b40-40d6-8338-43047e52ced9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "num_features = 100\n",
        "salient_features = features.iloc[:,saliency_order[0:num_features]]\n",
        "A = np.zeros((features.shape[0], features.shape[0]))\n",
        "for i in features.index:\n",
        "    for j in range(i):\n",
        "        A[i,j] = np.linalg.norm(salient_features.iloc[i,:] - salient_features.iloc[j,:])\n",
        "A = A + np.transpose(A)\n",
        "p = 1.3\n",
        "A = (A < p)\n",
        "A = A - np.eye(A.shape[0])\n",
        "rows, cols = np.where(A==1)\n",
        "edges = zip(rows.tolist(), cols.tolist())\n",
        "G = nx.Graph()\n",
        "G.add_edges_from(edges, node_size=1)\n",
        "color_map = np.array([])\n",
        "for node in G:\n",
        "    if (class_label[node]==0):\n",
        "        color_map = np.append(color_map, 'red')\n",
        "    elif (class_label[node]==1):\n",
        "        color_map = np.append(color_map, 'blue')\n",
        "    else:\n",
        "        color_map = np.append(color_map, 'yellow')\n",
        "nx.draw(G, node_color=color_map)\n",
        "plt.plot()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nx.is_connected(G) # tells whether or not the graph is connected\n",
        "# nx.clustering(G) # gives the clustering value of each vertex"
      ],
      "metadata": {
        "id": "CZQuhjgE2J34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7f83110-f24e-4877-a9f7-22f1c3737803"
      },
      "id": "CZQuhjgE2J34",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nx.number_connected_components(G) # number of different connected components"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc3dliY3CKcW",
        "outputId": "1623759b-d818-4094-a17b-29fe89be7035"
      },
      "id": "Rc3dliY3CKcW",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nx.density(G) # this tells how close the graph is to being fully connected\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZIxz2ELCKno",
        "outputId": "b687c5d9-7ebf-4275-9d62-f06f52db800f"
      },
      "id": "SZIxz2ELCKno",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4695302013422819"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nx.average_clustering(G) # clustering value for the whole graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1g5OOrXCKxf",
        "outputId": "07a2e3c4-e9a9-4f26-969b-d998339cc226"
      },
      "id": "Y1g5OOrXCKxf",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7561923178052088"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nx.transitivity(G) # 3* number of triangles in G/ number of connected triads in G"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwfxV_O2CK73",
        "outputId": "16c179f0-0ac2-431e-fb01-de87e2c0670f"
      },
      "id": "KwfxV_O2CK73",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8007330739533417"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "04de62bc",
      "metadata": {
        "id": "04de62bc",
        "outputId": "457fb95f-13f7-4a90-db31-c095059b9ae9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "giant_component = G.subgraph(max(nx.connected_components(G), key=len))\n",
        "color_map_GC = np.array([])\n",
        "for node in G:\n",
        "    if node in giant_component:\n",
        "        color_map_GC = np.append(color_map_GC, 'blue')\n",
        "    else:\n",
        "        color_map_GC = np.append(color_map_GC, 'red')\n",
        "nx.draw(G, node_color=color_map_GC)\n",
        "plt.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "1cf69a78",
      "metadata": {
        "id": "1cf69a78",
        "outputId": "69436881-368e-46bd-fed4-aa1f611ce84d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eccentricity of giant component: {0: 3, 1: 3, 2: 3, 3: 3, 4: 3, 5: 3, 6: 3, 7: 3, 8: 3, 9: 3, 10: 3, 11: 3, 12: 3, 13: 3, 14: 3, 15: 3, 16: 3, 17: 3, 18: 3, 20: 3, 21: 3, 22: 3, 23: 3, 24: 3, 25: 3, 26: 3, 27: 3, 28: 3, 29: 3, 30: 3, 31: 3, 32: 3, 33: 3, 34: 3, 35: 3, 36: 3, 37: 3, 38: 3, 39: 3, 41: 3, 42: 3, 43: 3, 46: 3, 47: 3, 50: 3, 51: 3, 52: 3, 53: 3, 54: 3, 55: 3, 56: 3, 57: 3, 58: 3, 59: 3, 60: 3, 61: 3, 62: 3, 63: 3, 64: 3, 65: 3, 66: 3, 67: 3, 72: 3, 73: 4, 75: 3, 76: 3, 77: 3, 78: 3, 81: 3, 89: 3, 92: 3, 96: 3, 100: 3, 102: 3, 116: 3, 122: 3, 123: 3, 124: 3, 125: 3, 126: 3, 127: 3, 128: 3, 129: 3, 132: 3, 133: 3, 136: 3, 137: 3, 138: 3, 139: 3, 140: 3, 141: 3, 142: 3, 143: 3, 144: 3, 145: 3, 146: 3, 147: 3, 148: 3, 149: 3, 150: 3, 151: 3, 99: 4, 90: 4, 97: 3, 113: 3, 40: 4, 74: 3, 68: 4, 69: 3, 88: 4, 108: 4, 130: 4, 131: 4, 82: 3, 91: 3, 95: 3, 115: 4, 117: 4, 118: 4, 121: 4, 101: 4, 19: 4, 87: 4, 80: 3, 85: 4, 49: 4, 84: 4, 83: 4, 79: 5, 48: 5, 114: 4, 98: 4, 105: 4, 103: 4, 120: 4, 109: 4, 110: 4, 111: 4, 112: 4, 119: 4, 86: 5, 93: 4, 104: 4, 106: 4}\n",
            "Diameter of giant component: 5\n",
            "Radius of giant component: 3\n",
            "Degree centrality: \n",
            "{0: 0.6711409395973155, 1: 0.610738255033557, 2: 0.6241610738255033, 3: 0.5570469798657718, 4: 0.7114093959731543, 5: 0.7449664429530202, 6: 0.6241610738255033, 7: 0.40268456375838924, 8: 0.6912751677852349, 9: 0.7046979865771812, 10: 0.7449664429530202, 11: 0.7449664429530202, 12: 0.6577181208053691, 13: 0.5838926174496644, 14: 0.6845637583892618, 15: 0.7114093959731543, 16: 0.5704697986577181, 17: 0.38926174496644295, 18: 0.6375838926174496, 20: 0.6644295302013423, 21: 0.7114093959731543, 22: 0.7248322147651006, 23: 0.6711409395973155, 24: 0.6845637583892618, 25: 0.6644295302013423, 26: 0.610738255033557, 27: 0.7114093959731543, 28: 0.5906040268456376, 29: 0.6442953020134228, 30: 0.697986577181208, 31: 0.6375838926174496, 32: 0.6174496644295302, 33: 0.5906040268456376, 34: 0.6845637583892618, 35: 0.6577181208053691, 36: 0.5973154362416108, 37: 0.6845637583892618, 38: 0.6308724832214765, 39: 0.6241610738255033, 41: 0.5503355704697986, 42: 0.5570469798657718, 43: 0.7449664429530202, 46: 0.4832214765100671, 47: 0.6845637583892618, 50: 0.6510067114093959, 51: 0.6912751677852349, 52: 0.5033557046979865, 53: 0.5637583892617449, 54: 0.6644295302013423, 55: 0.47651006711409394, 56: 0.5838926174496644, 57: 0.7516778523489933, 58: 0.7382550335570469, 59: 0.7114093959731543, 60: 0.18120805369127516, 61: 0.6241610738255033, 62: 0.6711409395973155, 63: 0.44966442953020136, 64: 0.6711409395973155, 65: 0.6711409395973155, 66: 0.6778523489932886, 67: 0.5906040268456376, 72: 0.5503355704697986, 73: 0.21476510067114093, 75: 0.5100671140939598, 76: 0.7449664429530202, 77: 0.5503355704697986, 78: 0.6845637583892618, 81: 0.4228187919463087, 89: 0.7248322147651006, 92: 0.3624161073825503, 96: 0.5906040268456376, 100: 0.5436241610738255, 102: 0.4832214765100671, 116: 0.8322147651006712, 122: 0.42953020134228187, 123: 0.3624161073825503, 124: 0.7651006711409396, 125: 0.7046979865771812, 126: 0.4899328859060403, 127: 0.6241610738255033, 128: 0.8187919463087248, 129: 0.7114093959731543, 132: 0.4966442953020134, 133: 0.3221476510067114, 136: 0.825503355704698, 137: 0.7516778523489933, 138: 0.6711409395973155, 139: 0.6375838926174496, 140: 0.6845637583892618, 141: 0.6711409395973155, 142: 0.7114093959731543, 143: 0.6442953020134228, 144: 0.6510067114093959, 145: 0.3624161073825503, 146: 0.5838926174496644, 147: 0.4697986577181208, 148: 0.6040268456375839, 149: 0.7315436241610738, 150: 0.5234899328859061, 151: 0.7516778523489933, 99: 0.3221476510067114, 90: 0.2483221476510067, 97: 0.7181208053691275, 113: 0.436241610738255, 40: 0.1476510067114094, 74: 0.44295302013422816, 68: 0.2348993288590604, 69: 0.3624161073825503, 88: 0.19463087248322147, 108: 0.18791946308724833, 130: 0.06711409395973154, 131: 0.08053691275167785, 82: 0.35570469798657717, 91: 0.31543624161073824, 95: 0.5369127516778524, 115: 0.2348993288590604, 117: 0.0738255033557047, 118: 0.19463087248322147, 121: 0.35570469798657717, 101: 0.33557046979865773, 19: 0.013422818791946308, 87: 0.174496644295302, 80: 0.22818791946308725, 85: 0.15436241610738255, 49: 0.03355704697986577, 84: 0.174496644295302, 83: 0.14093959731543623, 79: 0.006711409395973154, 44: 0.006711409395973154, 45: 0.006711409395973154, 48: 0.006711409395973154, 114: 0.12751677852348994, 98: 0.16778523489932887, 105: 0.1342281879194631, 103: 0.10067114093959731, 120: 0.09395973154362416, 70: 0.006711409395973154, 71: 0.006711409395973154, 109: 0.08053691275167785, 110: 0.19463087248322147, 111: 0.026845637583892617, 112: 0.12080536912751677, 119: 0.12751677852348994, 86: 0.013422818791946308, 93: 0.06711409395973154, 104: 0.053691275167785234, 106: 0.026845637583892617, 134: 0.006711409395973154, 135: 0.006711409395973154}\n",
            "Maximum degree centrality: 151\n",
            "Degree histogram: [0, 8, 2, 0, 2, 1, 0, 0, 1, 0, 2, 1, 2, 0, 1, 1, 0, 0, 1, 2, 1, 1, 1, 1, 0, 1, 2, 1, 1, 3, 0, 0, 1, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 2, 4, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 2, 1, 1, 1, 1, 0, 1, 0, 1, 1, 3, 2, 1, 1, 0, 3, 4, 1, 1, 2, 1, 5, 1, 3, 2, 2, 2, 3, 7, 1, 7, 2, 1, 2, 7, 1, 2, 1, 1, 5, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]\n",
            "Eigenvector centrality: \n",
            "{0: 0.10568164868946893, 1: 0.09800702693418131, 2: 0.10077692017061576, 3: 0.09066268317278622, 4: 0.1072938300287277, 5: 0.10996279095528882, 6: 0.1001745696645837, 7: 0.06675194416382953, 8: 0.10697705827673196, 9: 0.10849532164864324, 10: 0.11130299387795507, 11: 0.11213702348449725, 12: 0.10402068255759407, 13: 0.09574838569654198, 14: 0.10721061828384022, 15: 0.10804762841603292, 16: 0.0943559945842312, 17: 0.065440056801099, 18: 0.10117401264387167, 20: 0.10486711666637398, 21: 0.1096230293204988, 22: 0.11036987903810042, 23: 0.1041336773482118, 24: 0.10658179522625437, 25: 0.10483273075455347, 26: 0.09770536709303741, 27: 0.10895023269627264, 28: 0.09673939217511572, 29: 0.10198472139747243, 30: 0.10786384637659578, 31: 0.10140515593112341, 32: 0.09904999376361058, 33: 0.09440510337902108, 34: 0.10625086670823947, 35: 0.1042505757147523, 36: 0.09524304942855968, 37: 0.10629726695094759, 38: 0.10113859352460601, 39: 0.10096398489492238, 41: 0.09079516181112042, 42: 0.09001199901783064, 43: 0.11165625137989078, 46: 0.07944211185821719, 47: 0.10629272644428137, 50: 0.10334895049577515, 51: 0.10632036669329542, 52: 0.08293122064537876, 53: 0.09360694383671764, 54: 0.10507042924069254, 55: 0.08018453538779512, 56: 0.0904517024283204, 57: 0.11225866718029372, 58: 0.1096926848535599, 59: 0.1088899918574062, 60: 0.03168746736280967, 61: 0.09967116774335585, 62: 0.10483862149138475, 63: 0.07413617474503216, 64: 0.10419700444722377, 65: 0.10243726446037091, 66: 0.10634339938109573, 67: 0.09595193131775048, 72: 0.08748370130662009, 73: 0.03601458301851529, 75: 0.084234548062266, 76: 0.11044205901579685, 77: 0.08952905629171037, 78: 0.10655473493321153, 81: 0.062462281633864206, 89: 0.10039931277156496, 92: 0.05301495104062622, 96: 0.08318467428353404, 100: 0.07225737884314946, 102: 0.0687822544179083, 116: 0.11314286322967868, 122: 0.06894579784113965, 123: 0.05980914747932941, 124: 0.11220686251786492, 125: 0.10679658130693537, 126: 0.07874228079508684, 127: 0.09427712176522572, 128: 0.1139327277907434, 129: 0.10359251826426309, 132: 0.07952579087270344, 133: 0.05273755081238096, 136: 0.11391992611437975, 137: 0.11111265311278902, 138: 0.10455143971240581, 139: 0.10094440136552109, 140: 0.10673684018199601, 141: 0.10387507638312882, 142: 0.10947797482161675, 143: 0.10152908808254636, 144: 0.10008902106572654, 145: 0.06060904589290904, 146: 0.08981012048731324, 147: 0.07783524372944114, 148: 0.09684190294244781, 149: 0.10674785070660261, 150: 0.0834837702045587, 151: 0.11136131525054879, 99: 0.04357321086882522, 90: 0.03963702188578159, 97: 0.09543280893441893, 113: 0.05899340829700533, 40: 0.024273220594645754, 74: 0.06395458781586823, 68: 0.037813958622366764, 69: 0.059821319458023874, 88: 0.027011513842672013, 108: 0.025311531803032805, 130: 0.01001544140882912, 131: 0.012419634861937687, 82: 0.04251768256675481, 91: 0.04322617939648913, 95: 0.07401483902937617, 115: 0.02946541037228731, 117: 0.009290858205235645, 118: 0.019812630373453665, 121: 0.04341698869788167, 101: 0.04771098481208268, 19: 0.0015577065772666761, 87: 0.023339896443881413, 80: 0.02972926047732324, 85: 0.017441657198181755, 49: 0.004490331255555255, 84: 0.021076048102081506, 83: 0.014100771392603323, 79: 0.00026837348538638004, 44: 4.8866274392925085e-15, 45: 4.8866274392925085e-15, 48: 4.964627567109007e-05, 114: 0.017063839906288337, 98: 0.016504957370468448, 105: 0.013609598034564015, 103: 0.010197984537304666, 120: 0.010210435781218755, 70: 4.8866274392925085e-15, 71: 4.8866274392925085e-15, 109: 0.007137192492852655, 110: 0.020296130858380484, 111: 0.00225463061172568, 112: 0.01159151944828747, 119: 0.011769974226785234, 86: 0.0005567190717549737, 93: 0.006034336237428372, 104: 0.0017064533287827555, 106: 0.0009972717081347608, 134: 4.8866274392925085e-15, 135: 4.8866274392925085e-15}\n",
            "Maximum eigenvector centrality: 151\n",
            "Closeness centrality: \n",
            "{0: 0.7223242670434475, 1: 0.6862080536912751, 2: 0.6931394481730052, 3: 0.6566584245849523, 4: 0.749954157039645, 5: 0.7753763318545481, 6: 0.6966579225292133, 7: 0.5915586669752372, 8: 0.737858122248683, 9: 0.7458783192296469, 10: 0.7753763318545481, 11: 0.7710202850463765, 12: 0.7185424645981938, 13: 0.6694712718939269, 14: 0.7300085677566757, 15: 0.7540747842761265, 16: 0.6662214113507525, 17: 0.5865026099925429, 18: 0.7074309831868816, 20: 0.7261460885621959, 21: 0.7540747842761265, 22: 0.7667129091522628, 23: 0.7261460885621959, 24: 0.737858122248683, 25: 0.7223242670434475, 26: 0.6931394481730052, 27: 0.749954157039645, 28: 0.6727529938149756, 29: 0.7038031319910514, 30: 0.737858122248683, 31: 0.7002122996849746, 32: 0.6931394481730052, 33: 0.6794139145458169, 34: 0.737858122248683, 35: 0.7185424645981938, 36: 0.6827940832749007, 37: 0.7339123568890643, 38: 0.7002122996849746, 39: 0.6966579225292133, 41: 0.6504341741149527, 42: 0.6662214113507525, 43: 0.7797818791946308, 46: 0.6238255033557046, 47: 0.7339123568890643, 50: 0.7148000559284116, 51: 0.7418465445311082, 52: 0.6324498190702997, 53: 0.6598154362416107, 54: 0.7185424645981938, 55: 0.621002763521516, 56: 0.6760670479716997, 57: 0.7797818791946308, 58: 0.7710202850463765, 59: 0.7582409433052764, 60: 0.5008817910155293, 61: 0.7002122996849746, 62: 0.7261460885621959, 63: 0.6099627143922446, 64: 0.7261460885621959, 65: 0.7223242670434475, 66: 0.7339123568890643, 67: 0.6794139145458169, 72: 0.6566584245849523, 73: 0.5218312195370913, 75: 0.6353778274919215, 76: 0.7753763318545481, 77: 0.6535314797059764, 78: 0.737858122248683, 81: 0.6045885935605948, 89: 0.7582409433052764, 92: 0.5840068542053405, 96: 0.6827940832749007, 100: 0.6598154362416107, 102: 0.6295486731112615, 116: 0.8317673378076063, 122: 0.6019368892028729, 123: 0.5790785263217512, 124: 0.7887448893003163, 125: 0.7458783192296469, 126: 0.6324498190702997, 127: 0.7002122996849746, 128: 0.8317673378076063, 129: 0.7540747842761265, 132: 0.6353778274919215, 133: 0.5601698397479797, 136: 0.8368390898674087, 137: 0.7797818791946308, 138: 0.7300085677566757, 139: 0.7074309831868816, 140: 0.7339123568890643, 141: 0.7185424645981938, 142: 0.749954157039645, 143: 0.7038031319910514, 144: 0.7110964286956218, 145: 0.5790785263217512, 146: 0.6827940832749007, 147: 0.621002763521516, 148: 0.6896563353681157, 149: 0.7624533929903057, 150: 0.6443268109777232, 151: 0.7753763318545481, 99: 0.5647802911039301, 90: 0.5319442276676551, 97: 0.7540747842761265, 113: 0.6099627143922446, 40: 0.49906040268456375, 74: 0.6126857622243528, 68: 0.5298903889507917, 69: 0.576645423269979, 88: 0.5198545861297539, 108: 0.515945905031034, 130: 0.4748844662223357, 131: 0.4748844662223357, 82: 0.5815322488909112, 91: 0.5671140939597316, 95: 0.6566584245849523, 115: 0.5340140495651947, 117: 0.48667237850445044, 118: 0.5198545861297539, 121: 0.576645423269979, 101: 0.5694672644740872, 19: 0.3822886092987605, 87: 0.515945905031034, 80: 0.5361000419463087, 85: 0.510191861480502, 49: 0.4329388351364512, 84: 0.515945905031034, 83: 0.5008817910155293, 79: 0.329116572513801, 44: 0.006711409395973154, 45: 0.006711409395973154, 48: 0.2990013305844336, 114: 0.5008817910155293, 98: 0.510191861480502, 105: 0.49906040268456375, 103: 0.4884043086770642, 120: 0.48667237850445044, 70: 0.006711409395973154, 71: 0.006711409395973154, 109: 0.4765333706189411, 110: 0.5218312195370913, 111: 0.42358521832794765, 112: 0.49545707847745496, 119: 0.5008817910155293, 86: 0.3555482143478109, 93: 0.4798657718120805, 104: 0.4096764499649404, 106: 0.4001213141056998, 134: 0.006711409395973154, 135: 0.006711409395973154}\n",
            "Maximum closeness centrality: 151\n",
            "Betweeness centrality: \n",
            "{0: 0.0018726648022598582, 1: 0.001113304184459114, 2: 0.0011058276262783035, 3: 0.0011399069973433028, 4: 0.006830578915851918, 5: 0.00867534969146138, 6: 0.0012192367690544619, 7: 0.00587402541540746, 8: 0.0030594395490549683, 9: 0.003290695950212549, 10: 0.00538145321457732, 11: 0.004025374291262265, 12: 0.0023615798829487696, 13: 0.0006350671689976434, 14: 0.002077883055098973, 15: 0.004630464522620947, 16: 0.0004029078656497753, 17: 8.420720735359228e-05, 18: 0.007356901848052011, 20: 0.0023737076786393306, 21: 0.003573569548522623, 22: 0.004426843135745777, 23: 0.002827600896509016, 24: 0.003082664028781534, 25: 0.0019402736194743299, 26: 0.001391188456099076, 27: 0.0036017501478973722, 28: 0.0006239006428579793, 29: 0.002209475413571772, 30: 0.0036334167828071637, 31: 0.0021290769138228617, 32: 0.0012604651866182162, 33: 0.006253806297352169, 34: 0.009601812538211964, 35: 0.007533029346254442, 36: 0.001361322363699815, 37: 0.0034306386511947346, 38: 0.001273210118300279, 39: 0.0009892483156104335, 41: 0.000471130547889548, 42: 0.0016288960343261885, 43: 0.0057859615043058055, 46: 0.00046474664579727973, 47: 0.0034342791038123963, 50: 0.002097134631736686, 51: 0.004194874066282834, 52: 0.000810611211877059, 53: 0.00044353740786352353, 54: 0.0023061695886043326, 55: 0.0001510437511376418, 56: 0.004014494003765973, 57: 0.0048903837921652005, 58: 0.007302034210198947, 59: 0.004129047418529168, 60: 0.0, 61: 0.002185703502575439, 62: 0.002867931960024248, 63: 0.007179338028591349, 64: 0.0030260228290240544, 65: 0.004484080233350145, 66: 0.0027374780474247206, 67: 0.0012314337419176567, 72: 0.002595260561178295, 73: 2.7485311224861683e-05, 75: 0.0006566420024666913, 76: 0.00809899234811617, 77: 0.006279051365722708, 78: 0.0032233516741343978, 81: 0.0029400949224739816, 89: 0.013313337821650848, 92: 0.0014005649434731613, 96: 0.007012723823036061, 100: 0.018750402367816738, 102: 0.008092059302523097, 116: 0.020779329854129783, 122: 0.001409780753899034, 123: 0.00012511780840824776, 124: 0.007461222671267421, 125: 0.005341357259496221, 126: 0.0013207237515432569, 127: 0.004726637107511106, 128: 0.0184905531678654, 129: 0.011668291411684574, 132: 0.0015521394265032796, 133: 0.00037142242870622037, 136: 0.017460510027491716, 137: 0.007241876651709379, 138: 0.002844207957109572, 139: 0.002087193798601668, 140: 0.0023800841885917015, 141: 0.004990996976344058, 142: 0.003584641470231546, 143: 0.001792941843078594, 144: 0.0045134988110827326, 145: 0.00025992156522134296, 146: 0.002598098825762534, 147: 0.0002513794281547142, 148: 0.0016774778696983866, 149: 0.010211124235248864, 150: 0.0020642888048540238, 151: 0.008038895604181034, 99: 0.0016190176149231755, 90: 0.0002801516094395536, 97: 0.01640066522805364, 113: 0.005063327448545735, 40: 0.012878650462543075, 74: 0.003949569547369514, 68: 0.00019602422274136254, 69: 0.0004298833924819771, 88: 0.007291535029755851, 108: 0.001787301722868208, 130: 5.310254793497146e-05, 131: 7.726267851238922e-05, 82: 0.003956634473593312, 91: 0.0021789484482598147, 95: 0.013964331831940095, 115: 0.001090978441269748, 117: 0.00011548522614663296, 118: 0.002444443924293708, 121: 0.0033772662323065246, 101: 0.0015859902576239153, 19: 0.0, 87: 0.006071087132732364, 80: 0.001038735527743893, 85: 0.00039856059896912116, 49: 0.01287865046254308, 84: 0.0004001496799021715, 83: 0.00038745211933782607, 79: 0.0, 44: 0.0, 45: 0.0, 48: 0.0, 114: 6.538999451629163e-05, 98: 0.0015608912390196472, 105: 0.0009842838417955357, 103: 0.0011532184434145225, 120: 9.418205812450102e-05, 70: 0.0, 71: 0.0, 109: 0.00010442332196164249, 110: 0.002523613724543366, 111: 6.478194397657485e-06, 112: 0.0006415396984431402, 119: 0.0009886512613682323, 86: 1.0077191285244975e-05, 93: 0.0009320279425500294, 104: 0.0005109614691880159, 106: 0.0001613397414234268, 134: 0.0, 135: 0.0}\n",
            "Maximum betweeness centrality: 151\n"
          ]
        }
      ],
      "source": [
        "print(f'Eccentricity of giant component: {nx.eccentricity(giant_component)}') # largest possible shortest path distance between a vertex and all other vertices\n",
        "print(f'Diameter of giant component: {nx.diameter(giant_component)}') # maximum shortest distance between a pair of vertices in G, it is the largest possible eccentricity value of a vertex\n",
        "print(f'Radius of giant component: {nx.radius(giant_component)}') #  minimum eccentricity value of a vertex\n",
        "\n",
        "print(f'Degree centrality: \\n{nx.degree_centrality(G)}') # number of edges incident upon a vertex\n",
        "print(f'Maximum degree centrality: {max(nx.degree_centrality(G))}')\n",
        "print(f'Degree histogram: {nx.degree_histogram(G)}')\n",
        "\n",
        "# below gives us the different centrality measures for the vertices of the graphs\n",
        "print(f'Eigenvector centrality: \\n{nx.eigenvector_centrality(G)}')\n",
        "print(f'Maximum eigenvector centrality: {max(nx.eigenvector_centrality(G))}')\n",
        "print(f'Closeness centrality: \\n{nx.closeness_centrality(G)}')\n",
        "print(f'Maximum closeness centrality: {max(nx.closeness_centrality(G))}')\n",
        "print(f'Betweeness centrality: \\n{nx.betweenness_centrality(G)}')\n",
        "print(f'Maximum betweeness centrality: {max(nx.betweenness_centrality(G))}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "a21a45c5",
      "metadata": {
        "id": "a21a45c5",
        "outputId": "78d12c1f-40bc-4d27-9114-91b23aa37f41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Iterations:  4\n"
          ]
        }
      ],
      "source": [
        "kmeans = KMeans(n_clusters=3)\n",
        "kmeans.fit(salient_features)\n",
        "print('Number of Iterations: ', kmeans.n_iter_)\n",
        "predicted_label = kmeans.labels_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Cluster Centers: ', kmeans.cluster_centers_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4pMZU70CW7z",
        "outputId": "7b36f8cc-3f86-467c-eb18-039437289c0b"
      },
      "id": "r4pMZU70CW7z",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Centers:  [[-3.78787879e-01 -1.33622548e-02  6.22432333e-02 -8.14373591e-03\n",
            "   1.02845798e-02 -1.36280299e-02 -1.04173427e-02 -1.20615760e-02\n",
            "  -4.09597530e-03 -9.33434578e-03 -6.11565911e-03 -3.68607991e-02\n",
            "  -2.18197659e-02 -1.72728874e-02 -3.46690162e-04 -9.59856778e-03\n",
            "  -3.59396728e-03  2.75583230e-02  5.00152880e-04 -3.57427314e-03\n",
            "   4.43402190e-03 -1.17129404e-02 -5.96272848e-05  8.31202769e-02\n",
            "  -1.70953084e-02 -4.21875938e-02  1.29722300e-02 -2.19361480e-02\n",
            "  -1.11221258e-02 -2.74204462e-02 -6.31868799e-02  7.45674683e-02\n",
            "  -4.22829818e-02 -3.57856351e-03  8.98518730e-02 -4.32625390e-03\n",
            "   7.21976561e-02 -1.40643205e-02  6.48230522e-02 -7.59624248e-02\n",
            "  -1.22001867e-02 -1.41937736e-02  2.00973243e-02 -3.16104778e-02\n",
            "   4.45750499e-02  2.97635077e-02 -1.14808529e-01  4.44092364e-02\n",
            "   4.46751978e-02 -4.49935358e-03 -5.36150809e-03 -2.55158886e-02\n",
            "  -4.51761107e-02 -1.43624085e-01 -5.37239374e-02  1.87573022e-02\n",
            "  -5.72819611e-02  7.11306696e-02  8.96257178e-03 -1.72272047e-02\n",
            "  -8.00411324e-03  1.37315596e-01 -7.84321093e-03 -9.43419213e-03\n",
            "  -1.53167076e-02 -9.30075755e-04 -2.59644474e-02  1.94308846e-02\n",
            "   8.64863042e-02  4.63578238e-03  5.18052081e-03  5.11352632e-04\n",
            "  -1.09834764e-03 -6.46726756e-03  6.60337979e-03 -1.01902591e-03\n",
            "   1.04046110e-01 -6.19732690e-03 -9.17996704e-04  2.34024416e-02\n",
            "  -2.27098499e-02 -1.00906467e-01 -1.36755170e-02 -5.04286875e-03\n",
            "  -1.38021355e-02 -1.11335048e-02 -7.58204155e-02 -5.20514234e-03\n",
            "  -9.72003659e-03 -3.91148974e-02  5.48081976e-02 -1.72966982e-02\n",
            "  -2.77098497e-02 -6.11525871e-02 -1.01225569e-02  3.38567297e-03\n",
            "  -1.33809099e-02 -1.11419049e-02 -2.86152837e-02  3.24020232e-02]\n",
            " [ 2.50000000e-01 -4.17247079e-02  4.22168828e-02 -8.14373591e-03\n",
            "   4.96402636e-02 -3.41069899e-02 -5.08163620e-02 -4.10590707e-02\n",
            "  -1.67287235e-02 -3.67486066e-01 -5.69568139e-02 -1.05410161e-02\n",
            "  -3.15710220e-02 -2.51582451e-02  3.67188155e-02 -6.05277331e-02\n",
            "  -6.18111971e-02  8.40017634e-02  1.82973101e-02 -3.12133615e-02\n",
            "  -3.70004300e-02 -4.75795089e-02  2.95516872e-02 -8.37197107e-03\n",
            "  -1.52631173e-02 -5.55757186e-02 -5.30342918e-01 -1.32202311e-02\n",
            "  -4.84451161e-02 -1.12970796e-02  1.06316326e-01  6.55087003e-02\n",
            "   8.28495279e-02 -2.35280386e-02  4.83040050e-02  1.16572462e-01\n",
            "   3.29673029e-02 -2.43903888e-02  3.11988576e-02 -5.09415741e-02\n",
            "  -2.69960037e-02 -2.24770513e-02  4.84852932e-02  4.56971663e-02\n",
            "  -3.77193851e-02 -2.61878175e-02 -1.76207863e-01 -2.90245034e-02\n",
            "  -3.60501833e-02 -3.42856538e-01 -5.10107183e-02 -1.38834193e-02\n",
            "  -7.10960128e-01 -1.20857895e-02 -8.67840151e-02  8.90471248e-02\n",
            "   1.69268920e-01  3.87212209e-02  6.78044010e-02 -6.35874420e-02\n",
            "  -3.13968925e-01 -7.34031751e-02 -6.95331781e-02 -3.49120291e-01\n",
            "  -1.10579796e-01 -8.25863642e-03 -5.98881259e-02 -5.97481887e-01\n",
            "   7.72618673e-03  4.47285964e-02 -5.15926831e-02  3.72786095e-02\n",
            "   9.77761850e-03 -3.04926141e-01  5.27102596e-02 -3.40747060e-01\n",
            "   6.41048237e-02 -3.78587173e-01  1.68679174e-02  1.35065924e-01\n",
            "  -1.30234144e-01 -1.64779397e-01 -5.02620467e-02 -7.19799791e-02\n",
            "  -2.50082835e-01 -1.48431324e-01  9.43656595e-02 -7.03178550e-02\n",
            "  -2.91447648e-01 -9.09250504e-03 -6.79479769e-01 -3.81273477e-02\n",
            "  -1.81316276e-02  1.32097693e-01  7.46881907e-03  8.48146379e-02\n",
            "   1.56230478e-02 -1.02252282e-03  1.43345752e-02 -7.29248948e-01]\n",
            " [ 1.50641026e-01  7.25805811e-03 -2.79574019e-02  3.75864734e-03\n",
            "  -6.26040928e-03  7.07751227e-03  6.36181276e-03  6.68216947e-03\n",
            "   2.37632507e-03  1.80832258e-02  4.77804093e-03  1.60003772e-02\n",
            "   1.04457095e-02  8.27538485e-03 -1.26558553e-03  6.38892226e-03\n",
            "   3.89787835e-03 -1.48901275e-02 -9.15345837e-04  2.71270639e-03\n",
            "  -4.52838882e-04  6.78545590e-03 -1.11137642e-03 -3.48442721e-02\n",
            "   7.81967346e-03  1.99861250e-02  1.49095534e-02  9.78914843e-03\n",
            "   6.56878847e-03  1.20354611e-02  2.26438213e-02 -3.40673405e-02\n",
            "   1.47024335e-02  2.41893220e-03 -3.98721003e-02 -2.65321804e-03\n",
            "  -3.18131354e-02  6.88838131e-03 -2.86250935e-02  3.40972403e-02\n",
            "   6.19992528e-03  6.86956002e-03 -1.03675331e-02  1.16160803e-02\n",
            "  -1.74079294e-02 -1.15850295e-02  5.53500647e-02 -1.76721961e-02\n",
            "  -1.75144997e-02  1.50903626e-02  4.23028105e-03  1.13291613e-02\n",
            "   4.64575902e-02  6.12288740e-02  2.60672049e-02 -1.13606711e-02\n",
            "   1.77243328e-02 -3.15830226e-02 -6.39971887e-03  9.73410360e-03\n",
            "   1.54620835e-02 -5.52718609e-02  5.99263455e-03  1.74190925e-02\n",
            "   1.07332146e-02  7.11133451e-04  1.32883480e-02  1.47593137e-02\n",
            "  -3.68875205e-02 -3.68162318e-03 -2.07424839e-04 -1.65013417e-03\n",
            "   8.86232881e-05  1.44640802e-02 -4.82105528e-03  1.35367825e-02\n",
            "  -4.64850784e-02  1.71829911e-02 -2.60382835e-04 -1.50958762e-02\n",
            "   1.46170190e-02  4.90288668e-02  7.71895131e-03  4.90198213e-03\n",
            "   1.54579356e-02  1.04192260e-02  2.84484197e-02  4.90670849e-03\n",
            "   1.53218481e-02  1.68983222e-02  2.94575367e-03  8.78427030e-03\n",
            "   1.24207683e-02  2.07915679e-02  3.99535795e-03 -4.69450156e-03\n",
            "   5.06026775e-03  4.75321066e-03  1.15551364e-02  1.43394882e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Inertia: ', kmeans.inertia_) # SSE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRGO62KOCXHz",
        "outputId": "0b9455a8-9230-4cda-a5d9-e77d91567a48"
      },
      "id": "BRGO62KOCXHz",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inertia:  122.31186650528306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "19f946f0",
      "metadata": {
        "id": "19f946f0",
        "outputId": "aad613b6-c8c5-48f9-f627-6c35841e57f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KMeans accuracy for 3 classes:  0.4934210526315789\n"
          ]
        }
      ],
      "source": [
        "compared_classes = np.array([])\n",
        "for i in classes.iterrows():\n",
        "    if i[1]['adenoma']==1:\n",
        "        compared_classes = np.append(compared_classes, 2)\n",
        "    elif i[1]['hyperplasic']==1:\n",
        "        compared_classes = np.append(compared_classes, 1)\n",
        "    else:\n",
        "        compared_classes = np.append(compared_classes, 0)\n",
        "print('KMeans accuracy for 3 classes: ', np.count_nonzero(compared_classes==predicted_label)/len(predicted_label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "d5069e44",
      "metadata": {
        "id": "d5069e44",
        "outputId": "75f13e25-4a43-4223-d281-e5f46e45e42b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Iterations:  4\n"
          ]
        }
      ],
      "source": [
        "kmeans = KMeans(n_clusters=2)\n",
        "kmeans.fit(salient_features)\n",
        "print('Number of Iterations: ', kmeans.n_iter_)\n",
        "predicted_label = kmeans.labels_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Cluster Centers: ', kmeans.cluster_centers_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEgc-bXBCeHP",
        "outputId": "44874d44-ad8a-44e7-dd55-1a3b06b87c15"
      },
      "id": "kEgc-bXBCeHP",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Centers:  [[-3.14625850e-01 -1.68825514e-02  5.77241633e-02 -8.14373591e-03\n",
            "   1.35119332e-02 -1.69487314e-02 -1.54499130e-02 -1.58361664e-02\n",
            "  -5.20158172e-03 -4.00469555e-02 -1.20332779e-02 -3.19136330e-02\n",
            "  -2.97988504e-02 -7.20337115e-03  3.77283516e-03 -1.50267419e-02\n",
            "  -1.14293120e-02  3.53177865e-02  2.46774974e-03 -7.30464853e-03\n",
            "   1.35758401e-04 -1.65045876e-02  3.50944342e-03  7.29453172e-02\n",
            "  -2.00512177e-02 -4.61846217e-02 -3.77023600e-02 -1.91668227e-02\n",
            "  -1.20321400e-02 -2.47973793e-02 -5.21467934e-02  8.51970541e-02\n",
            "  -2.65345270e-02 -5.82408917e-03  9.88098343e-02  8.37253896e-03\n",
            "   7.18296749e-02 -1.68928385e-02  6.48517198e-02 -6.86348900e-02\n",
            "  -1.52302790e-02 -1.62515731e-02  2.52237804e-02 -2.86438752e-02\n",
            "   3.78187887e-02  2.46395848e-02 -1.11884751e-01  3.85306104e-02\n",
            "   3.81274339e-02 -3.47997449e-02 -1.10449878e-02 -2.25677342e-02\n",
            "  -1.08367877e-01 -1.27456912e-01 -5.92640039e-02  2.82933976e-02\n",
            "  -3.40509384e-02  7.06747440e-02  1.58574451e-02 -2.05574437e-02\n",
            "  -3.58427253e-02  1.17266974e-01 -1.42956774e-02 -3.89399960e-02\n",
            "  -2.64882557e-02 -1.40567670e-03 -1.80781516e-02 -4.45588660e-02\n",
            "   7.65069588e-02  9.18117031e-03  2.13221297e-03  4.86531707e-03\n",
            "   1.98475842e-04 -3.46914957e-02  1.15946254e-02 -3.53727820e-02\n",
            "   8.96017057e-02 -4.28185414e-02  1.41886509e-03  3.72759510e-02\n",
            "  -3.57519510e-02 -1.03052290e-01 -1.86604825e-02 -1.53504365e-02\n",
            "  -3.50912807e-02 -2.55231146e-02 -5.30171385e-02 -1.25973225e-02\n",
            "  -3.42755826e-02 -3.52967669e-02 -2.72600370e-02 -2.10186054e-02\n",
            "  -2.55536352e-02 -4.38996030e-02 -5.72599750e-03  4.30592667e-03\n",
            "  -1.14588722e-02 -1.99405893e-02 -3.15078239e-02 -4.55338635e-02]\n",
            " [ 1.49676375e-01  8.03150503e-03 -2.74610097e-02  3.87420446e-03\n",
            "  -6.42800705e-03  8.06298871e-03  7.34995860e-03  7.53371023e-03\n",
            "   2.47453888e-03  1.90514643e-02  5.72456910e-03  1.51822138e-02\n",
            "   1.41761521e-02  3.42684647e-03 -1.79484391e-03  7.14864420e-03\n",
            "   5.43724549e-03 -1.68016654e-02 -1.17397803e-03  3.47502697e-03\n",
            "  -6.45840938e-05  7.85169699e-03 -1.66954105e-03 -3.47021412e-02\n",
            "   9.53892883e-03  2.19713249e-02  1.79360742e-02  9.11819719e-03\n",
            "   5.72402776e-03  1.17968115e-02  2.48076978e-02 -4.05306374e-02\n",
            "   1.26232216e-02  2.77068320e-03 -4.70066202e-02 -3.98305252e-03\n",
            "  -3.41713987e-02  8.03639890e-03 -3.08517890e-02  3.26515496e-02\n",
            "   7.24547253e-03  7.73133091e-03 -1.19996625e-02  1.36266979e-02\n",
            "  -1.79914626e-02 -1.17217442e-02  5.32267263e-02 -1.83300962e-02\n",
            "  -1.81382938e-02  1.65552185e-02  5.25441165e-03  1.07361066e-02\n",
            "   5.15536501e-02  6.06348416e-02  2.81935552e-02 -1.34599659e-02\n",
            "   1.61989901e-02 -3.36219656e-02 -7.54383311e-03  9.77975478e-03\n",
            "   1.70513936e-02 -5.57872010e-02  6.80085626e-03  1.85248525e-02\n",
            "   1.26012090e-02  6.68719981e-04  8.60028572e-03  2.11979071e-02\n",
            "  -3.63965144e-02 -4.36774122e-03 -1.01435374e-03 -2.31456832e-03\n",
            "  -9.44205460e-05  1.65037212e-02 -5.51588973e-03  1.68278283e-02\n",
            "  -4.26260542e-02  2.03699857e-02 -6.74994072e-04 -1.77332194e-02\n",
            "   1.70082097e-02  4.90248759e-02  8.87731690e-03  7.30263482e-03\n",
            "   1.66939102e-02  1.21420642e-02  2.52217455e-02  5.99290099e-03\n",
            "   1.63058597e-02  1.67916658e-02  1.29683671e-02  9.99914238e-03\n",
            "   1.21565837e-02  2.08842771e-02  2.72401823e-03 -2.04845055e-03\n",
            "   5.45130813e-03  9.48629978e-03  1.49891590e-02  2.16617409e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Inertia: ', kmeans.inertia_) # SSE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RV1oqdgtCgR1",
        "outputId": "4c21a7d9-e683-4af6-fd15-09a2caead313"
      },
      "id": "RV1oqdgtCgR1",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inertia:  136.53823843090078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "4bd2148b",
      "metadata": {
        "id": "4bd2148b",
        "outputId": "e30f7edf-5e12-4e0a-9bfc-0737a13cbccf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KMeans accuracy for 2 classes:  0.07236842105263158\n"
          ]
        }
      ],
      "source": [
        "compared_classes = np.array([])\n",
        "for i in classes.iterrows():\n",
        "    if i[1]['adenoma']==1:\n",
        "        compared_classes = np.append(compared_classes, 0)\n",
        "    elif i[1]['hyperplasic']==1:\n",
        "        compared_classes = np.append(compared_classes, 1)\n",
        "    else:\n",
        "        compared_classes = np.append(compared_classes, 0)\n",
        "print('KMeans accuracy for 2 classes: ', np.count_nonzero(compared_classes==predicted_label)/len(predicted_label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "2c92d9eb",
      "metadata": {
        "id": "2c92d9eb",
        "outputId": "978e178b-2a77-4f0e-e96f-acd030ed24d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "color_map_cluster = np.array([])\n",
        "for node in G:\n",
        "    if (predicted_label[node]==0):\n",
        "        color_map_cluster = np.append(color_map_cluster, 'red')\n",
        "    elif (predicted_label[node]==1):\n",
        "        color_map_cluster = np.append(color_map_cluster, 'blue')\n",
        "    else:\n",
        "        color_map_cluster = np.append(color_map_cluster, 'yellow')\n",
        "nx.draw(G, node_color=color_map_cluster)\n",
        "plt.plot()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "MLPColonoscopy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}