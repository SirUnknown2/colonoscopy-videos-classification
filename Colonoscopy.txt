# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-28T20:15:37.237168Z","iopub.execute_input":"2022-04-28T20:15:37.237514Z","iopub.status.idle":"2022-04-28T20:15:37.245544Z","shell.execute_reply.started":"2022-04-28T20:15:37.237481Z","shell.execute_reply":"2022-04-28T20:15:37.244484Z"}}
from tqdm import tqdm
from sklearn.model_selection import LeaveOneOut
from IPython.utils import io
import pandas as pd
import numpy as np
import networkx as nx
import matplotlib.pyplot as plt
from sklearn.datasets import make_blobs
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import InputLayer
from tensorflow.keras.layers import Activation

# %% [code] {"execution":{"iopub.status.busy":"2022-04-28T20:15:37.269126Z","iopub.execute_input":"2022-04-28T20:15:37.269983Z","iopub.status.idle":"2022-04-28T20:15:37.312886Z","shell.execute_reply.started":"2022-04-28T20:15:37.269939Z","shell.execute_reply":"2022-04-28T20:15:37.312188Z"}}
features = pd.read_csv('../input/gastrointestinal-lesions/data.txt')
features = features.T
class_label = pd.Series(features.index)
features.index = range(features.shape[0])
classes = np.zeros((features.shape[0], 3))
for i in range(classes.shape[0]):
    if 'adenoma' in class_label[i]:
        classes[i,0] = 1.0
        class_label[i] = 0
    elif 'serrated' in class_label[i]:
        classes[i,2] = 1.0
        class_label[i] = 2
    else:
        classes[i,1] = 1.0
        class_label[i] = 1
classes = {'adenoma': classes[:,0], 'hyperplasic': classes[:,1], 'serrated': classes[:,2]}
classes = pd.DataFrame(classes)
class_label = class_label.astype('int')

# %% [code] {"execution":{"iopub.status.busy":"2022-04-28T20:15:37.314211Z","iopub.execute_input":"2022-04-28T20:15:37.314565Z","iopub.status.idle":"2022-04-28T20:15:37.762607Z","shell.execute_reply.started":"2022-04-28T20:15:37.314536Z","shell.execute_reply":"2022-04-28T20:15:37.761943Z"}}
for col in features.columns:
    if features[col].abs().max()==0:
        continue
    features[col] = (features[col] - features[col].mean())/features[col].abs().max()

# %% [code] {"execution":{"iopub.status.busy":"2022-04-28T20:15:37.763928Z","iopub.execute_input":"2022-04-28T20:15:37.764260Z","iopub.status.idle":"2022-04-28T20:15:37.814714Z","shell.execute_reply.started":"2022-04-28T20:15:37.764231Z","shell.execute_reply":"2022-04-28T20:15:37.813820Z"}}
model = Sequential([
    
    InputLayer(input_shape=(features.shape[1])),
    Dense(7, activation='sigmoid'),
    Dense(5, activation='sigmoid'),
    Dense(3, activation='relu')])

model.compile(optimizer='Adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])
model.summary()
model.save_weights('model_weights/initial_weights_colonoscopy')

# %% [code] {"execution":{"iopub.status.busy":"2022-04-28T20:15:37.816137Z","iopub.execute_input":"2022-04-28T20:15:37.816524Z","iopub.status.idle":"2022-04-28T20:31:37.911840Z","shell.execute_reply.started":"2022-04-28T20:15:37.816479Z","shell.execute_reply":"2022-04-28T20:31:37.910840Z"}}
acc = 0
j = 0
for train_index, test_index in LeaveOneOut().split(features):
    x_train, x_test = features.iloc[train_index,:], features.iloc[test_index,:]
    y_train, y_test = classes.iloc[train_index,:], classes.iloc[test_index,:]
    model.load_weights('model_weights/initial_weights_colonoscopy')
    with io.capture_output() as captured:
        model.fit(x_train, y_train, epochs=500)
    acc += model.evaluate(x_test, y_test)[1]
    j+=1

# %% [code] {"execution":{"iopub.status.busy":"2022-04-28T20:31:37.914217Z","iopub.execute_input":"2022-04-28T20:31:37.914467Z","iopub.status.idle":"2022-04-28T20:31:37.922701Z","shell.execute_reply.started":"2022-04-28T20:31:37.914436Z","shell.execute_reply":"2022-04-28T20:31:37.921868Z"}}
acc/j

# %% [code] {"execution":{"iopub.status.busy":"2022-04-28T20:31:37.923910Z","iopub.execute_input":"2022-04-28T20:31:37.924157Z","iopub.status.idle":"2022-04-28T20:31:47.062349Z","shell.execute_reply.started":"2022-04-28T20:31:37.924126Z","shell.execute_reply":"2022-04-28T20:31:47.061520Z"}}
model.fit(features, classes, epochs=500)

# %% [code] {"execution":{"iopub.status.busy":"2022-04-28T20:31:47.063704Z","iopub.execute_input":"2022-04-28T20:31:47.063946Z","iopub.status.idle":"2022-04-28T20:39:19.452693Z","shell.execute_reply.started":"2022-04-28T20:31:47.063918Z","shell.execute_reply":"2022-04-28T20:39:19.451758Z"}}
grad_sum = 0
for col_name in tqdm(features.columns):
    pointFrame = features.loc[:, features.columns != col_name]
    for i in features[col_name]:
        pointFrame[col_name] = i*np.ones(len(features.index))
        points = tf.Variable(pointFrame, dtype='float')
        with tf.GradientTape() as tape:
            pred = model(points, training=False)
        grads = tape.gradient(pred, points)
        grad_sum += np.abs(grads.numpy())
saliency_order = np.argsort(-np.sum(np.abs(grad_sum), 0))

# %% [code] {"execution":{"iopub.status.busy":"2022-04-28T20:39:19.453772Z","iopub.execute_input":"2022-04-28T20:39:19.454013Z","iopub.status.idle":"2022-04-28T20:39:19.497520Z","shell.execute_reply.started":"2022-04-28T20:39:19.453986Z","shell.execute_reply":"2022-04-28T20:39:19.496641Z"}}
features[saliency_order]

# %% [code] {"execution":{"iopub.status.busy":"2022-04-28T20:42:13.067323Z","iopub.execute_input":"2022-04-28T20:42:13.067618Z","iopub.status.idle":"2022-04-28T20:42:16.913065Z","shell.execute_reply.started":"2022-04-28T20:42:13.067583Z","shell.execute_reply":"2022-04-28T20:42:16.912189Z"}}
num_features = 100
salient_features = features.iloc[:,saliency_order[0:num_features]]
A = np.zeros((features.shape[0], features.shape[0]))
for i in features.index:
    for j in range(i):
        A[i,j] = np.linalg.norm(salient_features.iloc[i,:] - salient_features.iloc[j,:])
A = A + np.transpose(A)
# p = np.median(A).astype('int')
# print(np.max(A))
p = 1.3
A = (A < p)
A = A - np.eye(A.shape[0])
rows, cols = np.where(A==1)
edges = zip(rows.tolist(), cols.tolist())
G = nx.Graph()
G.add_edges_from(edges, node_size=1)
color_map = np.array([])
for node in G:
    if (class_label[node]==0):
        color_map = np.append(color_map, 'red')
    elif (class_label[node]==1):
        color_map = np.append(color_map, 'blue')
    else:
        color_map = np.append(color_map, 'yellow')
nx.draw(G, node_color=color_map) 
plt.plot()

# %% [code] {"execution":{"iopub.status.busy":"2022-04-28T20:57:05.584356Z","iopub.execute_input":"2022-04-28T20:57:05.584698Z","iopub.status.idle":"2022-04-28T20:57:05.589996Z","shell.execute_reply.started":"2022-04-28T20:57:05.584663Z","shell.execute_reply":"2022-04-28T20:57:05.589278Z"}}
print(p)

# %% [code] {"execution":{"iopub.status.busy":"2022-04-28T20:39:23.641791Z","iopub.execute_input":"2022-04-28T20:39:23.642013Z","iopub.status.idle":"2022-04-28T20:39:23.924331Z","shell.execute_reply.started":"2022-04-28T20:39:23.641979Z","shell.execute_reply":"2022-04-28T20:39:23.923395Z"}}
nx.is_connected(G) # tells whether or not the graph is connected
nx.number_connected_components(G) # number of different connected components
nx.density(G) # this tells how close the graph is to being fully connected
# nx.clustering(G) # gives the clustering value of each vertex
nx.average_clustering(G) # clustering value for the whole graph
nx.transitivity(G) # 3* number of triangles in G/ number of connected triads in G

# %% [code] {"execution":{"iopub.status.busy":"2022-04-28T20:41:15.233513Z","iopub.execute_input":"2022-04-28T20:41:15.233824Z","iopub.status.idle":"2022-04-28T20:41:15.543269Z","shell.execute_reply.started":"2022-04-28T20:41:15.233793Z","shell.execute_reply":"2022-04-28T20:41:15.542383Z"}}
giant_component = G.subgraph(max(nx.connected_components(G), key=len))
color_map_GC = np.array([])
for node in G:
    if node in giant_component:
        color_map_GC = np.append(color_map_GC, 'blue')
    else:
        color_map_GC = np.append(color_map_GC, 'red')
nx.draw(G, node_color=color_map_GC)
plt.plot()

# %% [code] {"execution":{"iopub.status.busy":"2022-04-28T20:43:03.629954Z","iopub.execute_input":"2022-04-28T20:43:03.630542Z","iopub.status.idle":"2022-04-28T20:43:08.997812Z","shell.execute_reply.started":"2022-04-28T20:43:03.630495Z","shell.execute_reply":"2022-04-28T20:43:08.996975Z"}}
nx.eccentricity(giant_component) # largest possible shortest path distance between a vertex and all other vertices
nx.diameter(giant_component) # maximum shortest distance between a pair of vertices in G, it is the largest possible eccentricity value of a vertex
nx.radius(giant_component) #  minimum eccentricity value of a vertex

nx.degree_centrality(G) # number of edges incident upon a vertex
max(nx.degree_centrality(G))
nx.degree_histogram(G) # making a histogram of the distribution of degrees

# below gives us the different centrality measures for the vertices of the graphs
nx.eigenvector_centrality(G)
max(nx.eigenvector_centrality(G))
nx.closeness_centrality(G)
max(nx.closeness_centrality(G))
nx.betweenness_centrality(G)
max(nx.betweenness_centrality(G))

# %% [code] {"execution":{"iopub.status.busy":"2022-04-28T20:54:16.555260Z","iopub.execute_input":"2022-04-28T20:54:16.555670Z","iopub.status.idle":"2022-04-28T20:54:17.313290Z","shell.execute_reply.started":"2022-04-28T20:54:16.555627Z","shell.execute_reply":"2022-04-28T20:54:17.312254Z"}}
kmeans = KMeans(n_clusters=3)
kmeans.fit(salient_features)
print(kmeans.n_iter_)
print(kmeans.cluster_centers_)
print(kmeans.inertia_)
predicted_label = kmeans.labels_
# predicted_label = kmeans.fit_predict(features)
print(predicted_label)
print(classes)

# %% [code] {"execution":{"iopub.status.busy":"2022-04-28T20:55:01.914442Z","iopub.execute_input":"2022-04-28T20:55:01.914752Z","iopub.status.idle":"2022-04-28T20:55:01.942183Z","shell.execute_reply.started":"2022-04-28T20:55:01.914718Z","shell.execute_reply":"2022-04-28T20:55:01.941125Z"}}
compared_classes = np.array([])
for i in classes.iterrows():
    if i[1]['adenoma']==1:
        compared_classes = np.append(compared_classes, 1)
    elif i[1]['hyperplasic']==1:
        compared_classes = np.append(compared_classes, 0)
    else:
        compared_classes = np.append(compared_classes, 2)

# this gives the percent of match between the cluster groups and the actual groups
print(np.count_nonzero(compared_classes==predicted_label)/ len(predicted_label))
# print(i[1]['adenoma'])

# %% [code] {"execution":{"iopub.status.busy":"2022-04-28T20:55:40.698178Z","iopub.execute_input":"2022-04-28T20:55:40.698453Z","iopub.status.idle":"2022-04-28T20:55:41.102579Z","shell.execute_reply.started":"2022-04-28T20:55:40.698425Z","shell.execute_reply":"2022-04-28T20:55:41.101716Z"}}
color_map_cluster = np.array([])
for node in G:
    if (predicted_label[node]==0):
        color_map_cluster = np.append(color_map_cluster, 'red')
    elif (predicted_label[node]==1):
        color_map_cluster = np.append(color_map_cluster, 'blue')
    else:
        color_map_cluster = np.append(color_map_cluster, 'yellow')
nx.draw(G, node_color=color_map_cluster)
plt.plot()